__updated__ = "2022-11-05 00:13:07"

import os
import numpy as np
import pandas as pd
import datetime
from typing import Union
from loguru import logger

from pure_ocean_breeze.legacy_version.v3p4.state.states import STATES
from pure_ocean_breeze.legacy_version.v3p4.state.homeplace import HomePlace
from pure_ocean_breeze.legacy_version.v3p4.state.decorators import *
from pure_ocean_breeze.legacy_version.v3p4.data.database import ClickHouseClient, Questdb

homeplace = HomePlace()


def read_daily(
    path: str = None,
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    tr: bool = 0,
    sharenum: bool = 0,
    volume: bool = 0,
    age: bool = 0,
    flow_cap: bool = 0,
    st: bool = 0,
    state: bool = 0,
    unadjust: bool = 0,
    ret: bool = 0,
    ret_inday: bool = 0,
    ret_night: bool = 0,
    vol: bool = 0,
    vol_inday: bool = 0,
    vol_night: bool = 0,
    swing: bool = 0,
    pb: bool = 0,
    pe: bool = 0,
    iret: bool = 0,
    ivol: bool = 0,
    start: int = STATES["START"],
) -> pd.DataFrame:
    """ç›´æ¥è¯»å–å¸¸ç”¨çš„é‡ä»·è¯»å–æ—¥é¢‘æ•°æ®ï¼Œé»˜è®¤ä¸ºå¤æƒä»·æ ¼ï¼Œ
    åœ¨ open,close,high,low,tr,sharenum,volume ä¸­é€‰æ‹©ä¸€ä¸ªå‚æ•°æŒ‡å®šä¸º1

    Parameters
    ----------
    path : str, optional
        è¦è¯»å–æ–‡ä»¶çš„è·¯å¾„ï¼Œç”±äºå¸¸ç”¨çš„é«˜å¼€ä½æ”¶æ¢æ‰‹ç‡ç­‰éƒ½å·²ç»å°è£…ï¼Œå› æ­¤æ­¤å¤„é€šå¸¸ä¸ºNone, by default None
    open : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å¼€ç›˜ä»·, by default 0
    close : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ”¶ç›˜ä»·, by default 0
    high : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€é«˜ä»·, by default 0
    low : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€ä½ä»·, by default 0
    tr : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ¢æ‰‹ç‡, by default 0
    sharenum : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šè‚¡æ•°, by default 0
    volume : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æˆäº¤é‡, by default 0
    age : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–ä¸Šå¸‚å¤©æ•°, by default 0
    flow_cap : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šå¸‚å€¼, by default 0
    st : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥æ˜¯å¦ä¸ºstè‚¡ï¼Œ1è¡¨ç¤ºæ˜¯stè‚¡ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    state : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥äº¤æ˜“çŠ¶æ€æ˜¯å¦æ­£å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸äº¤æ˜“ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    unadjust : bool, optional
        ä¸º1åˆ™å°†ä¸Šè¿°ä»·æ ¼æ”¹ä¸ºä¸å¤æƒä»·æ ¼, by default 0
    ret : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ—¥é—´æ”¶ç›Šç‡, by default 0
    ret_inday : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ—¥å†…æ”¶ç›Šç‡, by default 0
    ret_night : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–éš”å¤œæ³¢åŠ¨ç‡, by default 0
    vol : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ»šåŠ¨20æ—¥æ—¥é—´æ³¢åŠ¨ç‡, by default 0
    vol_inday : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ»šåŠ¨20æ—¥æ—¥å†…æ”¶ç›Šç‡æ³¢åŠ¨ç‡, by default 0
    vol_night : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ»šåŠ¨20æ—¥éš”å¤œæ”¶ç›Šç‡æ³¢åŠ¨ç‡, by default 0
    swing : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æŒ¯å¹…, by default 0
    pb : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–å¸‚å‡€ç‡, by default 0
    pe : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–å¸‚ç›ˆç‡, by default 0
    iret : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–20æ—¥å›å½’çš„famaä¸‰å› å­ï¼ˆå¸‚åœºã€æµé€šå¸‚å€¼ã€å¸‚å‡€ç‡ï¼‰ç‰¹è´¨æ”¶ç›Šç‡, by default 0
    ivol : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–20æ—¥å›å½’çš„20æ—¥famaä¸‰å› å­ï¼ˆå¸‚åœºã€æµé€šå¸‚å€¼ã€å¸‚å‡€ç‡ï¼‰ç‰¹è´¨æ³¢åŠ¨ç‡, by default 0
    start : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default STATES["START"]

    Returns
    -------
    `pd.DataFrame`
        ä¸€ä¸ªcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œindexä¸ºæ—¶é—´ï¼Œvaluesä¸ºç›®æ ‡æ•°æ®çš„pd.DataFrame

    Raises
    ------
    `IOError`
        open,close,high,low,tr,sharenum,volume éƒ½ä¸º0æ—¶ï¼Œå°†æŠ¥é”™
    å¦ï¼šå¦‚æœæ•°æ®æœªæ›´æ–°ï¼Œå¯ä½¿ç”¨read_daily.clear_cache()æ¥æ¸…ç©ºç¼“å­˜
    """

    if not unadjust:
        if path:
            return pd.read_feather(homeplace.daily_data_file + path).set_index("date")
        elif open:
            opens = pd.read_feather(homeplace.daily_data_file + "opens.feather")
            df = opens
            df = df.set_index(list(df.columns)[0])
        elif close:
            closes = pd.read_feather(homeplace.daily_data_file + "closes.feather")
            df = closes
            df = df.set_index(list(df.columns)[0])
        elif high:
            highs = pd.read_feather(homeplace.daily_data_file + "highs.feather")
            df = highs
            df = df.set_index(list(df.columns)[0])
        elif low:
            lows = pd.read_feather(homeplace.daily_data_file + "lows.feather")
            df = lows
            df = df.set_index(list(df.columns)[0])
        elif tr:
            trs = pd.read_feather(homeplace.daily_data_file + "trs.feather")
            df = trs
            df = df.set_index(list(df.columns)[0])
        elif sharenum:
            sharenums = pd.read_feather(homeplace.daily_data_file + "sharenums.feather")
            df = sharenums
            df = df.set_index(list(df.columns)[0])
        elif volume:
            volumes = pd.read_feather(homeplace.daily_data_file + "volumes.feather")
            df = volumes
            df = df.set_index(list(df.columns)[0])
        elif age:
            age = pd.read_feather(homeplace.daily_data_file + "ages.feather")
            df = age
            df = df.set_index(list(df.columns)[0])
        elif flow_cap:
            closes = pd.read_feather(homeplace.daily_data_file + "closes_unadj.feather")
            sharenums = pd.read_feather(homeplace.daily_data_file + "sharenums.feather")
            closes = closes.set_index(list(closes.columns)[0])
            sharenums = sharenums.set_index(list(sharenums.columns)[0])
            flow_cap = closes * sharenums
            df = flow_cap
        elif st:
            st = pd.read_feather(homeplace.daily_data_file + "sts.feather")
            df = st
            df = df.set_index(list(df.columns)[0])
        elif state:
            state = pd.read_feather(homeplace.daily_data_file + "states.feather")
            df = state
            df = df.set_index(list(df.columns)[0])
        elif ret:
            df = read_daily(close=1, start=start)
            df = df / df.shift(1) - 1
        elif ret_inday:
            df = read_daily(close=1, start=start) / read_daily(open=1, start=start) - 1
        elif ret_night:
            df = (
                read_daily(open=1, start=start)
                / read_daily(close=1, start=start).shift(1)
                - 1
            )
        elif vol:
            df = read_daily(ret=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif vol_inday:
            df = read_daily(ret_inday=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif vol_night:
            df = read_daily(ret_night=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif swing:
            df = (
                read_daily(high=1, start=start) - read_daily(low=1, start=start)
            ) / read_daily(close=1, start=start)
        elif pb:
            df = pd.read_feather(homeplace.daily_data_file + "pb.feather")
            df = df.set_index(list(df.columns)[0])
        elif pe:
            df = pd.read_feather(homeplace.daily_data_file + "pe.feather")
            df = df.set_index(list(df.columns)[0])
        elif iret:
            df = pd.read_feather(
                homeplace.daily_data_file + "idiosyncratic_ret.feather"
            )
            df = df.set_index(list(df.columns)[0])
        elif ivol:
            df = read_daily(iret=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")
    else:
        if open:
            opens = pd.read_feather(homeplace.daily_data_file + "opens.feather")
            df = opens
            df = df.set_index(list(df.columns)[0])
        elif close:
            closes = pd.read_feather(homeplace.daily_data_file + "closes.feather")
            df = closes
            df = df.set_index(list(df.columns)[0])
        elif high:
            highs = pd.read_feather(homeplace.daily_data_file + "highs.feather")
            df = highs
            df = df.set_index(list(df.columns)[0])
        elif low:
            lows = pd.read_feather(homeplace.daily_data_file + "lows.feather")
            df = lows
            df = df.set_index(list(df.columns)[0])

        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")
    df = df[df.index >= pd.Timestamp(str(start))]
    return df


def read_market(
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    start: int = STATES["START"],
    every_stock: bool = 1,
) -> Union[pd.DataFrame, pd.Series]:
    """è¯»å–ä¸­è¯å…¨æŒ‡æ—¥è¡Œæƒ…æ•°æ®

    Parameters
    ----------
    open : bool, optional
        è¯»å–å¼€ç›˜ç‚¹æ•°, by default 0
    close : bool, optional
        è¯»å–æ”¶ç›˜ç‚¹æ•°, by default 0
    high : bool, optional
        è¯»å–æœ€é«˜ç‚¹æ•°, by default 0
    low : bool, optional
        è¯»å–æœ€ä½ç‚¹æ•°, by default 0
    start : int, optional
        è¯»å–çš„èµ·å§‹æ—¥æœŸ, by default STATES["START"]
    every_stock : bool, optional
        æ˜¯å¦ä¿®æ”¹ä¸ºindexæ˜¯æ—¶é—´ï¼Œcolumnsæ˜¯æ¯åªè‚¡ç¥¨ä»£ç ï¼Œæ¯ä¸€åˆ—å€¼éƒ½ç›¸åŒçš„å½¢å¼, by default 1

    Returns
    -------
    Union[pd.DataFrame,pd.Series]
        ä¸­è¯å…¨æŒ‡æ¯å¤©çš„æŒ‡æ•°

    Raises
    ------
    IOError
        å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æŒ‡æ•°ï¼Œå°†æŠ¥é”™
    """
    try:
        chc = ClickHouseClient("minute_data")
        df = chc.get_data(
            f"select * from minute_data.minute_data_index where code='000985.SH' and date>={start}00 order by date,num"
        )
        df = df.set_index("code")
        df = df / 100
    except Exception:
        qdb = Questdb()
        df = qdb.get_data(
            "select date,num,close from minute_data_index where code='000985.SH'"
        )
        df.num = df.num.astype(int)
    df = df.set_index("date")
    df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
    if open:
        # ç±³ç­çš„ç¬¬ä¸€åˆ†é’Ÿæ˜¯é›†åˆç«ä»·ï¼Œç¬¬ä¸€åˆ†é’Ÿçš„æ”¶ç›˜ä»·å³ä¸ºå½“å¤©å¼€ç›˜ä»·
        df = df[df.num == 1].close
    elif close:
        df = df[df.num == 240].close
    elif high:
        df = df[df.num > 1]
        df = df.groupby("date").max()
        df = df.high
    elif low:
        df = df[df.num > 1]
        df = df.groupby("date").min()
        df = df.low
    else:
        raise IOError("æ€»å¾—æŒ‡å®šä¸€ä¸ªæŒ‡æ ‡å§ï¼ŸğŸ¤’")
    if every_stock:
        tr = read_daily(tr=1, start=start)
        df = pd.DataFrame({k: list(df) for k in list(tr.columns)}, index=df.index)
    return df


def read_money_flow(
    buy: bool = 0,
    sell: bool = 0,
    exlarge: bool = 0,
    large: bool = 0,
    median: bool = 0,
    small: bool = 0,
    whole: bool = 0,
) -> pd.DataFrame:
    """ä¸€é”®è¯»å…¥èµ„é‡‘æµå‘æ•°æ®ï¼ŒåŒ…æ‹¬è¶…å¤§å•ã€å¤§å•ã€ä¸­å•ã€å°å•çš„ä¹°å…¥å’Œå–å‡ºæƒ…å†µ

    Parameters
    ----------
    buy : bool, optional
        æ–¹å‘ä¸ºä¹°, by default 0
    sell : bool, optional
        æ–¹å‘ä¸ºå–, by default 0
    exlarge : bool, optional
        è¶…å¤§å•ï¼Œé‡‘é¢å¤§äº100ä¸‡ï¼Œä¸ºæœºæ„æ“ä½œ, by default 0
    large : bool, optional
        å¤§å•ï¼Œé‡‘é¢åœ¨20ä¸‡åˆ°100ä¸‡ä¹‹é—´ï¼Œä¸ºå¤§æˆ·ç‰¹å¤§å•, by default 0
    median : bool, optional
        ä¸­å•ï¼Œé‡‘é¢åœ¨4ä¸‡åˆ°20ä¸‡ä¹‹é—´ï¼Œä¸ºä¸­æˆ·å¤§å•, by default 0
    small : bool, optional
        å°å•ï¼Œé‡‘é¢åœ¨4ä¸‡ä»¥ä¸‹ï¼Œä¸ºæ•£æˆ·ä¸­å•, by default 0
    whole : bool, optional
        è¯»å…¥å½“å¤©çš„æ€»äº¤æ˜“é¢, by default 0

    Returns
    -------
    pd.DataFrame
        indexä¸ºæ—¶é—´ï¼Œcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œvaluesä¸ºå¯¹åº”ç±»å‹è®¢å•å½“æ—¥çš„æˆäº¤é‡‘é¢

    Raises
    ------
    IOError
        buyå’Œsellå¿…é¡»æŒ‡å®šä¸€ä¸ªï¼Œå¦åˆ™ä¼šæŠ¥é”™
    IOError
        exlargeï¼Œlargeï¼Œmedianå’Œsmallå¿…é¡»æŒ‡å®šä¸€ä¸ªï¼Œå¦åˆ™ä¼šæŠ¥é”™
    """
    if not whole:
        if buy:
            if exlarge:
                name = "buy_value_exlarge"
            elif large:
                name = "buy_value_large"
            elif median:
                name = "buy_value_med"
            elif small:
                name = "buy_value_small"
            else:
                raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ç§è§„æ¨¡å§ï¼ŸğŸ¤’")
        elif sell:
            if exlarge:
                name = "sell_value_exlarge"
            elif large:
                name = "sell_value_large"
            elif median:
                name = "sell_value_med"
            elif small:
                name = "sell_value_small"
            else:
                raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ç§è§„æ¨¡å§ï¼ŸğŸ¤’")
        else:
            raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸‹æ˜¯ä¹°è¿˜æ˜¯å–å§ï¼ŸğŸ¤’")
        name = homeplace.daily_data_file + name + ".feather"
        df = pd.read_feather(name).set_index("date")
        return df
    else:
        dfs = [
            pd.read_feather(homeplace.daily_data_file + name + ".feather").set_index(
                "date"
            )
            for name in [
                "buy_value_exlarge",
                "buy_value_large",
                "buy_value_med",
                "buy_value_small",
                "sell_value_exlarge",
                "sell_value_large",
                "sell_value_med",
                "sell_value_small",
            ]
        ]
        dfs = sum(dfs)
        return dfs


def read_index_single(code: str) -> pd.Series:
    try:
        chc = ClickHouseClient("minute_data")
        hs300 = (
            chc.get_data(
                f"select date,num,close FROM minute_data.minute_data_index WHERE code='{code}'"
            )
            / 100
        )
        hs300.date = pd.to_datetime(hs300.date, format="%Y%m%d")
        hs300 = (
            hs300.sort_values(["date", "num"])
            .groupby("date")
            .last()
            .drop(columns=["num"])
            .close
        )
        return hs300
    except Exception:
        qdb = Questdb()
        hs300 = qdb.get_data(
            f"select date,num,close FROM 'minute_data_index' WHERE code='{code}'"
        )
        hs300.date = pd.to_datetime(hs300.date, format="%Y%m%d")
        hs300.num = hs300.num.astype(int)
        hs300 = (
            hs300.sort_values(["date", "num"])
            .groupby("date")
            .last()
            .drop(columns=["num"])
            .close
        )
        return hs300


def read_index_three(day: int = None) -> tuple[pd.DataFrame]:
    """è¯»å–ä¸‰å¤§æŒ‡æ•°çš„åŸå§‹è¡Œæƒ…æ•°æ®ï¼Œè¿”å›å¹¶ä¿å­˜åœ¨æœ¬åœ°

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None

    Returns
    -------
    `tuple[pd.DataFrame]`
        åˆ†åˆ«è¿”å›æ²ªæ·±300ã€ä¸­è¯500ã€ä¸­è¯1000çš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]

    hs300, zz500, zz1000, zz2000 = (
        read_index_single("000300.SH").resample("M").last(),
        read_index_single("000905.SH").resample("M").last(),
        read_index_single("000852.SH").resample("M").last(),
        read_index_single("399303.SZ").resample("M").last(),
    )
    hs300 = hs300[hs300.index >= pd.Timestamp(str(day))]
    zz500 = zz500[zz500.index >= pd.Timestamp(str(day))]
    zz1000 = zz1000[zz1000.index >= pd.Timestamp(str(day))]
    zz2000 = zz2000[zz2000.index >= pd.Timestamp(str(day))]

    return hs300, zz500, zz1000, zz2000


def read_swindustry_prices(
    day: int = None, monthly: bool = 1, start: int = STATES["START"]
) -> pd.DataFrame:
    """è¯»å–ç”³ä¸‡ä¸€çº§è¡Œä¸šæŒ‡æ•°çš„æ—¥è¡Œæƒ…æˆ–æœˆè¡Œæƒ…

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None
    monthly : bool, optional
        æ˜¯å¦ä¸ºæœˆè¡Œæƒ…, by default 1

    Returns
    -------
    `pd.DataFrame`
        ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    df = pd.read_feather(homeplace.daily_data_file + "ç”³ä¸‡å„è¡Œä¸šè¡Œæƒ…æ•°æ®.feather").set_index(
        "date"
    )
    df = df[df.index >= pd.Timestamp(str(start))]
    if monthly:
        df = df.resample("M").last()
    return df


def read_zxindustry_prices(
    day: int = None, monthly: bool = 1, start: int = STATES["START"]
) -> pd.DataFrame:
    """è¯»å–ä¸­ä¿¡ä¸€çº§è¡Œä¸šæŒ‡æ•°çš„æ—¥è¡Œæƒ…æˆ–æœˆè¡Œæƒ…

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None
    monthly : bool, optional
        æ˜¯å¦ä¸ºæœˆè¡Œæƒ…, by default 1

    Returns
    -------
    `pd.DataFrame`
        ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    df = pd.read_feather(homeplace.daily_data_file + "ä¸­ä¿¡å„è¡Œä¸šè¡Œæƒ…æ•°æ®.feather").set_index(
        "date"
    )
    df = df[df.index >= pd.Timestamp(str(start))]
    if monthly:
        df = df.resample("M").last()
    return df


def get_industry_dummies(
    daily: bool = 0,
    monthly: bool = 0,
    start: int = STATES["START"],
    swindustry: bool = 0,
    zxindustry: bool = 0,
) -> dict:
    """ç”Ÿæˆ30/31ä¸ªè¡Œä¸šçš„å“‘å˜é‡çŸ©é˜µï¼Œè¿”å›ä¸€ä¸ªå­—å…¸

    Parameters
    ----------
    daily : bool, optional
        è¿”å›æ—¥é¢‘çš„å“‘å˜é‡, by default 0
    monthly : bool, optional
        è¿”å›æœˆé¢‘çš„å“‘å˜é‡, by default 0
    start : int, optional
        èµ·å§‹æ—¥æœŸ, by default STATES["START"]
    swindustry : bool, optional
        æ˜¯å¦ä½¿ç”¨ç”³ä¸‡ä¸€çº§è¡Œä¸š, by default 0
    zxindustry : bool, optional
        æ˜¯å¦ä½¿ç”¨ä¸­ä¿¡ä¸€çº§è¡Œä¸š, by default 0

    Returns
    -------
    `dict`
        å„ä¸ªè¡Œä¸šåŠå…¶å“‘å˜é‡æ„æˆçš„å­—å…¸

    Raises
    ------
    `ValueError`
        å¦‚æœæœªæŒ‡å®šé¢‘ç‡ï¼Œå°†æŠ¥é”™
    """
    homeplace = HomePlace()
    if swindustry:
        name = "ç”³ä¸‡è¡Œä¸š2021ç‰ˆå“‘å˜é‡.feather"
    else:
        name = "ä¸­ä¿¡ä¸€çº§è¡Œä¸šå“‘å˜é‡åç§°ç‰ˆ.feather"
    if monthly:
        industry_dummy = pd.read_feather(homeplace.daily_data_file + name)
        industry_dummy = (
            industry_dummy.set_index("date")
            .groupby("code")
            .resample("M")
            .last()
            .fillna(0)
            .drop(columns=["code"])
            .reset_index()
        )
    elif daily:
        industry_dummy = pd.read_feather(homeplace.daily_data_file + name).fillna(0)
    else:
        raise ValueError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸ªé¢‘ç‡å§ï¼ŸğŸ¤’")
    industry_dummy = industry_dummy[industry_dummy.date >= pd.Timestamp(str(start))]
    ws = list(industry_dummy.columns)[2:]
    ress = {}
    for w in ws:
        df = industry_dummy[["date", "code", w]]
        df = df.pivot(index="date", columns="code", values=w)
        df = df.replace(0, np.nan)
        ress[w] = df
    return ress


def database_read_final_factors(
    name: str = None, order: int = None, output: bool = 0, new: bool = 0
) -> tuple[pd.DataFrame, str]:
    """æ ¹æ®å› å­åå­—ï¼Œæˆ–å› å­åºå·ï¼Œè¯»å–æœ€ç»ˆå› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None
    order : int, optional
        å› å­çš„åºå·, by default None
    output : bool, optional
        æ˜¯å¦è¾“å‡ºåˆ°csvæ–‡ä»¶, by default 0
    new : bool, optional
        æ˜¯å¦åªè¾“å‡ºæœ€æ–°ä¸€æœŸçš„å› å­å€¼, by default 0

    Returns
    -------
    `tuple[pd.DataFrame,str]`
        æœ€ç»ˆå› å­å€¼å’Œæ–‡ä»¶è·¯å¾„
    """
    homeplace = HomePlace()
    facs = os.listdir(homeplace.final_factor_file)
    if name is None and order is None:
        raise IOError("è¯·æŒ‡å®šå› å­åå­—æˆ–è€…å› å­åºå·")
    elif name is None and order is not None:
        key = "å¤šå› å­" + str(order)
        ans = [i for i in facs if key in i][0]
    elif name is not None and name is None:
        key = name
        ans = [i for i in facs if key in i]
        if len(ans) > 0:
            ans = ans[0]
        else:
            raise IOError(f"æ‚¨åå­—è®°é”™äº†ï¼Œä¸å­˜åœ¨å«{name}çš„å› å­")
    else:
        key1 = name
        key2 = "å¤šå› å­" + str(order)
        ans1 = [i for i in facs if key1 in i]
        if len(ans1) > 0:
            ans1 = ans1[0]
        else:
            raise IOError(f"æ‚¨åå­—è®°é”™äº†ï¼Œä¸å­˜åœ¨å«{name}çš„å› å­")
        ans2 = [i for i in facs if key2 in i][0]
        if ans1 != ans2:
            ans = ans1
            logger.warning("æ‚¨è¾“å…¥çš„åå­—å’Œåºå·ä¸ä¸€è‡´ï¼Œæ€€ç–‘æ‚¨è®°é”™äº†åºå·ï¼Œç¨‹åºé»˜è®¤ä»¥åå­—ä¸ºå‡†äº†å“ˆ")
        else:
            ans = ans1
    path = homeplace.final_factor_file + ans
    df = pd.read_feather(path)
    df.columns = ["date"] + list(df.columns)[1:]
    df = df.set_index(["date"])
    df = df[sorted(list(df.columns))]
    final_date = df.index.max()
    final_date = datetime.datetime.strftime(final_date, "%Y%m%d")
    if output:
        if new:
            if os.path.exists(ans.split("_")[0]):
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            else:
                os.makedirs(ans.split("_")[0])
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            df.tail(1).T.to_csv(fac_name)
            logger.success(f"{final_date}çš„å› å­å€¼å·²ä¿å­˜")
        else:
            if os.path.exists(ans.split("_")[0]):
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­æˆªè‡³"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            else:
                os.makedirs(ans.split("_")[0])
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­æˆªè‡³"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            df.to_csv(fac_name)
            logger.success(f"æˆªè‡³{final_date}çš„å› å­å€¼å·²ä¿å­˜")
        return df, fac_name
    else:
        return df, ""


def database_read_primary_factors(name: str = None) -> pd.DataFrame:
    """æ ¹æ®å› å­åå­—ï¼Œè¯»å–åˆçº§å› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None

    Returns
    -------
    `pd.DataFrame`
        åˆçº§å› å­çš„å› å­å€¼
    """
    homeplace = HomePlace()
    name = name + "_åˆçº§.feather"
    df = pd.read_feather(homeplace.factor_data_file + name)
    df = df.rename(columns={list(df.columns)[0]: "date"})
    df = df.set_index("date")
    df = df[sorted(list(df.columns))]
    return df
