__updated__ = "2022-09-13 16:43:19"

import os
import numpy as np
import pandas as pd
import scipy.io as scio
import datetime
from typing import Union
from loguru import logger

from cachier import cachier
import pickledb
from pure_ocean_breeze.legacy_version.v3p1.state.states import STATES
from pure_ocean_breeze.legacy_version.v3p1.state.homeplace import HomePlace
from pure_ocean_breeze.legacy_version.v3p1.state.decorators import *
from pure_ocean_breeze.legacy_version.v3p1.data.database import ClickHouseClient

homeplace = HomePlace()


@cachier()
def read_daily(
    path: str = None,
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    tr: bool = 0,
    sharenum: bool = 0,
    volume: bool = 0,
    age: bool = 0,
    flow_cap: bool = 0,
    st: bool = 0,
    state: bool = 0,
    unadjust: bool = 0,
    start: int = STATES["START"],
) -> pd.DataFrame:
    """ç›´æ¥è¯»å–å¸¸ç”¨çš„é‡ä»·è¯»å–æ—¥é¢‘æ•°æ®ï¼Œé»˜è®¤ä¸ºå¤æƒä»·æ ¼ï¼Œ
    åœ¨ open,close,high,low,tr,sharenum,volume ä¸­é€‰æ‹©ä¸€ä¸ªå‚æ•°æŒ‡å®šä¸º1

    Parameters
    ----------
    path : str, optional
        è¦è¯»å–æ–‡ä»¶çš„è·¯å¾„ï¼Œç”±äºå¸¸ç”¨çš„é«˜å¼€ä½æ”¶æ¢æ‰‹ç‡ç­‰éƒ½å·²ç»å°è£…ï¼Œå› æ­¤æ­¤å¤„é€šå¸¸ä¸ºNone, by default None
    open : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å¼€ç›˜ä»·, by default 0
    close : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ”¶ç›˜ä»·, by default 0
    high : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€é«˜ä»·, by default 0
    low : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€ä½ä»·, by default 0
    tr : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ¢æ‰‹ç‡, by default 0
    sharenum : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šè‚¡æ•°, by default 0
    volume : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æˆäº¤é‡, by default 0
    age : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–ä¸Šå¸‚å¤©æ•°, by default 0
    flow_cap : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šå¸‚å€¼, by default 0
    st : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥æ˜¯å¦ä¸ºstè‚¡ï¼Œ1è¡¨ç¤ºæ˜¯stè‚¡ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    state : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥äº¤æ˜“çŠ¶æ€æ˜¯å¦æ­£å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸äº¤æ˜“ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    unadjust : bool, optional
        ä¸º1åˆ™å°†ä¸Šè¿°ä»·æ ¼æ”¹ä¸ºä¸å¤æƒä»·æ ¼, by default 0
    start : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default STATES["START"]

    Returns
    -------
    `pd.DataFrame`
        ä¸€ä¸ªcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œindexä¸ºæ—¶é—´ï¼Œvaluesä¸ºç›®æ ‡æ•°æ®çš„pd.DataFrame

    Raises
    ------
    `IOError`
        open,close,high,low,tr,sharenum,volume éƒ½ä¸º0æ—¶ï¼Œå°†æŠ¥é”™
    å¦ï¼šå¦‚æœæ•°æ®æœªæ›´æ–°ï¼Œå¯ä½¿ç”¨read_daily.clear_cache()æ¥æ¸…ç©ºç¼“å­˜
    """

    def read_mat(path):
        homeplace = HomePlace()
        col = list(
            scio.loadmat(homeplace.daily_data_file + "AllStockCode.mat").values()
        )[3]
        index = list(
            scio.loadmat(homeplace.daily_data_file + "TradingDate_Daily.mat").values()
        )[3]
        col = [i[0] for i in col[0]]
        index = index[0].tolist()
        path = homeplace.daily_data_file + path
        data = list(scio.loadmat(path).values())[3]
        data = pd.DataFrame(data, index=index, columns=col)
        data.index = pd.to_datetime(data.index, format="%Y%m%d")
        data = data.replace(0, np.nan)
        data = data[data.index >= pd.Timestamp(str(start))]
        return data

    if not unadjust:
        if path:
            return read_mat(path)
        elif open:
            trs = read_mat("AllStock_DailyTR.mat")
            opens = read_mat("AllStock_DailyOpen_dividend.mat")
            return opens
        elif close:
            trs = read_mat("AllStock_DailyTR.mat")
            closes = read_mat("AllStock_DailyClose_dividend.mat")
            return closes
        elif high:
            trs = read_mat("AllStock_DailyTR.mat")
            highs = read_mat("AllStock_DailyHigh_dividend.mat")
            return highs
        elif low:
            trs = read_mat("AllStock_DailyTR.mat")
            lows = read_mat("AllStock_DailyLow_dividend.mat")
            return lows
        elif tr:
            trs = read_mat("AllStock_DailyTR.mat")
            return trs
        elif sharenum:
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            return sharenums
        elif volume:
            volumes = read_mat("AllStock_DailyVolume.mat")
            return volumes
        elif age:
            age = read_mat("AllStock_DailyListedDate.mat")
            return age
        elif flow_cap:
            closes = read_mat("AllStock_DailyClose.mat")
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            flow_cap = closes * sharenums
            return flow_cap
        elif st:
            st = read_mat("AllStock_DailyST.mat")
            return st
        elif state:
            state = read_mat("AllStock_DailyStatus.mat")
            return state
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")
    else:
        if path:
            return read_mat(path)
        elif open:
            trs = read_mat("AllStock_DailyTR.mat")
            opens = read_mat("AllStock_DailyOpen.mat")
            return opens
        elif close:
            trs = read_mat("AllStock_DailyTR.mat")
            closes = read_mat("AllStock_DailyClose.mat")
            return closes
        elif high:
            trs = read_mat("AllStock_DailyTR.mat")
            highs = read_mat("AllStock_DailyHigh.mat")
            return highs
        elif low:
            trs = read_mat("AllStock_DailyTR.mat")
            lows = read_mat("AllStock_DailyLow.mat")
            return lows
        elif tr:
            trs = read_mat("AllStock_DailyTR.mat")
            return trs
        elif sharenum:
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            return sharenums
        elif volume:
            volumes = read_mat("AllStock_DailyVolume.mat")
            return volumes
        elif age:
            age = read_mat("AllStock_DailyListedDate.mat")
            return age
        elif flow_cap:
            closes = read_mat("AllStock_DailyClose.mat")
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            flow_cap = closes * sharenums
            return flow_cap
        elif st:
            st = read_mat("AllStock_DailyST.mat")
            return st
        elif state:
            state = read_mat("AllStock_DailyStatus.mat")
            return state
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")


def read_market(
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    start: int = STATES["START"],
    every_stock: bool = 1,
) -> Union[pd.DataFrame, pd.Series]:
    """è¯»å–ä¸­è¯å…¨æŒ‡æ—¥è¡Œæƒ…æ•°æ®

    Parameters
    ----------
    open : bool, optional
        è¯»å–å¼€ç›˜ç‚¹æ•°, by default 0
    close : bool, optional
        è¯»å–æ”¶ç›˜ç‚¹æ•°, by default 0
    high : bool, optional
        è¯»å–æœ€é«˜ç‚¹æ•°, by default 0
    low : bool, optional
        è¯»å–æœ€ä½ç‚¹æ•°, by default 0
    start : int, optional
        è¯»å–çš„èµ·å§‹æ—¥æœŸ, by default STATES["START"]
    every_stock : bool, optional
        æ˜¯å¦ä¿®æ”¹ä¸ºindexæ˜¯æ—¶é—´ï¼Œcolumnsæ˜¯æ¯åªè‚¡ç¥¨ä»£ç ï¼Œæ¯ä¸€åˆ—å€¼éƒ½ç›¸åŒçš„å½¢å¼, by default 1

    Returns
    -------
    Union[pd.DataFrame,pd.Series]
        ä¸­è¯å…¨æŒ‡æ¯å¤©çš„æŒ‡æ•°

    Raises
    ------
    IOError
        å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•æŒ‡æ•°ï¼Œå°†æŠ¥é”™
    """
    chc = ClickHouseClient("minute_data")
    df = chc.get_data(
        f"select * from minute_data.minute_data_index where code='000985.SH' and date>={start}00 order by date,num"
    )
    df = df.set_index("code")
    df = df / 100
    df = df.set_index("date")
    df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
    if open:
        # ç±³ç­çš„ç¬¬ä¸€åˆ†é’Ÿæ˜¯é›†åˆç«ä»·ï¼Œç¬¬ä¸€åˆ†é’Ÿçš„æ”¶ç›˜ä»·å³ä¸ºå½“å¤©å¼€ç›˜ä»·
        df = df[df.num == 1].close
    elif close:
        df = df[df.num == 240].close
    elif high:
        df = df[df.num > 1]
        df = df.groupby("date").max()
        df = df.high
    elif low:
        df = df[df.num > 1]
        df = df.groupby("date").min()
        df = df.low
    else:
        raise IOError("æ€»å¾—æŒ‡å®šä¸€ä¸ªæŒ‡æ ‡å§ï¼ŸğŸ¤’")
    if every_stock:
        tr = read_daily(tr=1, start=start)
        df = pd.DataFrame({k: list(df) for k in list(tr.columns)}, index=df.index)
    return df


def read_money_flow(
    buy: bool = 0,
    sell: bool = 0,
    exlarge: bool = 0,
    large: bool = 0,
    median: bool = 0,
    small: bool = 0,
) -> pd.DataFrame:
    """ä¸€é”®è¯»å…¥èµ„é‡‘æµå‘æ•°æ®ï¼ŒåŒ…æ‹¬è¶…å¤§å•ã€å¤§å•ã€ä¸­å•ã€å°å•çš„ä¹°å…¥å’Œå–å‡ºæƒ…å†µ

    Parameters
    ----------
    buy : bool, optional
        æ–¹å‘ä¸ºä¹°, by default 0
    sell : bool, optional
        æ–¹å‘ä¸ºå–, by default 0
    exlarge : bool, optional
        è¶…å¤§å•ï¼Œé‡‘é¢å¤§äº100ä¸‡ï¼Œä¸ºæœºæ„æ“ä½œ, by default 0
    large : bool, optional
        å¤§å•ï¼Œé‡‘é¢åœ¨20ä¸‡åˆ°100ä¸‡ä¹‹é—´ï¼Œä¸ºå¤§æˆ·ç‰¹å¤§å•, by default 0
    median : bool, optional
        ä¸­å•ï¼Œé‡‘é¢åœ¨4ä¸‡åˆ°20ä¸‡ä¹‹é—´ï¼Œä¸ºä¸­æˆ·å¤§å•, by default 0
    small : bool, optional
        å°å•ï¼Œé‡‘é¢åœ¨4ä¸‡ä»¥ä¸‹ï¼Œä¸ºæ•£æˆ·ä¸­å•, by default 0

    Returns
    -------
    pd.DataFrame
        indexä¸ºæ—¶é—´ï¼Œcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œvaluesä¸ºå¯¹åº”ç±»å‹è®¢å•å½“æ—¥çš„æˆäº¤é‡‘é¢

    Raises
    ------
    IOError
        buyå’Œsellå¿…é¡»æŒ‡å®šä¸€ä¸ªï¼Œå¦åˆ™ä¼šæŠ¥é”™
    IOError
        exlargeï¼Œlargeï¼Œmedianå’Œsmallå¿…é¡»æŒ‡å®šä¸€ä¸ªï¼Œå¦åˆ™ä¼šæŠ¥é”™
    """
    if buy:
        if exlarge:
            name = "buy_value_exlarge"
        elif large:
            name = "buy_value_large"
        elif median:
            name = "buy_value_med"
        elif small:
            name = "buy_value_small"
        else:
            raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ç§è§„æ¨¡å§ï¼ŸğŸ¤’")
    elif sell:
        if exlarge:
            name = "sell_value_exlarge"
        elif large:
            name = "sell_value_large"
        elif median:
            name = "sell_value_med"
        elif small:
            name = "sell_value_small"
        else:
            raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ç§è§„æ¨¡å§ï¼ŸğŸ¤’")
    else:
        raise IOError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸‹æ˜¯ä¹°è¿˜æ˜¯å–å§ï¼ŸğŸ¤’")
    name = homeplace.daily_data_file + name + ".feather"
    df = pd.read_feather(name).set_index("date")
    return df


def read_index_three(day: int = None) -> tuple[pd.DataFrame]:
    """è¯»å–ä¸‰å¤§æŒ‡æ•°çš„åŸå§‹è¡Œæƒ…æ•°æ®ï¼Œè¿”å›å¹¶ä¿å­˜åœ¨æœ¬åœ°

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None

    Returns
    -------
    `tuple[pd.DataFrame]`
        åˆ†åˆ«è¿”å›æ²ªæ·±300ã€ä¸­è¯500ã€ä¸­è¯1000çš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    res = pd.read_feather(homeplace.daily_data_file + "3510è¡Œæƒ….feather").set_index(
        "date"
    )
    hs300, zz500, zz1000 = res.æ²ªæ·±300, res.ä¸­è¯500, res.ä¸­è¯1000
    hs300 = hs300[hs300.index >= pd.Timestamp(str(day))]
    zz500 = zz500[zz500.index >= pd.Timestamp(str(day))]
    zz1000 = zz1000[zz1000.index >= pd.Timestamp(str(day))]

    def to_one(df):
        df = df / df.iloc[0]
        return df

    w = pd.ExcelWriter("3510åŸå§‹è¡Œæƒ….xlsx")
    hs300.to_excel(w, sheet_name="300")
    zz500.to_excel(w, sheet_name="500")
    zz1000.to_excel(w, sheet_name="1000")
    w.save()
    w.close()
    return hs300, zz500, zz1000


def read_swindustry_prices(
    day: int = None, monthly: bool = 1, start: int = STATES["START"]
) -> pd.DataFrame:
    """è¯»å–ç”³ä¸‡ä¸€çº§è¡Œä¸šæŒ‡æ•°çš„æ—¥è¡Œæƒ…æˆ–æœˆè¡Œæƒ…

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None
    monthly : bool, optional
        æ˜¯å¦ä¸ºæœˆè¡Œæƒ…, by default 1

    Returns
    -------
    `pd.DataFrame`
        ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    df = pd.read_feather(homeplace.daily_data_file + "ç”³ä¸‡å„è¡Œä¸šè¡Œæƒ…æ•°æ®.feather").set_index(
        "date"
    )
    df = df[df.index >= pd.Timestamp(str(start))]
    if monthly:
        df = df.resample("M").last()
    return df


def read_zxindustry_prices(
    day: int = None, monthly: bool = 1, start: int = STATES["START"]
) -> pd.DataFrame:
    """è¯»å–ä¸­ä¿¡ä¸€çº§è¡Œä¸šæŒ‡æ•°çš„æ—¥è¡Œæƒ…æˆ–æœˆè¡Œæƒ…

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None
    monthly : bool, optional
        æ˜¯å¦ä¸ºæœˆè¡Œæƒ…, by default 1

    Returns
    -------
    `pd.DataFrame`
        ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    df = pd.read_feather(homeplace.daily_data_file + "ä¸­ä¿¡å„è¡Œä¸šè¡Œæƒ…æ•°æ®.feather").set_index(
        "date"
    )
    df = df[df.index >= pd.Timestamp(str(start))]
    if monthly:
        df = df.resample("M").last()
    return df


def get_industry_dummies(
    daily: bool = 0, monthly: bool = 0, start: int = STATES["START"]
) -> dict:
    """ç”Ÿæˆ31ä¸ªè¡Œä¸šçš„å“‘å˜é‡çŸ©é˜µï¼Œè¿”å›ä¸€ä¸ªå­—å…¸

    Parameters
    ----------
    daily : bool, optional
        è¿”å›æ—¥é¢‘çš„å“‘å˜é‡, by default 0
    monthly : bool, optional
        è¿”å›æœˆé¢‘çš„å“‘å˜é‡, by default 0

    Returns
    -------
    `dict`
        å„ä¸ªè¡Œä¸šåŠå…¶å“‘å˜é‡æ„æˆçš„å­—å…¸

    Raises
    ------
    `ValueError`
        å¦‚æœæœªæŒ‡å®šé¢‘ç‡ï¼Œå°†æŠ¥é”™
    """
    homeplace = HomePlace()
    if monthly:
        industry_dummy = pd.read_feather(
            homeplace.daily_data_file + "ç”³ä¸‡è¡Œä¸š2021ç‰ˆå“‘å˜é‡.feather"
        )
        industry_dummy = (
            industry_dummy.set_index("date")
            .groupby("code")
            .resample("M")
            .last()
            .fillna(0)
            .drop(columns=["code"])
            .reset_index()
        )
    elif daily:
        industry_dummy = pd.read_feather(
            homeplace.daily_data_file + "ç”³ä¸‡è¡Œä¸š2021ç‰ˆå“‘å˜é‡.feather"
        ).fillna(0)
    else:
        raise ValueError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸ªé¢‘ç‡å§ï¼ŸğŸ¤’")
    industry_dummy = industry_dummy[industry_dummy.date >= pd.Timestamp(str(start))]
    ws = list(industry_dummy.columns)[2:]
    ress = {}
    for w in ws:
        df = industry_dummy[["date", "code", w]]
        df = df.pivot(index="date", columns="code", values=w)
        df = df.replace(0, np.nan)
        ress[w] = df
    return ress


def database_read_final_factors(
    name: str = None, order: int = None, output: bool = 0, new: bool = 0
) -> tuple[pd.DataFrame, str]:
    """æ ¹æ®å› å­åå­—ï¼Œæˆ–å› å­åºå·ï¼Œè¯»å–æœ€ç»ˆå› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None
    order : int, optional
        å› å­çš„åºå·, by default None
    output : bool, optional
        æ˜¯å¦è¾“å‡ºåˆ°csvæ–‡ä»¶, by default 0
    new : bool, optional
        æ˜¯å¦åªè¾“å‡ºæœ€æ–°ä¸€æœŸçš„å› å­å€¼, by default 0

    Returns
    -------
    `tuple[pd.DataFrame,str]`
        æœ€ç»ˆå› å­å€¼å’Œæ–‡ä»¶è·¯å¾„
    """
    homeplace = HomePlace()
    facs = os.listdir(homeplace.final_factor_file)
    if name is None and order is None:
        raise IOError("è¯·æŒ‡å®šå› å­åå­—æˆ–è€…å› å­åºå·")
    elif name is None and order is not None:
        key = "å¤šå› å­" + str(order)
        ans = [i for i in facs if key in i][0]
    elif name is not None and name is None:
        key = name
        ans = [i for i in facs if key in i]
        if len(ans) > 0:
            ans = ans[0]
        else:
            raise IOError(f"æ‚¨åå­—è®°é”™äº†ï¼Œä¸å­˜åœ¨å«{name}çš„å› å­")
    else:
        key1 = name
        key2 = "å¤šå› å­" + str(order)
        ans1 = [i for i in facs if key1 in i]
        if len(ans1) > 0:
            ans1 = ans1[0]
        else:
            raise IOError(f"æ‚¨åå­—è®°é”™äº†ï¼Œä¸å­˜åœ¨å«{name}çš„å› å­")
        ans2 = [i for i in facs if key2 in i][0]
        if ans1 != ans2:
            ans = ans1
            logger.warning("æ‚¨è¾“å…¥çš„åå­—å’Œåºå·ä¸ä¸€è‡´ï¼Œæ€€ç–‘æ‚¨è®°é”™äº†åºå·ï¼Œç¨‹åºé»˜è®¤ä»¥åå­—ä¸ºå‡†äº†å“ˆ")
        else:
            ans = ans1
    path = homeplace.final_factor_file + ans
    df = pd.read_feather(path)
    df.columns = ["date"] + list(df.columns)[1:]
    df = df.set_index(["date"])
    df = df[sorted(list(df.columns))]
    final_date = df.index.max()
    final_date = datetime.datetime.strftime(final_date, "%Y%m%d")
    if output:
        if new:
            if os.path.exists(ans.split("_")[0]):
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            else:
                os.makedirs(ans.split("_")[0])
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            df.tail(1).T.to_csv(fac_name)
            logger.success(f"{final_date}çš„å› å­å€¼å·²ä¿å­˜")
        else:
            if os.path.exists(ans.split("_")[0]):
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­æˆªè‡³"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            else:
                os.makedirs(ans.split("_")[0])
                fac_name = (
                    ans.split("_")[0]
                    + "/"
                    + ans.split("_")[0]
                    + "å› å­æˆªè‡³"
                    + final_date
                    + "å› å­å€¼.csv"
                )
            df.to_csv(fac_name)
            logger.success(f"æˆªè‡³{final_date}çš„å› å­å€¼å·²ä¿å­˜")
        return df, fac_name
    else:
        return df, ""


def database_read_primary_factors(name: str = None) -> pd.DataFrame:
    """æ ¹æ®å› å­åå­—ï¼Œè¯»å–åˆçº§å› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None

    Returns
    -------
    `pd.DataFrame`
        åˆçº§å› å­çš„å› å­å€¼
    """
    homeplace = HomePlace()
    name = name + "_åˆçº§.feather"
    df = pd.read_feather(homeplace.factor_data_file + name)
    df = df.rename(columns={list(df.columns)[0]: "date"})
    df = df.set_index("date")
    df = df[sorted(list(df.columns))]
    return df
