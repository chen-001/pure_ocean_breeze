import os
import tqdm
import numpy as np
import pandas as pd
import scipy.io as scio
import statsmodels.formula.api as smf
from functools import partial, reduce
from collections import Iterable
import warnings
warnings.filterwarnings('ignore')
import datetime
from dateutil.relativedelta import relativedelta
import matplotlib.pyplot as plt
import plotly.express as pe
import plotly.io as pio
import scipy.stats as ss
from loguru import logger
import time
from functools import lru_cache,wraps
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
import h5py
from cachier import cachier
import pickle



class HomePlace(object):
    def __init__(self):
        user_file=os.path.expanduser('~')+'/'
        path_file=open(user_file+'paths.settings','rb')
        paths=pickle.load(path_file)
        self.__dict__=paths

class params_setter(object):
    '''ç”¨äºæ ‡æ³¨è®¾ç½®å‚æ•°éƒ¨åˆ†çš„è£…é¥°å™¨'''
    def __init__(self,slogan=None):
        if not slogan:
            slogan='è¿™æ˜¯è®¾ç½®å‚æ•°ç±»å‹çš„å‡½æ•°\n'
        self.slogan=slogan
        self.box={}

    def __call__(self,func):
        # func.__doc__=self.slogan+func.__doc__
        self.box[func.__name__]=func
        self.func=func

        def wrapper(*args,**kwargs):
            func(*args,**kwargs)
            logger.info(f'{func.__name__} has been called $ kind of params_setter')
        return wrapper

class main_process(object):
    '''ç”¨äºæ ‡è®°ä¸»é€»è¾‘è¿‡ç¨‹çš„è£…é¥°å™¨'''
    def __init__(self,slogan=None):
        if not slogan:
            slogan='è¿™æ˜¯ä¸»é€»è¾‘è¿‡ç¨‹çš„å‡½æ•°\n'
        self.slogan=slogan
        self.box={}

    def __call__(self,func):
        # func.__doc__=self.slogan+func.__doc__
        self.box[func.__name__]=func

        def wrapper(*args,**kwargs):
            func(*args,**kwargs)
            logger.success(f'{func.__name__} has been called $ kind of main_process')
        return wrapper

class tool_box(object):
    '''ç”¨äºæ ‡æ³¨å·¥å…·ç®±éƒ¨åˆ†çš„è£…é¥°å™¨'''
    def __init__(self,slogan=None):
        if not slogan:
            slogan='è¿™æ˜¯å·¥å…·ç®±çš„å‡½æ•°\n'
        self.slogan=slogan
        self.box={}

    def __call__(self,func):
        # func.__doc__=self.slogan+func.__doc__
        self.box[func.__name__]=func

        def wrapper(*args,**kwargs):
            res=func(*args,**kwargs)
            # logger.success(f'{func.__name__} has been called $ kind of tool_box')
            return res
        return wrapper

class history_remain(object):
    '''ç”¨äºå†å²é—ç•™éƒ¨åˆ†çš„è£…é¥°å™¨'''
    def __init__(self,slogan=None):
        if not slogan:
            slogan='è¿™æ˜¯å†å²é—ç•™çš„å‡½æ•°\n'
        self.slogan=slogan
        self.box={}

    def __call__(self,func):
        # func.__doc__=self.slogan+func.__doc__
        self.box[func.__name__]=func

        def wrapper(*args,**kwargs):
            func(*args,**kwargs)
            logger.success(f'{func.__name__} has been called $ kind of history_remain')
        return wrapper



@cachier()
def read_daily(path=None,open=0,close=0,high=0,low=0,tr=0,sharenum=0,volume=0,unadjust=0):
    '''è¯»å–æ—¥é¢‘æ•°æ®,ä½¿ç”¨read_daily.clear_cache()æ¥æ¸…ç©ºç¼“å­˜'''
    def read_mat(path):
        homeplace=HomePlace()
        col=list(scio.loadmat(homeplace.daily_data_file+'AllStockCode.mat').values())[3]
        index=list(scio.loadmat(homeplace.daily_data_file+'TradingDate_Daily.mat').values())[3]
        col=[i[0] for i in col[0]]
        index=index[0].tolist()
        path=homeplace.daily_data_file+path
        data=list(scio.loadmat(path).values())[3]
        data=pd.DataFrame(data,index=index,columns=col)
        data.index=pd.to_datetime(data.index,format='%Y%m%d')
        data=data.replace(0,np.nan)
        return data
    if not unadjust:
        if path:
            return read_mat(path)
        elif open:
            trs=read_mat('AllStock_DailyTR.mat')
            opens=read_mat('AllStock_DailyOpen_dividend.mat')
            return np.sign(trs)*opens
        elif close:
            trs=read_mat('AllStock_DailyTR.mat')
            closes=read_mat('AllStock_DailyClose_dividend.mat')
            return np.sign(trs)*closes
        elif high:
            trs=read_mat('AllStock_DailyTR.mat')
            highs=read_mat('AllStock_DailyHigh_dividend.mat')
            return np.sign(trs)*highs
        elif low:
            trs=read_mat('AllStock_DailyTR.mat')
            lows=read_mat('AllStock_DailyLow_dividend.mat')
            return np.sign(trs)*lows
        elif tr:
            trs=read_mat('AllStock_DailyTR.mat')
            return trs
        elif sharenum:
            sharenums=read_mat('AllStock_DailyAShareNum.mat')
            return sharenums
        elif volume:
            volumes=read_mat('AllStock_DailyVolume.mat')
            return volumes
        else:
            raise IOError('é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’')
    else:
        if path:
            return read_mat(path)
        elif open:
            trs=read_mat('AllStock_DailyTR.mat')
            opens=read_mat('AllStock_DailyOpen.mat')
            return np.sign(trs)*opens
        elif close:
            trs=read_mat('AllStock_DailyTR.mat')
            closes=read_mat('AllStock_DailyClose.mat')
            return np.sign(trs)*closes
        elif high:
            trs=read_mat('AllStock_DailyTR.mat')
            highs=read_mat('AllStock_DailyHigh.mat')
            return np.sign(trs)*highs
        elif low:
            trs=read_mat('AllStock_DailyTR.mat')
            lows=read_mat('AllStock_DailyLow.mat')
            return np.sign(trs)*lows
        elif tr:
            trs=read_mat('AllStock_DailyTR.mat')
            return trs
        elif sharenum:
            sharenums=read_mat('AllStock_DailyAShareNum.mat')
            return sharenums
        elif volume:
            volumes=read_mat('AllStock_DailyVolume.mat')
            return volumes
        else:
            raise IOError('é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’')

def read_market(full=False,wide=True,open=0,high=0,low=0,close=0,amount=0,money=0):
    '''è¯»å–windå…¨Aæ—¥è¡Œæƒ…ï¼Œå¦‚æœä¸ºfullï¼Œåˆ™ç›´æ¥è¿”å›åŸå§‹è¡¨æ ¼ï¼Œå¦‚æœfullä¸ºFalseï¼Œåˆ™è¿”å›éƒ¨åˆ†æ•°æ®
    å¦‚æœwideä¸ºTrueï¼Œåˆ™è¿”å›æ–¹é˜µå½¢å¼ï¼Œindexæ˜¯æ—¶é—´ï¼Œcolumnsæ˜¯è‚¡ç¥¨ä»£ç ï¼Œæ¯ä¸€åˆ—çš„æ•°æ®éƒ½ä¸€æ ·ï¼Œè¿™ä¹ˆåšæ˜¯æŒ‡ä¸ºäº†ä¾¿äºä¸ä¸ªè‚¡è¿ç®—'''
    market=pd.read_excel('/Users/chenzongwei/pythoncode/æ•°æ®åº“/æ—¥é¢‘æ•°æ®/windå…¨Aæ—¥è¡Œæƒ….xlsx')
    market=market.drop(columns=['ä»£ç ','åç§°'])
    market.columns=['date','open','high','low','close','amount','money']
    market.money=market.money*1000000
    if full:
        return market
    else:
        if wide:
            tr=read_daily(tr=1)
            tr=np.abs(np.sign(tr)).replace(1,0).fillna(0)
            if open:
                market=market[['date','open']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['open']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            elif high:
                market=market[['date','high']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['high']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            elif low:
                market=market[['date','low']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['date','low']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            elif close:
                market=market[['date','close']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['close']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            elif amount:
                market=market[['date','amount']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['amount']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            elif money:
                market=market[['date','money']]
                market.date=pd.to_datetime(market.date)
                market=market[market.date.isin(list(tr.index))]
                market=market.set_index('date')
                market=market['money']
                tr_one=tr.iloc[:,0]
                market=market+tr_one
                market=market.fillna(method='ffill')
                market=pd.DataFrame({k:list(market) for k in list(tr.columns)},index=tr.index)
            else:
                raise IOError('æ‚¨æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’')
            return market
        else:
            cols=[varname.nameof(i) for i in [open,high,low,close,amount,money] if i==1]
            market=market[['date']+cols]
            return market

def read_h5(path):
    '''è¯»å–h5æ–‡ä»¶ä¸­çš„æ‰€æœ‰å­—å…¸'''
    import tqdm
    import h5py
    import pandas as pd
    res={}
    a=h5py.File(path)
    for k,v in tqdm.tqdm(list(a.items()),desc='æ•°æ®åŠ è½½ä¸­â€¦â€¦'):
        value=list(v.values())[-1]
        col=[i.decode('utf-8') for i in list(list(v.values())[0])]
        ind=[i.decode('utf-8') for i in list(list(v.values())[1])]
        res[k]=pd.DataFrame(value,columns=col,index=ind)
    return res

def get_value(df,n):
    '''å¾ˆå¤šå› å­è®¡ç®—æ—¶ï¼Œä¼šä¸€æ¬¡æ€§ç”Ÿæˆå¾ˆå¤šå€¼ï¼Œä½¿ç”¨æ—¶åªå–å‡ºä¸€ä¸ªå€¼'''
    def get_value_single(x,n):
        try:
            return x[n]
        except Exception:
            return np.nan
    df=df.applymap(lambda x:get_value_single(x,n))
    return df

def comment_on_rets_and_nets(rets,nets,name):
    '''
    è¾“å…¥æ”¶ç›Šç‡åºåˆ—å’Œå‡€å€¼åºåˆ—ï¼Œè¾“å‡ºå¹´åŒ–æ”¶ç›Šã€å¹´åŒ–æ³¢åŠ¨ã€ä¿¡æ¯æ¯”ç‡ã€æœˆåº¦èƒœç‡å’Œæœ€å¤§å›æ’¤ç‡
    è¾“å…¥2ä¸ªpd.Seriesï¼Œæ—¶é—´æ˜¯ç´¢å¼•
    '''
    duration_nets=(nets.index[-1]-nets.index[0]).days
    year_nets=duration_nets/365
    ret_yearly=(nets.iloc[-1]/nets.iloc[0])**(1/year_nets)-1
    max_draw=((nets.cummax()-nets)/nets.cummax()).max()
    vol=np.std(rets)*(12**0.5)
    info_rate=ret_yearly/vol
    win_rate=len(rets[rets>0])/len(rets)
    comments=pd.DataFrame({
        'å¹´åŒ–æ”¶ç›Šç‡':ret_yearly,'å¹´åŒ–æ³¢åŠ¨ç‡':vol,'ä¿¡æ¯æ¯”ç‡':info_rate,'æœˆåº¦èƒœç‡':win_rate,'æœ€å¤§å›æ’¤ç‡':max_draw
    },index=[name]).T
    return comments

def comments_on_twins(series,series1):
    '''å¯¹twinsä¸­çš„ç»“æœç»™å‡ºè¯„ä»·
    è¯„ä»·æŒ‡æ ‡åŒ…æ‹¬å¹´åŒ–æ”¶ç›Šç‡ã€æ€»æ”¶ç›Šç‡ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€å¹´åŒ–å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ç‡ã€èƒœç‡'''
    ret=(series.iloc[-1]-series.iloc[0])/series.iloc[0]
    duration=(series.index[-1]-series.index[0]).days
    year=duration/365
    ret_yearly=(series.iloc[-1]/series.iloc[0])**(1/year)-1
    max_draw=-(series/series.expanding(1).max()-1).min()
    vol=np.std(series1)*(12**0.5)
    sharpe=ret_yearly/vol
    wins=series1[series1>0]
    win_rate=len(wins)/len(series1)
    return pd.Series([ret,ret_yearly,vol,sharpe,max_draw,win_rate],
                     index=['æ€»æ”¶ç›Šç‡','å¹´åŒ–æ”¶ç›Šç‡','å¹´åŒ–æ³¢åŠ¨ç‡','ä¿¡æ¯æ¯”ç‡','æœ€å¤§å›æ’¤ç‡','èƒœç‡'])

def daily_factor_on300500(fac,hs300=False,zz500=False):
    '''è¾“å…¥æ—¥é¢‘å› å­ï¼ŒæŠŠæ—¥é¢‘å› å­å˜ä¸ºä»…åœ¨300æˆ–è€…500ä¸Šçš„è‚¡ç¥¨æ± '''
    if hs300:
        df=pd.read_feather('/Users/chenzongwei/pythoncode/æ•°æ®åº“/æ²ªæ·±300æˆåˆ†è‚¡.feather').set_index('date')
        df=df*fac
        df=df.dropna(how='all')
    elif zz500:
        df=pd.read_feather('/Users/chenzongwei/pythoncode/æ•°æ®åº“/ä¸­è¯500æˆåˆ†è‚¡.feather').set_index('date')
        df=df*fac
        df=df.dropna(how='all')
    return df

def select_max(df1,df2):
    '''ä¸¤ä¸ªcolumnsä¸indexå®Œå…¨ç›¸åŒçš„dfï¼Œæ¯ä¸ªå€¼éƒ½æŒ‘å‡ºè¾ƒå¤§å€¼'''
    return (df1+df2+np.abs(df1-df2))/2

def select_min(df1,df2):
    '''ä¸¤ä¸ªcolumnsä¸indexå®Œå…¨ç›¸åŒçš„dfï¼Œæ¯ä¸ªå€¼éƒ½æŒ‘å‡ºè¾ƒå°å€¼'''
    return (df1+df2-np.abs(df1-df2))/2

def decap(df,daily=False,monthly=False):
    '''åšå¸‚å€¼ä¸­æ€§åŒ–'''
    tqdm.tqdm.pandas()
    share=read_daily('AllStock_DailyAShareNum.mat')
    undi_close=read_daily('AllStock_DailyClose.mat')
    cap=(share*undi_close).stack().reset_index()
    cap.columns=['date','code','cap']
    cap.cap=ss.boxcox(cap.cap)[0]
    def single(x):
        x.cap=ss.boxcox(x.cap)[0]
        return x
    cap=cap.groupby(['date']).apply(single)
    cap=cap.set_index(['date','code']).unstack()
    cap.columns=[i[1] for i in list(cap.columns)]
    cap_monthly=cap.resample('M').last()
    last=df.resample('M').last()
    if df.shape[0]/last.shape[0]<2:
        monthly=True
    else:
        daily=True
    if daily:
        df=(pure_fallmount(df)-(pure_fallmount(cap),))()
    elif monthly:
        df=(pure_fallmount(df)-(pure_fallmount(cap_monthly),))()
    else:
        raise NotImplementedError('å¿…é¡»æŒ‡å®šé¢‘ç‡')
    return df

def boom_four(df,minus=None,backsee=20):
    '''ä½¿ç”¨20å¤©å‡å€¼å’Œæ ‡å‡†å·®ï¼Œç”Ÿæˆ4ä¸ªå› å­'''
    df_mean=df.rolling(backsee).mean().resample('M').last()
    df_std=df.rolling(backsee).std().resample('M').last()
    twins_add=(pure_fallmount(df_mean)+(pure_fallmount(df_std),))()
    rtwins_add=df_mean.rank(axis=1)+df_std.rank(axis=1)
    twins_minus=(pure_fallmount(df_mean)+(pure_fallmount(-df_std),))()
    rtwins_minus=df_mean.rank(axis=1)-df_std.rank(axis=1)
    return df_mean,df_std,twins_add,rtwins_add,twins_minus,rtwins_minus

def get_abs(df,median=False,square=False):
    '''ç”Ÿäº§å› å­æˆªé¢ä¸Šè·ç¦»å‡å€¼çš„è·ç¦»'''
    if not square:
        if median:
            return np.abs((df.T-df.T.median()).T)
        else:
            return np.abs((df.T-df.T.mean()).T)
    else:
        if median:
            return ((df.T-df.T.median()).T)**2
        else:
            return ((df.T-df.T.mean()).T)**2

def add_cross_standardlize(*args):
    '''å°†ä¼—å¤šå› å­æ¨ªæˆªé¢æ ‡å‡†åŒ–ä¹‹åç›¸åŠ '''
    fms=[pure_fallmount(i) for i in args]
    one=fms[0]
    others=fms[1:]
    final=one+others
    return final()

class pure_moon():
    __slots__=[
        'homeplace'
        'path_prefix',
        'codes_path',
        'tradedays_path',
        'ages_path',
        'sts_path',
        'states_path',
        'opens_path',
        'closes_path',
        'highs_path',
        'lows_path',
        'pricloses_path',
        'flowshares_path',
        'amounts_path',
        'turnovers_path',
        'factors_file',
        'sts_monthly_file',
        'states_monthly_file',
        'sts_monthly_by10_file',
        'states_monthly_by10_file',
        'factors',
        'codes',
        'tradedays',
        'ages',
        'amounts',
        'closes',
        'flowshares',
        'highs',
        'lows',
        'opens',
        'pricloses',
        'states',
        'sts',
        'turnovers',
        'sts_monthly',
        'states_monthly',
        'ages_monthly',
        'tris_monthly',
        'opens_monthly',
        'closes_monthly',
        'rets_monthly',
        'opens_monthly_shift',
        'rets_monthly_begin',
        'limit_ups',
        'limit_downs',
        'data',
        'ic_icir_and_rank',
        'rets_monthly_limit_downs',
        'group_rets',
        'long_short_rets',
        'long_short_net_values',
        'group_net_values',
        'long_short_ret_yearly',
        'long_short_vol_yearly',
        'long_short_info_ratio',
        'long_short_win_times',
        'long_short_win_ratio',
        'retreats',
        'max_retreat',
        'long_short_comments',
        'total_comments',
        'square_rets',
        'cap',
        'cap_value'
    ]

    @classmethod
    @lru_cache(maxsize=None)
    def __init__(cls):
        now=datetime.datetime.now()
        now=datetime.datetime.strftime(now,format='%Y-%m-%d %H:%M:%S')
        cls.homeplace=HomePlace()
        # logger.add('pure_moon'+now+'.log')
        # ç»å¯¹è·¯å¾„å‰ç¼€
        cls.path_prefix = cls.homeplace.daily_data_file
        # è‚¡ç¥¨ä»£ç æ–‡ä»¶
        cls.codes_path = 'AllStockCode.mat'
        # äº¤æ˜“æ—¥æœŸæ–‡ä»¶
        cls.tradedays_path = 'TradingDate_Daily.mat'
        # ä¸Šå¸‚å¤©æ•°æ–‡ä»¶
        cls.ages_path = 'AllStock_DailyListedDate.mat'
        # stæ—¥å­æ ‡å¿—æ–‡ä»¶
        cls.sts_path = 'AllStock_DailyST.mat'
        # äº¤æ˜“çŠ¶æ€æ–‡ä»¶
        cls.states_path = 'AllStock_DailyStatus.mat'
        # å¤æƒå¼€ç›˜ä»·æ•°æ®æ–‡ä»¶
        cls.opens_path = 'AllStock_DailyOpen_dividend.mat'
        # å¤æƒæ”¶ç›˜ä»·æ•°æ®æ–‡ä»¶
        cls.closes_path = 'AllStock_DailyClose_dividend.mat'
        #å¤æƒæœ€é«˜ä»·æ•°æ®æ–‡ä»¶
        cls.highs_path = 'Allstock_DailyHigh_dividend.mat'
        #å¤æƒæœ€ä½ä»·æ•°æ®æ–‡ä»¶
        cls.lows_path = 'Allstock_DailyLow_dividend.mat'
        # ä¸å¤æƒæ”¶ç›˜ä»·æ•°æ®æ–‡ä»¶
        cls.pricloses_path = 'AllStock_DailyClose.mat'
        # æµé€šè‚¡æœ¬æ•°æ®æ–‡ä»¶
        cls.flowshares_path = 'AllStock_DailyAShareNum.mat'
        # æˆäº¤é‡æ•°æ®æ–‡ä»¶
        cls.amounts_path = 'AllStock_DailyVolume.mat'
        # æ¢æ‰‹ç‡æ•°æ®æ–‡ä»¶
        cls.turnovers_path = 'AllStock_DailyTR.mat'
        # å› å­æ•°æ®æ–‡ä»¶
        cls.factors_file = ''
        # å·²ç»ç®—å¥½çš„æœˆåº¦stçŠ¶æ€æ–‡ä»¶
        cls.sts_monthly_file = 'sts_monthly.feather'
        # å·²ç»ç®—å¥½çš„æœˆåº¦äº¤æ˜“çŠ¶æ€æ–‡ä»¶
        cls.states_monthly_file = 'states_monthly.feather'
        # å·²ç»ç®—å¥½çš„æœˆåº¦st_by10çŠ¶æ€æ–‡ä»¶
        cls.sts_monthly_by10_file = 'sts_monthly_by10.feather'
        # å·²ç»ç®—å¥½çš„æœˆåº¦äº¤æ˜“çŠ¶æ€æ–‡ä»¶
        cls.states_monthly_by10_file = 'states_monthly_by10.feather'
        # æ‹¼æ¥ç»å¯¹è·¯å¾„å‰ç¼€å’Œç›¸å¯¹è·¯å¾„
        dirs = dir(cls)
        dirs.remove('new_path')
        dirs.remove('set_factor_file')
        dirs = [i for i in dirs if i.endswith('path')] + [i for i in dirs if i.endswith('file')]
        dirs_values = list(map(lambda x, y: getattr(x, y), [cls] * len(dirs), dirs))
        dirs_values = list(map(lambda x, y: x + y, [cls.path_prefix] * len(dirs), dirs_values))
        for attr, value in zip(dirs, dirs_values):
            setattr(cls, attr, value)

    def __call__(self, fallmount=0):
        '''è°ƒç”¨å¯¹è±¡åˆ™è¿”å›å› å­å€¼'''
        df=self.factors.copy()
        df=df.set_index(['date', 'code']).unstack()
        df.columns=list(map(lambda x:x[1],list(df.columns)))
        if fallmount == 0:
            return df
        else:
            return pure_fallmount(df)

    @params_setter(slogan=None)
    # @lru_cache(maxsize=None)
    def set_factor_file(self, factors_file):
        '''è®¾ç½®å› å­æ–‡ä»¶çš„è·¯å¾„ï¼Œå› å­æ–‡ä»¶åˆ—ååº”ä¸ºè‚¡ç¥¨ä»£ç ï¼Œç´¢å¼•ä¸ºæ—¶é—´'''
        self.factors_file = factors_file
        self.factors = pd.read_feather(self.factors_file)
        self.factors = self.factors.set_index('date')
        self.factors = self.factors.resample('M').last()
        self.factors = self.factors.reset_index()

    @params_setter(slogan=None)
    # @lru_cache(maxsize=None)
    def set_factor_df_date_as_index(self, df):
        '''è®¾ç½®å› å­æ•°æ®çš„dataframeï¼Œå› å­è¡¨åˆ—ååº”ä¸ºè‚¡ç¥¨ä»£ç ï¼Œç´¢å¼•åº”ä¸ºæ—¶é—´'''
        df = df.reset_index()
        df.columns = ['date'] + list(df.columns)[1:]
        # df.date=df.date.apply(self.next_month_end)
        # df=df.set_index('date')
        self.factors = df
        self.factors = self.factors.set_index('date')
        self.factors = self.factors.resample('M').last()
        self.factors = self.factors.reset_index()

    @params_setter(slogan=None)
    # @lru_cache(maxsize=None)
    def set_factor_df_wide(self, df):
        '''ä»dataframeè¯»å…¥å› å­å®½æ•°æ®'''
        if isinstance(df,pure_fallmount):
            df=df()
        self.factors = df.copy()
        # self.factors.date=self.factors.date.apply(self.next_month_end)
        # self.factors=self.factors.set_index('date')
        self.factors = self.factors.set_index('date')
        self.factors = self.factors.resample('M').last()
        self.factors = self.factors.reset_index()

    # def set_factor_df_long(self,df):
    #     '''ä»dataframeè¯»å…¥å› å­é•¿æ•°æ®'''
    #     self.factors=df
    #     self.factors.columns=['date','code','fac']

    @classmethod
    @lru_cache(maxsize=None)
    @history_remain(slogan=None)
    def new_path(cls, **kwargs):
        '''ä¿®æ”¹æ—¥é¢‘æ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼Œä¾¿äºæ›´æ–°æ•°æ®
        è¦ä¿®æ”¹çš„è·¯å¾„ä»¥å­—å…¸å½¢å¼ä¼ å…¥ï¼Œé”®ä¸ºå±æ€§åï¼Œå€¼ä¸ºè¦è®¾ç½®çš„æ–°è·¯å¾„'''
        for key, value in kwargs.items():
            setattr(cls, key, value)

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def col_and_index(cls):
        '''è¯»å–è‚¡ç¥¨ä»£ç ï¼Œä½œä¸ºæœªæ¥è¡¨æ ¼çš„è¡Œå
        è¯»å–äº¤æ˜“æ—¥å†ï¼Œä½œä¸ºæœªæ¥è¡¨æ ¼çš„ç´¢å¼•'''
        cls.codes = list(scio.loadmat(cls.codes_path).values())[3]
        cls.tradedays = list(scio.loadmat(cls.tradedays_path).values())[3].astype(str)
        cls.codes = cls.codes.flatten().tolist()
        # cls.tradedays = cls.tradedays.flatten().tolist()
        cls.codes = list(map(lambda x: x[0], cls.codes))
        cls.tradedays=cls.tradedays[0].tolist()

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def loadmat(cls, path):
        '''é‡å†™ä¸€ä¸ªåŠ è½½matæ–‡ä»¶çš„å‡½æ•°ï¼Œä»¥ä½¿ä»£ç æ›´ç®€æ´'''
        return list(scio.loadmat(path).values())[3]

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def make_df(cls, data):
        '''å°†è¯»å…¥çš„æ•°æ®ï¼Œå’Œè‚¡ç¥¨ä»£ç ä¸æ—¶é—´æ‹¼æ¥ï¼Œåšæˆdataframe'''
        data = pd.DataFrame(data, columns=cls.codes, index=cls.tradedays)
        data.index = pd.to_datetime(data.index, format='%Y%m%d')
        return data

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def load_all_files(cls):
        '''åŠ å…¨éƒ¨çš„matæ–‡ä»¶'''
        attrs = dir(cls)
        attrs = [i for i in attrs if i.endswith('path')]
        attrs.remove('codes_path')
        attrs.remove('tradedays_path')
        attrs.remove('new_path')
        for attr in attrs:
            new_attr = attr[:-5]
            setattr(cls, new_attr, cls.make_df(cls.loadmat(getattr(cls, attr))))
        cls.opens = cls.opens.replace(0, np.nan)
        cls.closes = cls.closes.replace(0, np.nan)
        cls.pricloses_copy=cls.pricloses.copy()
        cls.flowshares_copy=cls.flowshares.copy()

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def judge_month_st(cls, df):
        '''æ¯”è¾ƒä¸€ä¸ªæœˆå†…stçš„å¤©æ•°ï¼Œå¦‚æœstå¤©æ•°å¤šï¼Œå°±åˆ é™¤æœ¬æœˆï¼Œå¦‚æœæ­£å¸¸å¤šï¼Œå°±ä¿ç•™æœ¬æœˆ'''
        st_count = len(df[df == 1])
        normal_count = len(df[df != 1])
        if st_count >= normal_count:
            return 0
        else:
            return 1

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def judge_month_st_by10(cls, df):
        '''æ¯”è¾ƒä¸€ä¸ªæœˆå†…æ­£å¸¸äº¤æ˜“çš„å¤©æ•°ï¼Œå¦‚æœå°‘äº10å¤©ï¼Œå°±åˆ é™¤æœ¬æœˆ'''
        normal_count = len(df[df != 1])
        if normal_count < 10:
            return 0
        else:
            return 1

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def judge_month_state(cls, df):
        '''æ¯”è¾ƒä¸€ä¸ªæœˆå†…éæ­£å¸¸äº¤æ˜“çš„å¤©æ•°ï¼Œå¦‚æœéæ­£å¸¸äº¤æ˜“å¤©æ•°å¤šï¼Œå°±åˆ é™¤æœ¬æœˆï¼Œå¦åˆ™ä¿ç•™æœ¬æœˆ'''
        abnormal_count = len(df[df == 0])
        normal_count = len(df[df == 1])
        if abnormal_count >= normal_count:
            return 0
        else:
            return 1

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def judge_month_state_by10(cls, df):
        '''æ¯”è¾ƒä¸€ä¸ªæœˆå†…æ­£å¸¸äº¤æ˜“å¤©æ•°ï¼Œå¦‚æœå°‘äº10å¤©ï¼Œå°±åˆ é™¤æœ¬æœˆ'''
        normal_count = len(df[df == 1])
        if normal_count < 10:
            return 0
        else:
            return 1

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def read_add(cls, pridf, df, func):
        '''ç”±äºæ•°æ®æ›´æ–°ï¼Œè¿‡å»è®¡ç®—çš„æœˆåº¦çŠ¶æ€å¯èƒ½éœ€è¦è¿½åŠ '''
        logger.info(f'this is max_index of pridf{pridf.index.max()}')
        logger.info(f'this is max_index of df{df.index.max()}')
        if pridf.index.max() > df.index.max():
            df_add = pridf[pridf.index > df.index.max()]
            df_add = df_add.resample('M').apply(func)
            df = pd.concat([df, df_add])
            return df
        else:
            return df

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def write_feather(cls, df, path):
        '''å°†ç®—å‡ºæ¥çš„æ•°æ®å­˜å…¥æœ¬åœ°ï¼Œä»¥å…é€ æˆé‡å¤è¿ç®—'''
        df1 = df.copy()
        df1 = df1.reset_index()
        df1.to_feather(path)

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def daily_to_monthly(cls, pridf, path, func):
        '''æŠŠæ—¥åº¦çš„äº¤æ˜“çŠ¶æ€ã€stã€ä¸Šå¸‚å¤©æ•°ï¼Œè½¬åŒ–ä¸ºæœˆåº¦çš„ï¼Œå¹¶ç”Ÿæˆèƒ½å¦äº¤æ˜“çš„åˆ¤æ–­
        è¯»å–æœ¬åœ°å·²ç»ç®—å¥½çš„æ–‡ä»¶ï¼Œå¹¶è¿½åŠ æ–°çš„æ—¶é—´æ®µéƒ¨åˆ†ï¼Œå¦‚æœæœ¬åœ°æ²¡æœ‰å°±ç›´æ¥å…¨éƒ¨é‡æ–°ç®—'''
        try:
            logger.info('try to read the prepared state file')
            month_df = pd.read_feather(path).set_index('index')
            logger.info('state file load success')
            month_df = cls.read_add(pridf, month_df, func)
            logger.info('adding after state file has finish')
            cls.write_feather(month_df, path)
            logger.info('the feather is new now')
        except Exception as e:
            logger.error('error occurs when read state files')
            logger.error(e)
            print('state file rewritingâ€¦â€¦')
            month_df = pridf.resample('M').apply(func)
            cls.write_feather(month_df, path)
        return month_df

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def daily_to_monthly_by10(cls, pridf, path, func):
        '''æŠŠæ—¥åº¦çš„äº¤æ˜“çŠ¶æ€ã€stã€ä¸Šå¸‚å¤©æ•°ï¼Œè½¬åŒ–ä¸ºæœˆåº¦çš„ï¼Œå¹¶ç”Ÿæˆèƒ½å¦äº¤æ˜“çš„åˆ¤æ–­
        è¯»å–æœ¬åœ°å·²ç»ç®—å¥½çš„æ–‡ä»¶ï¼Œå¹¶è¿½åŠ æ–°çš„æ—¶é—´æ®µéƒ¨åˆ†ï¼Œå¦‚æœæœ¬åœ°æ²¡æœ‰å°±ç›´æ¥å…¨éƒ¨é‡æ–°ç®—'''
        try:
            month_df = pd.read_feather(path).set_index('date')
            month_df = cls.read_add(pridf, month_df, func)
            cls.write_feather(month_df, path)
        except Exception:
            print('rewriting')
            month_df = pridf.resample('M').apply(func)
            cls.write_feather(month_df, path)
        return month_df

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def judge_month(cls):
        '''ç”Ÿæˆä¸€ä¸ªæœˆç»¼åˆåˆ¤æ–­çš„è¡¨æ ¼'''
        cls.sts_monthly = cls.daily_to_monthly(cls.sts, cls.sts_monthly_file, cls.judge_month_st)
        cls.states_monthly = cls.daily_to_monthly(cls.states, cls.states_monthly_file, cls.judge_month_state)
        cls.ages_monthly = cls.ages.resample('M').last()
        cls.ages_monthly = np.sign(cls.ages_monthly.applymap(lambda x: x - 60)).replace(-1, 0)
        cls.tris_monthly = cls.sts_monthly * cls.states_monthly * cls.ages_monthly
        cls.tris_monthly = cls.tris_monthly.replace(0, np.nan)

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def judge_month_by10(cls):
        '''ç”Ÿæˆä¸€ä¸ªæœˆç»¼åˆåˆ¤æ–­çš„è¡¨æ ¼'''
        cls.sts_monthly = cls.daily_to_monthly(cls.sts, cls.sts_monthly_by10_file, cls.judge_month_st_by10)
        cls.states_monthly = cls.daily_to_monthly(cls.states, cls.states_monthly_by10_file,
                                                    cls.judge_month_state_by10)
        cls.ages_monthly = cls.ages.resample('M').last()
        cls.ages_monthly = np.sign(cls.ages_monthly.applymap(lambda x: x - 60)).replace(-1, 0)
        cls.tris_monthly = cls.sts_monthly * cls.states_monthly * cls.ages_monthly
        cls.tris_monthly = cls.tris_monthly.replace(0, np.nan)

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_rets_month(cls):
        '''è®¡ç®—æ¯æœˆçš„æ”¶ç›Šç‡ï¼Œå¹¶æ ¹æ®æ¯æœˆåšå‡ºäº¤æ˜“çŠ¶æ€ï¼Œåšå‡ºåˆ å‡'''
        cls.opens_monthly = cls.opens.resample('M').first()
        cls.closes_monthly = cls.closes.resample('M').last()
        cls.rets_monthly = (cls.closes_monthly - cls.opens_monthly) / cls.opens_monthly
        cls.rets_monthly = cls.rets_monthly * cls.tris_monthly
        cls.rets_monthly = cls.rets_monthly.stack().reset_index()
        cls.rets_monthly.columns = ['date', 'code', 'ret']

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def neutralize_factors(cls, df):
        '''ç»„å†…å¯¹å› å­è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–'''
        ols_result = smf.ols('fac~cap_size', data=df).fit()
        ols_w = ols_result.params['cap_size']
        ols_b = ols_result.params['Intercept']
        df.fac = df.fac - ols_w * df.cap_size - ols_b
        df = df[['fac']]
        return df

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_log_cap(cls,boxcox=False):
        '''è·å¾—å¯¹æ•°å¸‚å€¼'''
        cls.pricloses = cls.pricloses.replace(0, np.nan)
        cls.flowshares = cls.flowshares.replace(0, np.nan)
        cls.pricloses = cls.pricloses.resample('M').last()
        cls.pricloses = cls.pricloses.stack().reset_index()
        cls.pricloses.columns = ['date', 'code', 'priclose']
        cls.flowshares = cls.flowshares.resample('M').last()
        cls.flowshares = cls.flowshares.stack().reset_index()
        cls.flowshares.columns = ['date', 'code', 'flowshare']
        cls.flowshares = pd.merge(cls.flowshares, cls.pricloses, on=['date', 'code'])
        cls.cap = cls.flowshares.assign(cap_size=cls.flowshares.flowshare * cls.flowshares.priclose)
        if boxcox:
            def single(x):
                x.cap_size=ss.boxcox(x.cap_size)[0]
                return x
            cls.cap=cls.cap.groupby(['date']).apply(single)
        else:
            cls.cap['cap_size'] = np.log(cls.cap['cap_size'])

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_neutral_factors(self):
        '''å¯¹å› å­è¿›è¡Œå¸‚å€¼ä¸­æ€§åŒ–'''
        self.factors = self.factors.set_index('date')
        self.factors.index=self.factors.index+pd.DateOffset(months=1)
        self.factors = self.factors.resample('M').last()
        self.factors = self.factors * self.tris_monthly
        self.factors = self.factors.reset_index()
        self.factors=self.factors.rename(columns={'index':'date'})
        vanish_top_time = self.factors.date.min()
        self.factors.date = self.factors.date.shift(1)
        vanish_top_time = vanish_top_time - pd.Timedelta(days=vanish_top_time.day)
        self.factors.date = self.factors.date.fillna(vanish_top_time)
        self.factors = self.factors.set_index('date')
        self.factors = self.factors.stack().reset_index()
        self.factors.columns = ['date', 'code', 'fac']
        self.factors = pd.merge(self.factors, self.cap, how='inner', on=['date', 'code'])
        self.factors = self.factors.set_index(['date', 'code'])
        self.factors = self.factors.groupby(['date']).apply(self.neutralize_factors)
        self.factors = self.factors.reset_index()

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def deal_with_factors(self):
        '''åˆ é™¤ä¸ç¬¦åˆäº¤æ˜“æ¡ä»¶çš„å› å­æ•°æ®'''
        self.factors = self.factors.set_index('date')
        self.factors.index=self.factors.index+pd.DateOffset(months=1)
        self.factors = self.factors.resample('M').last()
        self.factors = self.factors * self.tris_monthly
        self.factors = self.factors.stack().reset_index()
        self.factors.columns = ['date', 'code', 'fac']

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def deal_with_factors_after_neutralize(self):
        '''ä¸­æ€§åŒ–ä¹‹åçš„å› å­å¤„ç†æ–¹æ³•'''
        self.factors = self.factors.set_index(['date', 'code'])
        self.factors = self.factors.unstack()
        self.factors.index=self.factors.index+pd.DateOffset(months=1)
        self.factors = self.factors.resample('M').last()
        self.factors.columns = list(map(lambda x: x[1], list(self.factors.columns)))
        self.factors = self.factors.stack().reset_index()
        self.factors.columns = ['date', 'code', 'fac']

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def find_limit(cls, df, up=1):
        '''è®¡ç®—æ¶¨è·Œå¹…è¶…è¿‡9.8%çš„è‚¡ç¥¨ï¼Œå¹¶å°†å…¶å­˜å‚¨è¿›ä¸€ä¸ªé•¿åˆ—è¡¨é‡Œ
        å…¶ä¸­æ—¶é—´åˆ—ï¼Œä¸ºæŸæœˆçš„æœ€åä¸€å¤©ï¼›æ¶¨åœæ—¥è™½ç„¶ä¸ºä¸‹æœˆåˆç¬¬ä¸€å¤©ï¼Œä½†è¿™é‡Œæ ‡æ³¨çš„æ—¶é—´ç»Ÿä¸€ä¸ºä¸Šæœˆæœ€åä¸€å¤©'''
        limit_df = np.sign(df.applymap(lambda x: x - up * 0.098)).replace(-1 * up, np.nan)
        limit_df = limit_df.stack().reset_index()
        limit_df.columns = ['date', 'code', 'limit_up_signal']
        limit_df = limit_df[['date', 'code']]
        return limit_df

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_limit_ups_downs(cls):
        '''æ‰¾æœˆåˆç¬¬ä¸€å¤©å°±æ¶¨åœ'''
        '''æˆ–è€…æ˜¯æœˆæœ«è·Œåœçš„è‚¡ç¥¨'''
        cls.opens_monthly_shift = cls.opens_monthly.copy()
        cls.opens_monthly_shift = cls.opens_monthly_shift.shift(-1)
        cls.rets_monthly_begin = (cls.opens_monthly_shift - cls.closes_monthly) / cls.closes_monthly
        cls.closes2_monthly = cls.closes.shift(1).resample('M').last()
        cls.rets_monthly_last = (cls.closes_monthly - cls.closes2_monthly) / cls.closes2_monthly
        cls.limit_ups = cls.find_limit(cls.rets_monthly_begin, up=1)
        cls.limit_downs = cls.find_limit(cls.rets_monthly_last, up=-1)

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def get_ic_rankic(cls, df):
        '''è®¡ç®—ICå’ŒRankIC'''
        df1 = df[['ret', 'fac']]
        ic = df1.corr(method='pearson').iloc[0, 1]
        rankic = df1.corr(method='spearman').iloc[0, 1]
        df2 = pd.DataFrame({'ic': [ic], 'rankic': [rankic]})
        return df2

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def get_icir_rankicir(cls, df):
        '''è®¡ç®—ICIRå’ŒRankICIR'''
        ic = df.ic.mean()
        rankic = df.rankic.mean()
        icir = ic / np.std(df.ic) * (12 ** (0.5))
        rankicir = rankic / np.std(df.rankic) * (12 ** (0.5))
        return pd.DataFrame({'IC': [ic], 'ICIR': [icir], 'RankIC': [rankic], 'RankICIR': [rankicir]}, index=['è¯„ä»·æŒ‡æ ‡'])

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def get_ic_icir_and_rank(cls, df):
        '''è®¡ç®—ICã€ICIRã€RankICã€RankICIR'''
        df1 = df.groupby('date').apply(cls.get_ic_rankic)
        df2 = cls.get_icir_rankicir(df1)
        df2 = df2.T
        dura=(df.date.max()-df.date.min()).days/365
        t_value=df2.iloc[1,0]*(dura**(1/2))
        df3=pd.DataFrame({'è¯„ä»·æŒ‡æ ‡':[t_value]},index=['ICå‡å€¼tå€¼'])
        df4=pd.concat([df2,df3])
        return df4

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def get_groups(cls, df, groups_num):
        '''ä¾æ®å› å­å€¼ï¼Œåˆ¤æ–­æ˜¯åœ¨ç¬¬å‡ ç»„'''
        if 'group' in list(df.columns):
            df = df.drop(columns=['group'])
        df = df.sort_values(['fac'], ascending=True)
        each_group = round(df.shape[0] / groups_num)
        l = list(map(lambda x, y: [x] * y, list(range(1, groups_num + 1)), [each_group] * groups_num))
        l = reduce(lambda x, y: x + y, l)
        if len(l) < df.shape[0]:
            l = l + [groups_num] * (df.shape[0] - len(l))
        l = l[:df.shape[0]]
        df.insert(0, 'group', l)
        return df

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    # @history_remain(slogan='abandoned')
    def next_month_end(cls, x):
        '''æ‰¾åˆ°ä¸‹ä¸ªæœˆæœ€åä¸€å¤©'''
        x1 = x = x + relativedelta(months=1)
        while x1.month == x.month:
            x1 = x1 + relativedelta(days=1)
        return x1 - relativedelta(days=1)

    @classmethod
    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def limit_old_to_new(cls, limit, data):
        '''è·å–è·Œåœè‚¡åœ¨æ—§æœˆçš„ç»„å·ï¼Œç„¶åå°†æ—¥æœŸè°ƒæ•´åˆ°æ–°æœˆé‡Œ
        æ¶¨åœè‚¡åˆ™è·å¾—æ–°æœˆé‡Œæ¶¨åœè‚¡çš„ä»£ç å’Œæ—¶é—´ï¼Œç„¶åç›´æ¥åˆ å»'''
        data1 = data.copy()
        data1 = data1.reset_index()
        data1.columns = ['data_index'] + list(data1.columns)[1:]
        old = pd.merge(limit, data1, how='inner', on=['date', 'code'])
        old = old.set_index('data_index')
        old = old[['group', 'date', 'code']]
        old.date = list(map(cls.next_month_end, list(old.date)))
        return old

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_data(self, groups_num):
        '''æ‹¼æ¥å› å­æ•°æ®å’Œæ¯æœˆæ”¶ç›Šç‡æ•°æ®ï¼Œå¹¶å¯¹æ¶¨åœå’Œè·Œåœè‚¡åŠ ä»¥å¤„ç†'''
        self.data = pd.merge(self.rets_monthly, self.factors, how='inner', on=['date', 'code'])
        self.ic_icir_and_rank = self.get_ic_icir_and_rank(self.data)
        self.data = self.data.groupby('date').apply(lambda x: self.get_groups(x, groups_num))
        self.data = self.data.reset_index(drop=True)
        limit_ups_object = self.limit_old_to_new(self.limit_ups, self.data)
        limit_downs_object = self.limit_old_to_new(self.limit_downs, self.data)
        self.data = self.data.drop(limit_ups_object.index)
        rets_monthly_limit_downs = pd.merge(self.rets_monthly, limit_downs_object, how='inner', on=['date', 'code'])
        self.data = pd.concat([self.data, rets_monthly_limit_downs])

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def select_data_time(self, time_start, time_end):
        '''ç­›é€‰ç‰¹å®šçš„æ—¶é—´æ®µ'''
        if time_start:
            self.data = self.data[self.data.date >= time_start]
        if time_end:
            self.data = self.data[self.data.date <= time_end]

    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def make_start_to_one(self, l):
        '''è®©å‡€å€¼åºåˆ—çš„ç¬¬ä¸€ä¸ªæ•°å˜æˆ1'''
        min_date = self.factors.date.min()
        add_date = min_date - relativedelta(days=min_date.day)
        add_l = pd.Series([1], index=[add_date])
        l = pd.concat([add_l, l])
        return l

    # @lru_cache(maxsize=None)
    @tool_box(slogan=None)
    def to_group_ret(self,l):
        '''æ¯ä¸€ç»„çš„å¹´åŒ–æ”¶ç›Šç‡'''
        ret=l[-1]**(12/len(l))-1
        return ret

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_group_rets_net_values(self, groups_num=10,value_weighted=False):
        '''è®¡ç®—ç»„å†…æ¯ä¸€æœŸçš„å¹³å‡æ”¶ç›Šï¼Œç”Ÿæˆæ¯æ—¥æ”¶ç›Šç‡åºåˆ—å’Œå‡€å€¼åºåˆ—'''
        if value_weighted:
            cap_value=self.pricloses_copy*self.flowshares_copy
            cap_value=cap_value.resample('M').last().shift(1)
            cap_value=cap_value*self.tris_monthly
            # cap_value=np.log(cap_value)
            cap_value=cap_value.stack().reset_index()
            cap_value.columns=['date','code','cap_value']
            self.data=pd.merge(self.data,cap_value,on=['date','code'])
            def in_g(df):
                df.cap_value=df.cap_value/df.cap_value.sum()
                df.ret=df.ret*df.cap_value
                return df.ret.sum()
            self.group_rets=self.data.groupby(['date','group']).apply(in_g)
        else:
            self.group_rets = self.data.groupby(['date', 'group']).apply(lambda x: x.ret.mean())
        # dropnaæ˜¯å› ä¸ºå¦‚æœè‚¡ç¥¨è¡Œæƒ…æ•°æ®æ¯”å› å­æ•°æ®çš„æˆªæ­¢æ—¥æœŸæ™šï¼Œè€Œæœ€åä¸€ä¸ªæœˆå‘ç”Ÿæœˆåˆè·Œåœæ—¶ï¼Œä¼šé€ æˆæœ€åæŸç»„å¤šå‡ºä¸€ä¸ªæœˆçš„æ•°æ®
        self.group_rets = self.group_rets.unstack()
        self.group_rets = self.group_rets[self.group_rets.index <= self.factors.date.max()]
        self.group_rets.columns = list(map(str, list(self.group_rets.columns)))
        self.group_rets = self.group_rets.add_prefix('group')
        self.long_short_rets = self.group_rets['group1'] - self.group_rets['group' + str(groups_num)]
        self.long_short_net_values = (self.long_short_rets + 1).cumprod()
        if self.long_short_net_values[-1] <= self.long_short_net_values[0]:
            self.long_short_rets = self.group_rets['group' + str(groups_num)] - self.group_rets['group1']
            self.long_short_net_values = (self.long_short_rets + 1).cumprod()
        self.long_short_net_values = self.make_start_to_one(self.long_short_net_values)
        self.group_rets = self.group_rets.assign(long_short=self.long_short_rets)
        self.group_net_values = self.group_rets.applymap(lambda x: x + 1)
        self.group_net_values = self.group_net_values.cumprod()
        self.group_net_values = self.group_net_values.apply(self.make_start_to_one)
        a=groups_num**(0.5)
        #åˆ¤æ–­æ˜¯å¦è¦ä¸¤ä¸ªå› å­ç”»è¡¨æ ¼
        if a==int(a):
            self.square_rets=self.group_net_values.iloc[:,:-1].apply(self.to_group_ret).to_numpy()
            self.square_rets=self.square_rets.reshape((int(a),int(a)))
            self.square_rets=pd.DataFrame(self.square_rets,columns=list(range(1,int(a)+1)),index=list(range(1,int(a)+1)))
            print('è¿™æ˜¯self.square_rets',self.square_rets)

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_long_short_comments(self,on_paper=False):
        '''è®¡ç®—å¤šç©ºå¯¹å†²çš„ç›¸å…³è¯„ä»·æŒ‡æ ‡
        åŒ…æ‹¬å¹´åŒ–æ”¶ç›Šç‡ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€ä¿¡æ¯æ¯”ç‡ã€æœˆåº¦èƒœç‡ã€æœ€å¤§å›æ’¤ç‡'''
        self.long_short_ret_yearly = self.long_short_net_values[-1] ** (12 / len(self.long_short_net_values)) - 1
        self.long_short_vol_yearly = np.std(self.long_short_rets) * (12 ** 0.5)
        self.long_short_info_ratio = self.long_short_ret_yearly / self.long_short_vol_yearly
        self.long_short_win_times = len(self.long_short_rets[self.long_short_rets > 0])
        self.long_short_win_ratio = self.long_short_win_times / len(self.long_short_rets)
        self.max_retreat = -(self.long_short_net_values/self.long_short_net_values.expanding(1).max()-1).min()
        if on_paper:
            self.long_short_comments=pd.DataFrame({
                'è¯„ä»·æŒ‡æ ‡':[
                    self.long_short_ret_yearly,
                    self.long_short_vol_yearly,
                    self.long_short_info_ratio,
                    self.long_short_win_ratio,
                    self.max_retreat
                ]
            },index=['å¹´åŒ–æ”¶ç›Šç‡','å¹´åŒ–æ³¢åŠ¨ç‡','æ”¶ç›Šæ³¢åŠ¨æ¯”','æœˆåº¦èƒœç‡','æœ€å¤§å›æ’¤ç‡'])
        else:
            self.long_short_comments = pd.DataFrame({
                'è¯„ä»·æŒ‡æ ‡': [
                    self.long_short_ret_yearly,
                    self.long_short_vol_yearly,
                    self.long_short_info_ratio,
                    self.long_short_win_ratio,
                    self.max_retreat
                ]
            }, index=['å¹´åŒ–æ”¶ç›Šç‡', 'å¹´åŒ–æ³¢åŠ¨ç‡', 'ä¿¡æ¯æ¯”ç‡', 'æœˆåº¦èƒœç‡', 'æœ€å¤§å›æ’¤ç‡'])

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def get_total_comments(self):
        '''ç»¼åˆICã€ICIRã€RankICã€RankICIR,å¹´åŒ–æ”¶ç›Šç‡ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€ä¿¡æ¯æ¯”ç‡ã€æœˆåº¦èƒœç‡ã€æœ€å¤§å›æ’¤ç‡'''
        self.total_comments = pd.concat([self.ic_icir_and_rank, self.long_short_comments])

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def plot_net_values(self, y2, filename):
        '''ä½¿ç”¨matplotlibæ¥ç”»å›¾ï¼Œy2ä¸ºæ˜¯å¦å¯¹å¤šç©ºç»„åˆé‡‡ç”¨åŒyè½´'''
        self.group_net_values.plot(secondary_y=y2)
        filename_path = filename + '.png'
        plt.savefig(filename_path)

    # @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def plotly_net_values(self, filename):
        '''ä½¿ç”¨plotly.expressç”»å›¾'''
        fig = pe.line(self.group_net_values)
        filename_path = filename + '.html'
        pio.write_html(fig, filename_path, auto_open=True)

    @classmethod
    @lru_cache(maxsize=None)
    @main_process(slogan=None)
    def prerpare(cls):
        '''é€šç”¨æ•°æ®å‡†å¤‡'''
        cls.col_and_index()
        cls.load_all_files()
        cls.judge_month()
        cls.get_rets_month()

    # @lru_cache(maxsize=None)
    def run(self, groups_num=10, neutralize=False, boxcox=False, value_weighted=False,y2=False, plt_plot=True,
            plotly_plot=False, filename='åˆ†ç»„å‡€å€¼å›¾',
            time_start=None, time_end=None, print_comments=True,comments_writer=None,net_values_writer=None,rets_writer=None,
            comments_sheetname=None,net_values_sheetname=None,rets_sheetname=None,on_paper=False):
        '''è¿è¡Œå›æµ‹éƒ¨åˆ†'''
        if comments_writer and not comments_sheetname:
            raise IOError('æŠŠtotal_commentsè¾“å‡ºåˆ°excelä¸­æ—¶ï¼Œå¿…é¡»æŒ‡å®šsheetnameğŸ¤’')
        if net_values_writer and not net_values_sheetname:
            raise IOError('æŠŠgroup_net_valuesè¾“å‡ºåˆ°excelä¸­æ—¶ï¼Œå¿…é¡»æŒ‡å®šsheetnameğŸ¤’')
        if rets_writer and not rets_sheetname:
            raise IOError('æŠŠgroup_retsè¾“å‡ºåˆ°excelä¸­æ—¶ï¼Œå¿…é¡»æŒ‡å®šsheetnameğŸ¤’')
        if neutralize:
            self.get_log_cap()
            self.get_neutral_factors()
            self.deal_with_factors_after_neutralize()
        elif boxcox:
            self.get_log_cap(boxcox=True)
            self.get_neutral_factors()
            self.deal_with_factors_after_neutralize()
        else:
            self.deal_with_factors()
        self.get_limit_ups_downs()
        self.get_data(groups_num)
        self.select_data_time(time_start, time_end)
        self.get_group_rets_net_values(groups_num=groups_num,value_weighted=value_weighted)
        self.get_long_short_comments(on_paper=on_paper)
        self.get_total_comments()
        if plt_plot:
            if filename:
                self.plot_net_values(y2=y2, filename=filename)
            else:
                self.plot_net_values(y2=y2,
                                     filename=self.factors_file.split('.')[-2].split('/')[-1] + str(groups_num) + 'åˆ†ç»„')
            plt.show()
        if plotly_plot:
            if filename:
                self.plotly_net_values(filename=filename)
            else:
                self.plotly_net_values(
                    filename=self.factors_file.split('.')[-2].split('/')[-1] + str(groups_num) + 'åˆ†ç»„')
        if print_comments:
            print(self.total_comments)
        if comments_writer and comments_sheetname:
            self.total_comments.to_excel(comments_writer,sheet_name=comments_sheetname)
        if net_values_writer and net_values_sheetname:
            self.group_net_values.to_excel(net_values_writer,sheet_name=net_values_sheetname)
        if rets_writer and rets_sheetname:
            self.group_rets.to_excel(rets_writer,sheet_name=rets_sheetname)


class pure_fall():
    def __init__(
            self,
            minute_files_path=None,
            minute_columns=['date', 'open', 'high', 'low', 'close', 'amount', 'money'],
            daily_factors_path=None,
            monthly_factors_path=None
    ):
        self.homeplace=HomePlace()
        if monthly_factors_path:
            # åˆ†é’Ÿæ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
            self.minute_files_path = minute_files_path
        else:
            self.minute_files_path=self.homeplace.minute_data_file[:-1]
        # åˆ†é’Ÿæ•°æ®æ–‡ä»¶å¤¹
        self.minute_files = os.listdir(self.minute_files_path)
        self.minute_files = [i for i in self.minute_files if i.endswith('.mat')]
        # åˆ†é’Ÿæ•°æ®çš„è¡¨å¤´
        self.minute_columns = minute_columns
        # åˆ†é’Ÿæ•°æ®æ—¥é¢‘åŒ–ä¹‹åçš„æ•°æ®è¡¨
        self.daily_factors_list = []
        # å°†åˆ†é’Ÿæ•°æ®æ‹¼æˆä¸€å¼ æ—¥é¢‘å› å­è¡¨
        self.daily_factors = None
        # æœ€ç»ˆæœˆåº¦å› å­è¡¨æ ¼
        self.monthly_factors = None
        if daily_factors_path:
            # æ—¥é¢‘å› å­æ–‡ä»¶ä¿å­˜è·¯å¾„
            self.daily_factors_path = daily_factors_path
        else:
            self.daily_factors_path=self.homeplace.factor_data_file+'æ—¥é¢‘_'
        if monthly_factors_path:
            # æœˆé¢‘å› å­æ–‡ä»¶ä¿å­˜è·¯å¾„
            self.monthly_factors_path = monthly_factors_path
        else:
            self.monthly_factors_path=self.homeplace.factor_data_file+'æœˆé¢‘_'

    def __call__(self,monthly=False):
        '''ä¸ºäº†é˜²æ­¢å±æ€§åå¤ªå¤šï¼Œå¿˜è®°äº†è¦è°ƒç”¨å“ªä¸ªæ‰æ˜¯ç»“æœï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¾“å‡ºæœˆåº¦æ•°æ®è¡¨'''
        if monthly:
            return self.monthly_factors.copy()
        else:
            try:
                return self.daily_factors.copy()
            except Exception:
                return self.monthly_factors.copy()

    def __add__(self, selfas):
        '''å°†å‡ ä¸ªå› å­æˆªé¢æ ‡å‡†åŒ–ä¹‹åï¼Œå› å­å€¼ç›¸åŠ '''
        fac1 = self.standardlize_in_cross_section(self.monthly_factors)
        fac2s=[]
        if not isinstance(selfas,Iterable):
            logger.warning(f'{selfas} is changed into Iterable')
            selfas=(selfas,)
        for selfa in selfas:
            fac2 = self.standardlize_in_cross_section(selfa.monthly_factors)
            fac2s.append(fac2)
        for i in fac2s:
            fac1=fac1+i
        new_pure=pure_fall()
        new_pure.monthly_factors=fac1
        return new_pure

    def __mul__(self,selfas):
        '''å°†å‡ ä¸ªå› å­æ¨ªæˆªé¢æ ‡å‡†åŒ–ä¹‹åï¼Œä½¿å…¶éƒ½ä¸ºæ­£æ•°ï¼Œç„¶åå› å­å€¼ç›¸ä¹˜'''
        fac1=self.standardlize_in_cross_section(self.monthly_factors)
        fac1=fac1-fac1.min()
        fac2s=[]
        if not isinstance(selfas,Iterable):
            logger.warning(f'{selfas} is changed into Iterable')
            selfas=(selfas,)
        for selfa in selfas:
            fac2=self.standardlize_in_cross_section(selfa.monthly_factors)
            fac2=fac2-fac2.min()
            fac2s.append(fac2)
        for i in fac2s:
            fac1=fac1*i
        new_pure=pure_fall()
        new_pure.monthly_factors=fac1
        return new_pure

    def __truediv__(self, selfa):
        '''ä¸¤ä¸ªä¸€æ­£ä¸€å‰¯çš„å› å­ï¼Œå¯ä»¥ç”¨æ­¤æ–¹æ³•ç›¸å‡'''
        fac1 = self.standardlize_in_cross_section(self.monthly_factors)
        fac2 = self.standardlize_in_cross_section(selfa.monthly_factors)
        fac=fac1-fac2
        new_pure=pure_fall()
        new_pure.monthly_factors=fac
        return new_pure

    def __floordiv__(self, selfa):
        '''ä¸¤ä¸ªå› å­ä¸€æ­£ä¸€è´Ÿï¼Œå¯ä»¥ç”¨æ­¤æ–¹æ³•ç›¸é™¤'''
        fac1 = self.standardlize_in_cross_section(self.monthly_factors)
        fac2 = self.standardlize_in_cross_section(selfa.monthly_factors)
        fac1=fac1-fac1.min()
        fac2=fac2-fac2.min()
        fac=fac1/fac2
        fac=fac.replace(np.inf,np.nan)
        new_pure=pure_fall()
        new_pure.monthly_factors=fac
        return new_pure

    def __sub__(self, selfa):
        '''ç”¨ä¸»å› å­å‰”é™¤å…¶ä»–ç›¸å…³å› å­ã€ä¼ ç»Ÿå› å­ç­‰
        selfaå¯ä»¥ä¸ºå¤šä¸ªå› å­å¯¹è±¡ç»„æˆçš„å…ƒç»„æˆ–åˆ—è¡¨ï¼Œæ¯ä¸ªè¾…åŠ©å› å­åªéœ€è¦æœ‰æœˆåº¦å› å­æ–‡ä»¶è·¯å¾„å³å¯'''
        tqdm.tqdm.pandas()
        if not isinstance(selfa,Iterable):
            logger.warning(f'{selfa} is changed into Iterable')
            selfa=(selfa,)
        fac_main = self.wide_to_long(self.monthly_factors, 'fac')
        fac_helps = [i.monthly_factors for i in selfa]
        help_names = ['help' + str(i) for i in range(1, (len(fac_helps) + 1))]
        fac_helps = list(map(self.wide_to_long, fac_helps, help_names))
        fac_helps = pd.concat(fac_helps, axis=1)
        facs = pd.concat([fac_main, fac_helps], axis=1).dropna()
        facs = facs.groupby('date').progress_apply(lambda x: self.de_in_group(x, help_names))
        facs = facs.unstack()
        facs.columns = list(map(lambda x: x[1], list(facs.columns)))
        return facs

    def __gt__(self,selfa):
        '''ç”¨äºè¾“å‡º25åˆ†ç»„è¡¨æ ¼ï¼Œä½¿ç”¨æ—¶ï¼Œä»¥x>yçš„å½¢å¼ä½¿ç”¨ï¼Œå…¶ä¸­x,yå‡ä¸ºpure_fallå¯¹è±¡
        è®¡ç®—æ—¶ä½¿ç”¨çš„æ˜¯ä»–ä»¬çš„æœˆåº¦å› å­è¡¨ï¼Œå³self.monthly_factorså±æ€§ï¼Œä¸ºå®½æ•°æ®å½¢å¼çš„dataframe
        xåº”ä¸ºé¦–å…ˆç”¨æ¥çš„åˆ†ç»„çš„ä¸»å› å­ï¼Œyä¸ºåœ¨xåˆ†ç»„åçš„ç»„å†…ç»§ç»­åˆ†ç»„çš„æ¬¡å› å­'''
        x=self.monthly_factors.copy()
        y=selfa.monthly_factors.copy()
        x=x.stack().reset_index()
        y=y.stack().reset_index()
        x.columns=['date','code','fac']
        y.columns=['date','code','fac']
        shen=pure_moon()
        x=x.groupby('date').apply(lambda df:shen.get_groups(df,5))
        x=x.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupx'})
        xy=pd.merge(x,y,on=['date','code'])
        xy=xy.groupby(['date','groupx']).apply(lambda df:shen.get_groups(df,5))
        xy=xy.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupy'})
        xy=xy.assign(fac=xy.groupx*5+xy.groupy)
        xy=xy[['date','code','fac']]
        xy=xy.set_index(['date','code']).unstack()
        xy.columns=[i[1] for i in list(xy.columns)]
        new_pure=pure_fall()
        new_pure.monthly_factors=xy
        return new_pure

    def __rshift__(self, selfa):
        '''ç”¨äºè¾“å‡º100åˆ†ç»„è¡¨æ ¼ï¼Œä½¿ç”¨æ—¶ï¼Œä»¥x>>yçš„å½¢å¼ä½¿ç”¨ï¼Œå…¶ä¸­x,yå‡ä¸ºpure_fallå¯¹è±¡
        è®¡ç®—æ—¶ä½¿ç”¨çš„æ˜¯ä»–ä»¬çš„æœˆåº¦å› å­è¡¨ï¼Œå³self.monthly_factorså±æ€§ï¼Œä¸ºå®½æ•°æ®å½¢å¼çš„dataframe
        xåº”ä¸ºé¦–å…ˆç”¨æ¥çš„åˆ†ç»„çš„ä¸»å› å­ï¼Œyä¸ºåœ¨xåˆ†ç»„åçš„ç»„å†…ç»§ç»­åˆ†ç»„çš„æ¬¡å› å­'''
        x=self.monthly_factors.copy()
        y=selfa.monthly_factors.copy()
        x=x.stack().reset_index()
        y=y.stack().reset_index()
        x.columns=['date','code','fac']
        y.columns=['date','code','fac']
        shen=pure_moon()
        x=x.groupby('date').apply(lambda df:shen.get_groups(df,10))
        x=x.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupx'})
        xy=pd.merge(x,y,on=['date','code'])
        xy=xy.groupby(['date','groupx']).apply(lambda df:shen.get_groups(df,10))
        xy=xy.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupy'})
        xy=xy.assign(fac=xy.groupx*10+xy.groupy)
        xy=xy[['date','code','fac']]
        xy=xy.set_index(['date','code']).unstack()
        xy.columns=[i[1] for i in list(xy.columns)]
        new_pure=pure_fall()
        new_pure.monthly_factors=xy
        return new_pure

    def wide_to_long(self, df, i):
        '''å°†å®½æ•°æ®è½¬åŒ–ä¸ºé•¿æ•°æ®ï¼Œç”¨äºå› å­è¡¨è½¬åŒ–å’Œæ‹¼æ¥'''
        df = df.stack().reset_index()
        df.columns = ['date', 'code', i]
        df = df.set_index(['date', 'code'])
        return df

    def de_in_group(self, df, help_names):
        '''å¯¹æ¯ä¸ªæ—¶é—´ï¼Œåˆ†åˆ«åšå›å½’ï¼Œå‰”é™¤ç›¸å…³å› å­'''
        ols_order = 'fac~' + '+'.join(help_names)
        ols_result = smf.ols(ols_order, data=df).fit()
        params = {i: ols_result.params[i] for i in help_names}
        predict = [params[i] * df[i] for i in help_names]
        predict = reduce(lambda x, y: x + y, predict)
        df.fac = df.fac - predict - ols_result.params['Intercept']
        df = df[['fac']]
        return df

    def mat_to_df(self, mat,use_datetime=True):
        '''å°†matæ–‡ä»¶å˜æˆ'''
        mat_path = '/'.join([self.minute_files_path, mat])
        df = list(scio.loadmat(mat_path).values())[3]
        df = pd.DataFrame(df, columns=self.minute_columns)
        if use_datetime:
            df.date = pd.to_datetime(df.date.apply(str), format='%Y%m%d')
            df = df.set_index('date')
        return df

    def add_suffix(self, code):
        '''ç»™è‚¡ç¥¨ä»£ç åŠ ä¸Šåç¼€'''
        if not isinstance(code, str):
            code = str(code)
        if len(code) < 6:
            code = '0' * (6 - len(code)) + code
        if code.startswith('0') or code.startswith('3'):
            code = '.'.join([code, 'SZ'])
        elif code.startswith('6'):
            code = '.'.join([code, 'SH'])
        elif code.startswith('8'):
            code = '.'.join([code, 'BJ'])
        return code

    def minute_to_daily(self, func,add_priclose=False,add_tr=False,start_date=10000000,end_date=30000000):
        '''
        å°†åˆ†é’Ÿæ•°æ®å˜æˆæ—¥é¢‘å› å­ï¼Œå¹¶ä¸”æ·»åŠ åˆ°æ—¥é¢‘å› å­è¡¨é‡Œ
        é€šå¸¸åº”è¯¥æ¯å¤©ç”Ÿæˆä¸€ä¸ªæŒ‡æ ‡ï¼Œæœ€åä¸€åªè‚¡ç¥¨ä¼šç”Ÿæˆä¸€ä¸ªseries
        '''
        share=read_daily('AllStock_DailyAShareNum.mat')
        if add_priclose:
            for mat in tqdm.tqdm(self.minute_files):
                try:
                    code = self.add_suffix(mat[-10:-4])
                    df = self.mat_to_df(mat,use_datetime=True)
                    if add_tr:
                        share_this=share[code].to_frame('sharenum').reset_index()
                        share_this.columns=['date','sharenum']
                        df=df.reset_index()
                        df.columns=['date']+list(df.columns)[1:]
                        df=pd.merge(df,share_this,on=['date'],how='left')
                        df=df.assign(tr=df.amount/df.sharenum)
                    df=df.reset_index()
                    df.columns=['date']+list(df.columns)[1:]
                    df.date=df.date.dt.strftime('%Y%m%d')
                    df.date=df.date.astype(int)
                    df=df[(df.date>=start_date)&(df.date<=end_date)]
                    priclose=df.groupby('date').last()
                    priclose=priclose.shift(1).reset_index()
                    df=pd.concat([priclose,df])
                    the_func = partial(func)
                    df = df.groupby('date').apply(the_func)
                    df = df.to_frame(name=code)
                    self.daily_factors_list.append(df)
                    self.daily_factors=pd.concat(self.daily_factors_list,axis=1)
                    self.daily_factors.index=pd.to_datetime(self.daily_factors.index.astype(int),format='%Y%m%d')
                except Exception as e:
                    logger.warning(f'{code} ç¼ºå¤±')
                    logger.error(e)
        else:
            for mat in tqdm.tqdm(self.minute_files):
                try:
                    code = self.add_suffix(mat[-10:-4])
                    df = self.mat_to_df(mat,use_datetime=True)
                    if add_tr:
                        share_this=share[code].to_frame('sharenum').reset_index()
                        share_this.columns=['date','sharenum']
                        df=df.reset_index()
                        df.columns=['date']+list(df.columns)[1:]
                        df=pd.merge(df,share_this,on=['date'],how='left')
                        df=df.assign(tr=df.amount/df.sharenum)
                    the_func = partial(func)
                    df.date=df.date.astype(int)
                    df=df[(df.date>=start_date)&(df.date<=end_date)]
                    df = df.groupby('date').apply(the_func)
                    df = df.to_frame(name=code)
                    self.daily_factors_list.append(df)
                    self.daily_factors = pd.concat(self.daily_factors_list, axis=1)
                except Exception as e:
                    logger.warning(f'{code} ç¼ºå¤±')
                    logger.error(e)
        self.daily_factors.reset_index().to_feather(self.daily_factors_path)

    def minute_to_daily_whole(self, func,start_date=10000000,end_date=30000000):
        '''
        å°†åˆ†é’Ÿæ•°æ®å˜æˆæ—¥é¢‘å› å­ï¼Œå¹¶ä¸”æ·»åŠ åˆ°æ—¥é¢‘å› å­è¡¨é‡Œ
        é€šå¸¸åº”è¯¥æ¯å¤©ç”Ÿæˆä¸€ä¸ªæŒ‡æ ‡ï¼Œæœ€åä¸€åªè‚¡ç¥¨ä¼šç”Ÿæˆä¸€ä¸ªseries
        '''
        for mat in tqdm.tqdm(self.minute_files):
            self.code=self.add_suffix(mat[-10:-4])
            df = self.mat_to_df(mat)
            df.date=df.date.astype(int)
            df=df[(df.date>=start_date)&(df.date<=end_date)]
            the_func = partial(func)
            df = func(df)
            if isinstance(df,pd.DataFrame):
                df.columns = [self.code]
                self.daily_factors_list.append(df)
            elif isinstance(df,pd.Series):
                df=df.to_frame(name=self.code)
                self.daily_factors_list.append(df)
            else:
                logger.warning(f'df is {df}')
        self.daily_factors = pd.concat(self.daily_factors_list, axis=1)
        self.daily_factors.reset_index().to_feather(self.daily_factors_path)

    def standardlize_in_cross_section(self, df):
        '''
        åœ¨æ¨ªæˆªé¢ä¸Šåšæ ‡å‡†åŒ–
        è¾“å…¥çš„dfåº”ä¸ºï¼Œåˆ—åæ˜¯è‚¡ç¥¨ä»£ç ï¼Œç´¢å¼•æ˜¯æ—¶é—´
        '''
        df = df.T
        df = (df - df.mean()) / df.std()
        df = df.T
        return df

    def get_daily_factors(self, func, whole=False,add_priclose=False,add_tr=False,start_date=10000000,end_date=30000000):
        '''è°ƒç”¨åˆ†é’Ÿåˆ°æ—¥åº¦æ–¹æ³•ï¼Œç®—å‡ºæ—¥é¢‘æ•°æ®'''
        try:
            self.daily_factors = pd.read_feather(self.daily_factors_path)
            self.daily_factors = self.daily_factors.set_index('date')
        except Exception:
            if whole:
                self.minute_to_daily_whole(func,start_date=start_date,end_date=end_date)
            else:
                self.minute_to_daily(func,add_priclose=add_priclose,add_tr=add_tr,start_date=start_date,end_date=end_date)

    def get_neutral_monthly_factors(self, df,boxcox=False):
        '''å¯¹æœˆåº¦å› å­åšå¸‚å€¼ä¸­æ€§åŒ–å¤„ç†'''
        shen = pure_moon()
        shen.set_factor_df_date_as_index(df)
        if boxcox:
            shen.run(5, boxcox=True, plt=False, print_comments=False)
        else:
            shen.run(5,neutralize=True,plt=False,print_comments=False)
        new_factors = shen.factors.copy()
        new_factors = new_factors.set_index(['date', 'code']).unstack()
        new_factors.columns = list(map(lambda x: x[1], list(new_factors.columns)))
        new_factors = new_factors.reset_index()
        add_start_point = new_factors.date.min()
        add_start_point = add_start_point - pd.Timedelta(days=add_start_point.day)
        new_factors.date = new_factors.date.shift(1)
        new_factors.date = new_factors.date.fillna(add_start_point)
        new_factors = new_factors.set_index('date')
        return new_factors

    def get_monthly_factors(self, func, neutralize,boxcox):
        '''å°†æ—¥é¢‘çš„å› å­è½¬åŒ–ä¸ºæœˆé¢‘å› å­'''
        two_parts=self.monthly_factors_path.split('.')
        try:
            self.monthly_factors = pd.read_feather(self.monthly_factors_path)
            self.monthly_factors = self.monthly_factors.set_index('date')
        except Exception:
            the_func = partial(func)
            self.monthly_factors = the_func(self.daily_factors)
            if neutralize:
                self.monthly_factors = self.get_neutral_monthly_factors(self.monthly_factors)
            elif boxcox:
                self.monthly_factors=self.get_neutral_monthly_factors(self.monthly_factors,boxcox=True)

            self.monthly_factors.reset_index().to_feather(self.monthly_factors_path)

    def run(self, whole=False,daily_func=None, monthly_func=None,
            neutralize=False,boxcox=False):
        '''æ‰§å¿…è¦çš„å‡½æ•°ï¼Œå°†åˆ†é’Ÿæ•°æ®å˜æˆæœˆåº¦å› å­'''
        self.get_daily_factors(daily_func,whole)
        self.get_monthly_factors(monthly_func, neutralize,boxcox)


class pure_fallmount(pure_fall):
    '''ç»§æ‰¿è‡ªçˆ¶ç±»ï¼Œä¸“ä¸ºåšå› å­æˆªé¢æ ‡å‡†åŒ–ä¹‹åç›¸åŠ å’Œå› å­å‰”é™¤å…¶ä»–è¾…åŠ©å› å­çš„ä½œç”¨'''
    def __init__(self, monthly_factors):
        '''è¾“å…¥æœˆåº¦å› å­å€¼ï¼Œä»¥è®¾å®šæ–°çš„å¯¹è±¡'''
        super(pure_fall, self).__init__()
        self.monthly_factors = monthly_factors

    def __call__(self,monthly=False):
        '''ä¸ºäº†é˜²æ­¢å±æ€§åå¤ªå¤šï¼Œå¿˜è®°äº†è¦è°ƒç”¨å“ªä¸ªæ‰æ˜¯ç»“æœï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¾“å‡ºæœˆåº¦æ•°æ®è¡¨'''
        if monthly:
            return self.monthly_factors.copy()
        else:
            try:
                return self.daily_factors.copy()
            except Exception:
                return self.monthly_factors.copy()

    def __add__(self, selfas):
        '''è¿”å›ä¸€ä¸ªå¯¹è±¡ï¼Œè€Œéä¸€ä¸ªè¡¨æ ¼ï¼Œå¦‚éœ€è¡¨æ ¼è¯·è°ƒç”¨å¯¹è±¡'''
        fac1 = self.standardlize_in_cross_section(self.monthly_factors)
        fac2s = []
        if not isinstance(selfas,Iterable):
            logger.warning(f'{selfas} is changed into Iterable')
            selfas=(selfas,)
        for selfa in selfas:
            fac2 = self.standardlize_in_cross_section(selfa.monthly_factors)
            fac2s.append(fac2)
        for i in fac2s:
            fac1 = fac1 + i
        new_pure = pure_fallmount(fac1)
        return new_pure

    def __mul__(self,selfas):
        '''å°†å‡ ä¸ªå› å­æ¨ªæˆªé¢æ ‡å‡†åŒ–ä¹‹åï¼Œä½¿å…¶éƒ½ä¸ºæ­£æ•°ï¼Œç„¶åå› å­å€¼ç›¸ä¹˜'''
        fac1=self.standardlize_in_cross_section(self.monthly_factors)
        fac1=fac1-fac1.min()
        fac2s=[]
        if not isinstance(selfas,Iterable):
            logger.warning(f'{selfas} is changed into Iterable')
            selfas=(selfas,)
        for selfa in selfas:
            fac2=self.standardlize_in_cross_section(selfa.monthly_factors)
            fac2=fac2-fac2.min()
            fac2s.append(fac2)
        for i in fac2s:
            fac1=fac1*i
        new_pure=pure_fall()
        new_pure.monthly_factors=fac1
        return new_pure

    def __sub__(self, selfa):
        '''è¿”å›å¯¹è±¡ï¼Œå¦‚éœ€è¡¨æ ¼ï¼Œè¯·è°ƒç”¨å¯¹è±¡'''
        tqdm.tqdm.pandas()
        if not isinstance(selfa,Iterable):
            logger.warning(f'{selfa} is changed into Iterable')
            selfa=(selfa,)
        fac_main = self.wide_to_long(self.monthly_factors, 'fac')
        fac_helps = [i.monthly_factors for i in selfa]
        help_names = ['help' + str(i) for i in range(1, (len(fac_helps) + 1))]
        fac_helps = list(map(self.wide_to_long, fac_helps, help_names))
        fac_helps = pd.concat(fac_helps, axis=1)
        facs = pd.concat([fac_main, fac_helps], axis=1).dropna()
        facs = facs.groupby('date').progress_apply(lambda x: self.de_in_group(x, help_names))
        facs = facs.unstack()
        facs.columns = list(map(lambda x: x[1], list(facs.columns)))
        new_pure = pure_fallmount(facs)
        return new_pure

    def __gt__(self,selfa):
        '''ç”¨äºè¾“å‡º25åˆ†ç»„è¡¨æ ¼ï¼Œä½¿ç”¨æ—¶ï¼Œä»¥x>yçš„å½¢å¼ä½¿ç”¨ï¼Œå…¶ä¸­x,yå‡ä¸ºpure_fallå¯¹è±¡
        è®¡ç®—æ—¶ä½¿ç”¨çš„æ˜¯ä»–ä»¬çš„æœˆåº¦å› å­è¡¨ï¼Œå³self.monthly_factorså±æ€§ï¼Œä¸ºå®½æ•°æ®å½¢å¼çš„dataframe
        xåº”ä¸ºé¦–å…ˆç”¨æ¥çš„åˆ†ç»„çš„ä¸»å› å­ï¼Œyä¸ºåœ¨xåˆ†ç»„åçš„ç»„å†…ç»§ç»­åˆ†ç»„çš„æ¬¡å› å­'''
        x=self.monthly_factors.copy()
        y=selfa.monthly_factors.copy()
        x=x.stack().reset_index()
        y=y.stack().reset_index()
        x.columns=['date','code','fac']
        y.columns=['date','code','fac']
        shen=pure_moon()
        x=x.groupby('date').apply(lambda df:shen.get_groups(df,5))
        x=x.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupx'})
        xy=pd.merge(x,y,on=['date','code'])
        xy=xy.groupby(['date','groupx']).apply(lambda df:shen.get_groups(df,5))
        xy=xy.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupy'})
        xy=xy.assign(fac=xy.groupx*5+xy.groupy)
        xy=xy[['date','code','fac']]
        xy=xy.set_index(['date','code']).unstack()
        xy.columns=[i[1] for i in list(xy.columns)]
        new_pure=pure_fallmount(xy)
        return new_pure

    def __rshift__(self, selfa):
        '''ç”¨äºè¾“å‡º100åˆ†ç»„è¡¨æ ¼ï¼Œä½¿ç”¨æ—¶ï¼Œä»¥x>>yçš„å½¢å¼ä½¿ç”¨ï¼Œå…¶ä¸­x,yå‡ä¸ºpure_fallå¯¹è±¡
        è®¡ç®—æ—¶ä½¿ç”¨çš„æ˜¯ä»–ä»¬çš„æœˆåº¦å› å­è¡¨ï¼Œå³self.monthly_factorså±æ€§ï¼Œä¸ºå®½æ•°æ®å½¢å¼çš„dataframe
        xåº”ä¸ºé¦–å…ˆç”¨æ¥çš„åˆ†ç»„çš„ä¸»å› å­ï¼Œyä¸ºåœ¨xåˆ†ç»„åçš„ç»„å†…ç»§ç»­åˆ†ç»„çš„æ¬¡å› å­'''
        x=self.monthly_factors.copy()
        y=selfa.monthly_factors.copy()
        x=x.stack().reset_index()
        y=y.stack().reset_index()
        x.columns=['date','code','fac']
        y.columns=['date','code','fac']
        shen=pure_moon()
        x=x.groupby('date').apply(lambda df:shen.get_groups(df,10))
        x=x.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupx'})
        xy=pd.merge(x,y,on=['date','code'])
        xy=xy.groupby(['date','groupx']).apply(lambda df:shen.get_groups(df,10))
        xy=xy.reset_index(drop=True).drop(columns=['fac']).rename(columns={'group':'groupy'})
        xy=xy.assign(fac=xy.groupx*10+xy.groupy)
        xy=xy[['date','code','fac']]
        xy=xy.set_index(['date','code']).unstack()
        xy.columns=[i[1] for i in list(xy.columns)]
        new_pure=pure_fallmount(xy)
        return new_pure

class pure_winter():
    def __init__(self):
        self.homeplace=HomePlace()
        # barraå› å­æ•°æ®
        self.barras = self.read_h5(self.homeplace.barra_data_file+'FactorLoading_Style.h5')
        # è¡Œä¸šå“‘å˜é‡æ•°æ®
        self.industrys = self.read_h5(self.homeplace.barra_data_file+'FactorLoading_Industry.h5')

    def __call__(self,fallmount=0):
        '''è¿”å›çº¯å‡€å› å­å€¼'''
        if fallmount==0:
            return self.snow_fac
        else:
            return pure_fallmount(self.snow_fac)

    def read_h5(self,path):
        '''è¯»å…¥h5æ–‡ä»¶'''
        res={}
        a=h5py.File(path)
        for k,v in tqdm.tqdm(list(a.items()),desc='æ•°æ®åŠ è½½ä¸­â€¦â€¦'):
            value=list(v.values())[-1]
            col=[i.decode('utf-8') for i in list(list(v.values())[0])]
            ind=[i.decode('utf-8') for i in list(list(v.values())[1])]
            res[k]=pd.DataFrame(value,columns=col,index=ind)
        return res

    @history_remain(slogan='abandoned')
    def last_month_end(self, x):
        '''æ‰¾åˆ°ä¸‹ä¸ªæœˆæœ€åä¸€å¤©'''
        x1 = x = x - relativedelta(months=1)
        while x1.month == x.month:
            x1 = x1 + relativedelta(days=1)
        return x1 - relativedelta(days=1)

    @history_remain(slogan='abandoned')
    def set_factors_df(self, df):
        '''ä¼ å…¥å› å­dataframeï¼Œåº”ä¸ºä¸‰åˆ—ï¼Œç¬¬ä¸€åˆ—æ˜¯æ—¶é—´ï¼Œç¬¬äºŒåˆ—æ˜¯è‚¡ç¥¨ä»£ç ï¼Œç¬¬ä¸‰åˆ—æ˜¯å› å­å€¼'''
        df1=df.copy()
        df1.columns = ['date', 'code', 'fac']
        df1 = df1.set_index(['date', 'code'])
        df1 = df1.unstack().reset_index()
        df1.date = df1.date.apply(self.last_month_end)
        df1 = df1.set_index(['date']).stack()
        self.factors = df1.copy()

    def set_factors_df_wide(self, df):
        '''ä¼ å…¥å› å­æ•°æ®ï¼Œæ—¶é—´ä¸ºç´¢å¼•ï¼Œä»£ç ä¸ºåˆ—å'''
        df1=df.copy()
        # df1.index=df1.index-pd.DateOffset(months=1)
        df1=df1.resample('M').last()
        df1=df1.stack().reset_index()
        df1.columns = ['date', 'code','fac']
        self.factors=df1.copy()

    def daily_to_monthly(self, df):
        '''å°†æ—¥åº¦çš„barraå› å­æœˆåº¦åŒ–'''
        df.index = pd.to_datetime(df.index, format='%Y%m%d')
        df = df.resample('M').last()
        return df

    def get_monthly_barras_industrys(self):
        '''å°†barraå› å­å’Œè¡Œä¸šå“‘å˜é‡å˜æˆæœˆåº¦æ•°æ®'''
        for key, value in self.barras.items():
            self.barras[key] = self.daily_to_monthly(value)
        for key, value in self.industrys.items():
            self.industrys[key] = self.daily_to_monthly(value)

    def wide_to_long(self, df, name):
        '''å°†å®½æ•°æ®å˜æˆé•¿æ•°æ®ï¼Œä¾¿äºåç»­æ‹¼æ¥'''
        df = df.stack().reset_index()
        df.columns = ['date', 'code', name]
        df = df.set_index(['date', 'code'])
        return df

    def get_wide_barras_industrys(self):
        '''å°†barraå› å­å’Œè¡Œä¸šå“‘å˜é‡éƒ½å˜æˆé•¿æ•°æ®'''
        for key, value in self.barras.items():
            self.barras[key] = self.wide_to_long(value, key)
        for key, value in self.industrys.items():
            self.industrys[key] = self.wide_to_long(value, key)

    def get_corr_pri_ols_pri(self):
        '''æ‹¼æ¥barraå› å­å’Œè¡Œä¸šå“‘å˜é‡ï¼Œç”Ÿæˆç”¨äºæ±‚ç›¸å…³ç³»æ•°å’Œçº¯å‡€å› å­çš„æ•°æ®è¡¨'''
        if self.factors.shape[0]>1:
            self.factors=self.factors.set_index(['date', 'code'])
        self.corr_pri = pd.concat([self.factors] + list(self.barras.values()), axis=1).dropna()
        self.ols_pri = pd.concat([self.corr_pri] + list(self.industrys.values()), axis=1).dropna()

    def get_corr(self):
        '''è®¡ç®—æ¯ä¸€æœŸçš„ç›¸å…³ç³»æ•°ï¼Œå†æ±‚å¹³å‡å€¼'''
        self.corr_by_step = self.corr_pri.groupby(['date']).apply(lambda x: x.corr().head(1))
        self.corr = self.corr_by_step.mean()

    def ols_in_group(self, df):
        '''å¯¹æ¯ä¸ªæ—¶é—´æ®µè¿›è¡Œå›å½’ï¼Œå¹¶è®¡ç®—æ®‹å·®'''
        xs = list(df.columns)
        xs = [i for i in xs if i != 'fac']
        xs_join = '+'.join(xs)
        ols_formula = 'fac~' + xs_join
        ols_result = smf.ols(ols_formula, data=df).fit()
        ols_ws = {i: ols_result.params[i] for i in xs}
        ols_b = ols_result.params['Intercept']
        to_minus = [ols_ws[i] * df[i] for i in xs]
        to_minus = reduce(lambda x, y: x + y, to_minus)
        df = df.assign(snow_fac=df.fac - to_minus - ols_b)
        df = df[['snow_fac']]
        df = df.rename(columns={'snow_fac': 'fac'})
        return df

    def get_snow_fac(self):
        '''è·å¾—çº¯å‡€å› å­'''
        self.snow_fac = self.ols_pri.groupby(['date']).apply(self.ols_in_group)
        self.snow_fac = self.snow_fac.unstack()
        self.snow_fac.columns = list(map(lambda x: x[1], list(self.snow_fac.columns)))

    def run(self):
        '''è¿è¡Œä¸€äº›å¿…è¦çš„å‡½æ•°'''
        self.get_monthly_barras_industrys()
        self.get_wide_barras_industrys()
        self.get_corr_pri_ols_pri()
        self.get_corr()
        self.get_snow_fac()


class pure_snowtrain(pure_winter):
    '''ç›´æ¥è¿”å›çº¯å‡€å› å­'''

    def __init__(self, factors):
        '''ç›´æ¥è¾“å…¥åŸå§‹å› å­æ•°æ®'''
        super(pure_snowtrain, self).__init__()
        self.set_factors_df_wide(factors.copy())
        self.run()

    def __call__(self, fallmount=0):
        '''å¯ä»¥ç›´æ¥è¿”å›pure_fallmountå¯¹è±¡ï¼Œæˆ–çº¯å‡€å› å­çŸ©é˜µ'''
        if fallmount == 0:
            return self.snow_fac
        else:
            return pure_fallmount(self.snow_fac)


class pure_moonlight(pure_moon):
    '''ç»§æ‰¿è‡ªpure_moonå›æµ‹æ¡†æ¶ï¼Œä½¿ç”¨å…¶ä¸­çš„æ—¥é¢‘å¤æƒæ”¶ç›˜ä»·æ•°æ®ï¼Œä»¥åŠæ¢æ‰‹ç‡æ•°æ®'''

    def __init__(self):
        '''åŠ è½½å…¨éƒ¨æ•°æ®'''
        super(pure_moonlight, self).__init__()
        self.homeplace=HomePlace()
        self.col_and_index()
        self.load_all_files()
        self.judge_month()
        self.get_log_cap()
        # å¯¹æ•°å¸‚å€¼
        self.cap_as_factor = self.cap[['date', 'code', 'cap_size']].set_index(['date', 'code']).unstack()
        self.cap_as_factor.columns = list(map(lambda x: x[1], list(self.cap_as_factor.columns)))
        # ä¼ ç»Ÿåè½¬å› å­ret20
        self.ret20_database = self.homeplace.factor_data_file+'æœˆé¢‘_åè½¬å› å­ret20.feather'
        # ä¼ ç»Ÿæ¢æ‰‹ç‡å› å­turn20
        self.turn20_database = self.homeplace.factor_data_file+'æœˆé¢‘_æ¢æ‰‹ç‡å› å­turn20.feather'
        # ä¼ ç»Ÿæ³¢åŠ¨ç‡å› å­vol20
        self.vol20_database = self.homeplace.factor_data_file+'æœˆé¢‘_æ³¢åŠ¨ç‡å› å­vol20.feather'
        # #è‡ªåŠ¨æ›´æ–°
        self.get_updated_factors()

    def __call__(self, name):
        '''å¯ä»¥é€šè¿‡callæ–¹å¼ï¼Œç›´æ¥è·å–å¯¹åº”å› å­æ•°æ®'''
        value = getattr(self, name)
        return value

    def get_ret20(self, pri):
        '''è®¡ç®—20æ—¥æ¶¨è·Œå¹…å› å­'''
        past = pri.iloc[:-20, :]
        future = pri.iloc[20:, :]
        ret20 = (future.to_numpy() - past.to_numpy()) / past.to_numpy()
        df = pd.DataFrame(ret20, columns=pri.columns, index=future.index)
        df = df.resample('M').last()
        return df

    def get_turn20(self, pri):
        '''è®¡ç®—20æ¢æ‰‹ç‡å› å­'''
        turns = pri.rolling(20).mean()
        turns = turns.resample('M').last().reset_index()
        turns.columns = ['date'] + list(turns.columns)[1:]
        self.factors = turns
        self.get_neutral_factors()
        df = self.factors.copy()
        df = df.set_index(['date', 'code'])
        df = df.unstack()
        df.columns = list(map(lambda x: x[1], list(df.columns)))
        return df

    def get_vol20(self, pri):
        '''è®¡ç®—20æ—¥æ³¢åŠ¨ç‡å› å­'''
        rets = pri.pct_change()
        vol = rets.rolling(20).apply(np.std)
        df = vol.resample('M').last()
        return df

    def update_single_factor_in_database(self, path, pri, func):
        '''
        ç”¨åŸºç¡€æ•°æ®åº“æ›´æ–°å› å­æ•°æ®åº“
        æ‰§è¡Œé¡ºåºä¸ºï¼Œå…ˆè¯»å–æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå°±ç›´æ¥å…¨éƒ¨è®¡ç®—ï¼Œç„¶åå­˜å‚¨
        å¦‚æœæœ‰ï¼Œå°±è¯»å‡ºæ¥çœ‹çœ‹ã€‚æ•°æ®æ˜¯ä¸æ˜¯æœ€æ–°çš„
        å¦‚æœä¸æ˜¯æœ€æ–°çš„ï¼Œå°±å°†åŸå§‹æ•°æ®åœ¨ä¸Šæ¬¡å› å­å­˜å‚¨çš„æ—¥æœŸå¤„æˆªæ–­
        è®¡ç®—å‡ºæ–°çš„ä¸€æ®µæ—¶é—´çš„å› å­å€¼ï¼Œç„¶åè¿½åŠ å†™å…¥å› å­æ–‡ä»¶ä¸­
        '''
        the_func = partial(func)
        try:
            df = pd.read_feather(path)
            df.columns = ['date'] + list(df.columns)[1:]
            df = df.set_index('date')
            if df.index.max() < pri.index.max():
                to_add = pri[(pri.index > df.index.max()) & (pri.index <= pri.index.max())]
                to_add = the_func(to_add)
                df = pd.concat([df, to_add])
                print('ä¹‹å‰æ•°æ®æœ‰ç‚¹æ—§äº†ï¼Œå·²ä¸ºæ‚¨å®Œæˆæ›´æ–°')
            else:
                print('æ•°æ®å¾ˆæ–°ï¼Œæ— éœ€æ›´æ–°')
            df1 = df.reset_index()
            df1.columns = ['date'] + list(df1.columns)[1:]
            df1.to_feather(path)
            return df
        except Exception:
            df = the_func(pri)
            df1 = df.reset_index()
            df1.columns = ['date'] + list(df1.columns)[1:]
            df1.to_feather(path)
            print('æ–°å› å­å»ºåº“å®Œæˆ')
            return df

    def get_updated_factors(self):
        '''æ›´æ–°å› å­æ•°æ®'''
        self.ret20 = self.update_single_factor_in_database(self.ret20_database, self.closes, self.get_ret20)
        self.turn20 = self.update_single_factor_in_database(self.turn20_database, self.turnovers, self.get_turn20)
        self.vol20 = self.update_single_factor_in_database(self.vol20_database, self.closes, self.get_vol20)


class pure_moonnight():
    '''å°è£…é€‰è‚¡æ¡†æ¶'''
    __slots__ = ['shen']
    def __init__(self, factors, groups_num=10, neutralize=False, boxcox=False,by10=False, value_weighted=False,y2=False, plt_plot=True, plotly_plot=False,
                 filename='åˆ†ç»„å‡€å€¼å›¾', time_start=None, time_end=None, print_comments=True,comments_writer=None,net_values_writer=None,rets_writer=None,
            comments_sheetname=None,net_values_sheetname=None,rets_sheetname=None,on_paper=False):
        '''ç›´æ¥è¾“å…¥å› å­æ•°æ®'''
        if isinstance(factors,pure_fallmount):
            factors=factors().copy()
        self.shen=pure_moon()
        self.shen.set_factor_df_date_as_index(factors)
        self.shen.prerpare()
        self.shen.run(groups_num=groups_num,neutralize=neutralize,boxcox=boxcox,value_weighted=value_weighted,y2=y2,plt_plot=plt_plot,
                      plotly_plot=plotly_plot,filename=filename,time_start=time_start,time_end=time_end,print_comments=print_comments,
                      comments_writer=comments_writer,net_values_writer=net_values_writer,rets_writer=rets_writer,
                      comments_sheetname=comments_sheetname,net_values_sheetname=net_values_sheetname,rets_sheetname=rets_sheetname,on_paper=on_paper)

    def __call__(self, fallmount=0):
        '''è°ƒç”¨åˆ™è¿”å›å› å­æ•°æ®'''
        if fallmount == 0:
            return self.shen.factors
        else:
            return pure_fallmount(self.shen.factors)

class pure_newyear():
    '''è½¬ä¸ºç”Ÿæˆ25åˆ†ç»„å’Œç™¾åˆ†ç»„çš„æ”¶ç›ŠçŸ©é˜µè€Œå°è£…'''

    def __init__(self,facx,facy,group_num_single,namex='ä¸»',namey='æ¬¡'):
        '''åˆå§‹åŒ–æ—¶å³è¿›è¡Œå›æµ‹'''
        homex=pure_fallmount(facx)
        homey=pure_fallmount(facy)
        if group_num_single==5:
            homexy=homex>homey
        elif group_num_single==10:
            homexy=homex>>homey
        shen=pure_moonnight(homexy(),group_num_single**2,plt_plot=False,print_comments=False)
        sq=shen.shen.square_rets.copy()
        sq.index=[namex+str(i) for i in list(sq.index)]
        sq.columns=[namey+str(i) for i in list(sq.columns)]
        self.square_rets=sq

    def __call__(self):
        '''è°ƒç”¨å¯¹è±¡æ—¶ï¼Œè¿”å›æœ€ç»ˆç»“æœï¼Œæ­£æ–¹å½¢çš„åˆ†ç»„å¹´åŒ–æ”¶ç›Šç‡è¡¨'''
        return self.square_rets

class pure_dawn():
    '''
    å› å­åˆ‡å‰²è®ºçš„æ¯æ¡†æ¶ï¼Œå¯ä»¥å¯¹ä¸¤ä¸ªå› å­è¿›è¡Œç±»ä¼¼äºå› å­åˆ‡å‰²çš„æ“ä½œ
    å¯ç”¨äºæ´¾ç”Ÿä»»ä½•"ä»¥ä¸¤ä¸ªå› å­ç”Ÿæˆä¸€ä¸ªå› å­"çš„å­ç±»
    ä½¿ç”¨ä¸¾ä¾‹
    ç»„åˆæ–¹æ¡ˆå››ï¼Œå› å­åˆ‡å‰²ï¼Œæ­£å‘çš„pctä¸è´Ÿå‘çš„pctï¼Œç”¨å¤©æ•°åŠ æƒï¼Œå³ä¹˜ä»¥å¤©æ•°ï¼Œæ­£å‘ä¿¡æ¯æ¯”ç‡1.89ï¼Œè´Ÿå‘ä¿¡æ¯æ¯”ç‡1.41ï¼Œç»„åˆåä¿¡æ¯æ¯”ç‡1.62###
    class dawn_tr_pct_cut(pure_dawn):
        def __init__(self,fac1,fac2):
            self.fac1=fac1
            self.fac2=fac2
            super(dawn_tr_pct_cut,self).__init__(fac1=fac1,fac2=fac2)

        def positive_cut(self,df):
            #pctä¸ºæ­£çš„éƒ¨åˆ†ï¼Œç”Ÿæˆæœˆåº¦å› å­
            df=df[df.fac2>0]
            return df.fac1.mean()*df.shape[0]

        def negative_cut(self,df):
            #pctä¸ºè´Ÿçš„éƒ¨åˆ†ï¼Œç”Ÿæˆæœˆåº¦å› å­
            df=df[df.fac2<0]
            return df.fac1.mean()*df.shape[0]

    tr_pct_cut_positive_weighted=dawn_tr_pct_cut(tr,pct)
    tr_pct_cut_positive_weighted.run(tr_pct_cut_positive_weighted.positive_cut)
    '''

    def __init__(self,fac1,fac2,*args):
        self.fac1=fac1
        self.fac1=self.fac1.stack().reset_index()
        self.fac1.columns=['date','code','fac1']
        self.fac2=fac2
        self.fac2=self.fac2.stack().reset_index()
        self.fac2.columns=['date','code','fac2']
        fac_all=pd.merge(self.fac1,self.fac2,on=['date','code'])
        for i,fac in enumerate(args):
            fac=fac.stack().reset_index()
            fac.columns=['date','code',f'fac{i+3}']
            fac_all=pd.merge(fac_all,fac,on=['date','code'])
        fac_all=fac_all.sort_values(['date','code'])
        self.fac=fac_all.copy()

    def __call__(self):
        '''è¿”å›æœ€ç»ˆæœˆåº¦å› å­å€¼'''
        return self.fac

    def get_fac_long_and_tradedays(self):
        '''å°†ä¸¤ä¸ªå› å­çš„çŸ©é˜µè½¬åŒ–ä¸ºé•¿åˆ—è¡¨'''
        self.tradedays=sorted(list(set(self.fac.date)))

    def get_month_starts_and_ends(self,backsee=20):
        '''è®¡ç®—å‡ºæ¯ä¸ªæœˆå›çœ‹æœŸé—´çš„èµ·ç‚¹æ—¥å’Œç»ˆç‚¹æ—¥'''
        self.month_ends=[i for i,j in zip(self.tradedays[:-1],self.tradedays[1:]) if i.month!=j.month]
        self.month_ends.append(self.tradedays[-1])
        self.month_starts=[self.find_begin(self.tradedays,i,backsee=backsee) for i in self.month_ends]
        self.month_starts[0]=self.tradedays[0]

    def find_begin(self,tradedays,end_day,backsee=20):
        '''æ‰¾å‡ºå›çœ‹è‹¥å¹²å¤©çš„å¼€å§‹æ—¥ï¼Œé»˜è®¤ä¸º20'''
        end_day_index=tradedays.index(end_day)
        start_day_index=end_day_index-backsee+1
        start_day=tradedays[start_day_index]
        return start_day

    def make_monthly_factors_single_code(self,df,func):
        '''
        å¯¹å•ä¸€è‚¡ç¥¨æ¥è®¡ç®—æœˆåº¦å› å­
        funcä¸ºå•æœˆæ‰§è¡Œçš„å‡½æ•°ï¼Œè¿”å›å€¼åº”ä¸ºæœˆåº¦å› å­ï¼Œå¦‚ä¸€ä¸ªfloatæˆ–ä¸€ä¸ªlist
        dfä¸ºä¸€ä¸ªè‚¡ç¥¨çš„å››åˆ—è¡¨ï¼ŒåŒ…å«æ—¶é—´ã€ä»£ç ã€å› å­1å’Œå› å­2
        '''
        res={}
        for start,end in zip(self.month_starts,self.month_ends):
            this_month=df[(df.date>=start)&(df.date<=end)]
            res[end]=func(this_month)
        dates=list(res.keys())
        corrs=list(res.values())
        part=pd.DataFrame({'date':dates,'corr':corrs})
        return part

    def get_monthly_factor(self,func):
        '''è¿è¡Œè‡ªå·±å†™çš„å‡½æ•°ï¼Œè·å¾—æœˆåº¦å› å­'''
        tqdm.tqdm.pandas(desc='when the dawn comes, tonight will be a memory too.')
        self.fac=self.fac.groupby(['code']).progress_apply(lambda x:self.make_monthly_factors_single_code(x,func))
        self.fac=self.fac.reset_index(level=1,drop=True).reset_index().set_index(['date','code']).unstack()
        self.fac.columns=[i[1] for i in list(self.fac.columns)]
        self.fac=self.fac.resample('M').last()

    def run(self,func,backsee=20):
        '''è¿è¡Œå¿…è¦çš„å‡½æ•°'''
        self.get_fac_long_and_tradedays()
        self.get_month_starts_and_ends(backsee=backsee)
        self.get_monthly_factor(func)


