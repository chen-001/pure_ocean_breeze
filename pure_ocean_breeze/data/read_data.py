__updated__ = "2022-08-16 15:50:56"

import numpy as np
import pandas as pd
import scipy.io as scio
import datetime
from loguru import logger

from cachier import cachier
import pickledb
import rqdatac

rqdatac.init()
from pure_ocean_breeze.state.state import STATES
from pure_ocean_breeze.state.homeplace import HomePlace
from pure_ocean_breeze.state.decorators import *

homeplace = HomePlace()


@cachier()
def read_daily(
    path: str = None,
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    tr: bool = 0,
    sharenum: bool = 0,
    volume: bool = 0,
    unadjust: bool = 0,
    start: int = STATES["START"],
) -> pd.DataFrame:
    """ç›´æ¥è¯»å–å¸¸ç”¨çš„é‡ä»·è¯»å–æ—¥é¢‘æ•°æ®ï¼Œé»˜è®¤ä¸ºå¤æƒä»·æ ¼ï¼Œ
    åœ¨ open,close,high,low,tr,sharenum,volume ä¸­é€‰æ‹©ä¸€ä¸ªå‚æ•°æŒ‡å®šä¸º1

    Parameters
    ----------
    path : str, optional
        è¦è¯»å–æ–‡ä»¶çš„è·¯å¾„ï¼Œç”±äºå¸¸ç”¨çš„é«˜å¼€ä½æ”¶æ¢æ‰‹ç‡ç­‰éƒ½å·²ç»å°è£…ï¼Œå› æ­¤æ­¤å¤„é€šå¸¸ä¸ºNone, by default None
    open : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å¼€ç›˜ä»·, by default 0
    close : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ”¶ç›˜ä»·, by default 0
    high : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€é«˜ä»·, by default 0
    low : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€ä½ä»·, by default 0
    tr : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ¢æ‰‹ç‡, by default 0
    sharenum : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šè‚¡æ•°, by default 0
    volume : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æˆäº¤é‡, by default 0
    unadjust : bool, optional
        ä¸º1åˆ™å°†ä¸Šè¿°ä»·æ ¼æ”¹ä¸ºä¸å¤æƒä»·æ ¼, by default 0
    start : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default STATES["START"]

    Returns
    -------
    pd.DataFrame
        ä¸€ä¸ªcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œindexä¸ºæ—¶é—´ï¼Œvaluesä¸ºç›®æ ‡æ•°æ®çš„pd.DataFrame

    Raises
    ------
    IOError
        open,close,high,low,tr,sharenum,volume éƒ½ä¸º0æ—¶ï¼Œå°†æŠ¥é”™
    å¦ï¼šå¦‚æœæ•°æ®æœªæ›´æ–°ï¼Œå¯ä½¿ç”¨read_daily.clear_cache()æ¥æ¸…ç©ºç¼“å­˜
    """

    def read_mat(path):
        homeplace = HomePlace()
        col = list(
            scio.loadmat(homeplace.daily_data_file + "AllStockCode.mat").values()
        )[3]
        index = list(
            scio.loadmat(homeplace.daily_data_file + "TradingDate_Daily.mat").values()
        )[3]
        col = [i[0] for i in col[0]]
        index = index[0].tolist()
        path = homeplace.daily_data_file + path
        data = list(scio.loadmat(path).values())[3]
        data = pd.DataFrame(data, index=index, columns=col)
        data.index = pd.to_datetime(data.index, format="%Y%m%d")
        data = data.replace(0, np.nan)
        data = data[data.index >= pd.Timestamp(str(start))]
        return data

    if not unadjust:
        if path:
            return read_mat(path)
        elif open:
            trs = read_mat("AllStock_DailyTR.mat")
            opens = read_mat("AllStock_DailyOpen_dividend.mat")
            return np.sign(trs) * opens
        elif close:
            trs = read_mat("AllStock_DailyTR.mat")
            closes = read_mat("AllStock_DailyClose_dividend.mat")
            return np.sign(trs) * closes
        elif high:
            trs = read_mat("AllStock_DailyTR.mat")
            highs = read_mat("AllStock_DailyHigh_dividend.mat")
            return np.sign(trs) * highs
        elif low:
            trs = read_mat("AllStock_DailyTR.mat")
            lows = read_mat("AllStock_DailyLow_dividend.mat")
            return np.sign(trs) * lows
        elif tr:
            trs = read_mat("AllStock_DailyTR.mat")
            return trs
        elif sharenum:
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            return sharenums
        elif volume:
            volumes = read_mat("AllStock_DailyVolume.mat")
            return volumes
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")
    else:
        if path:
            return read_mat(path)
        elif open:
            trs = read_mat("AllStock_DailyTR.mat")
            opens = read_mat("AllStock_DailyOpen.mat")
            return np.sign(trs) * opens
        elif close:
            trs = read_mat("AllStock_DailyTR.mat")
            closes = read_mat("AllStock_DailyClose.mat")
            return np.sign(trs) * closes
        elif high:
            trs = read_mat("AllStock_DailyTR.mat")
            highs = read_mat("AllStock_DailyHigh.mat")
            return np.sign(trs) * highs
        elif low:
            trs = read_mat("AllStock_DailyTR.mat")
            lows = read_mat("AllStock_DailyLow.mat")
            return np.sign(trs) * lows
        elif tr:
            trs = read_mat("AllStock_DailyTR.mat")
            return trs
        elif sharenum:
            sharenums = read_mat("AllStock_DailyAShareNum.mat")
            return sharenums
        elif volume:
            volumes = read_mat("AllStock_DailyVolume.mat")
            return volumes
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸğŸ¤’")


def read_index_three(day: int = None) -> tuple[pd.DataFrame]:
    """è¯»å–ä¸‰å¤§æŒ‡æ•°çš„åŸå§‹è¡Œæƒ…æ•°æ®ï¼Œè¿”å›å¹¶ä¿å­˜åœ¨æœ¬åœ°

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None

    Returns
    -------
    tuple[pd.DataFrame]
        åˆ†åˆ«è¿”å›æ²ªæ·±300ã€ä¸­è¯500ã€ä¸­è¯1000çš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    res = pd.read_feather(homeplace.daily_data_file + "3510è¡Œæƒ….feather").set_index(
        "date"
    )
    hs300, zz500, zz1000 = res.æ²ªæ·±300, res.ä¸­è¯500, res.ä¸­è¯1000
    hs300 = hs300[hs300.index >= pd.Timestamp(str(day))]
    zz500 = zz500[zz500.index >= pd.Timestamp(str(day))]
    zz1000 = zz1000[zz1000.index >= pd.Timestamp(str(day))]

    def to_one(df):
        df = df / df.iloc[0]
        return df

    w = pd.ExcelWriter("3510åŸå§‹è¡Œæƒ….xlsx")
    hs300.to_excel(w, sheet_name="300")
    zz500.to_excel(w, sheet_name="500")
    zz1000.to_excel(w, sheet_name="1000")
    w.save()
    w.close()
    return hs300, zz500, zz1000


def read_industry_prices(day: int = None, monthly: bool = 1) -> pd.DataFrame:
    """è¯»å–ç”³ä¸‡ä¸€çº§è¡Œä¸šæŒ‡æ•°çš„æ—¥è¡Œæƒ…æˆ–æœˆè¡Œæƒ…

    Parameters
    ----------
    day : int, optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default None
    monthly : bool, optional
        æ˜¯å¦ä¸ºæœˆè¡Œæƒ…, by default 1

    Returns
    -------
    pd.DataFrame
        ç”³ä¸‡ä¸€çº§è¡Œä¸šçš„è¡Œæƒ…æ•°æ®
    """
    if day is None:
        day = STATES["START"]
    df = pd.read_feather(homeplace.daily_data_file + "å„è¡Œä¸šè¡Œæƒ…æ•°æ®.feather").set_index(
        "date"
    )
    if monthly:
        df = df.resample("M").last()
    return df


def get_industry_dummies(daily: bool = 0, monthly: bool = 0) -> dict:
    """ç”Ÿæˆ31ä¸ªè¡Œä¸šçš„å“‘å˜é‡çŸ©é˜µï¼Œè¿”å›ä¸€ä¸ªå­—å…¸

    Parameters
    ----------
    daily : bool, optional
        è¿”å›æ—¥é¢‘çš„å“‘å˜é‡, by default 0
    monthly : bool, optional
        è¿”å›æœˆé¢‘çš„å“‘å˜é‡, by default 0

    Returns
    -------
    dict
        å„ä¸ªè¡Œä¸šåŠå…¶å“‘å˜é‡æ„æˆçš„å­—å…¸

    Raises
    ------
    ValueError
        å¦‚æœæœªæŒ‡å®šé¢‘ç‡ï¼Œå°†æŠ¥é”™
    """
    homeplace = HomePlace()
    if monthly:
        industry_dummy = pd.read_feather(
            homeplace.daily_data_file + "ç”³ä¸‡è¡Œä¸š2021ç‰ˆå“‘å˜é‡.feather"
        )
        industry_dummy = (
            industry_dummy.set_index("date")
            .groupby("code")
            .resample("M")
            .last()
            .fillna(0)
            .drop(columns=["code"])
            .reset_index()
        )
    elif daily:
        industry_dummy = pd.read_feather(
            homeplace.daily_data_file + "ç”³ä¸‡è¡Œä¸š2021ç‰ˆå“‘å˜é‡.feather"
        ).fillna(0)
    else:
        raise ValueError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸ªé¢‘ç‡å§ï¼ŸğŸ¤’")
    ws = list(industry_dummy.columns)[2:]
    ress = {}
    for w in ws:
        df = industry_dummy[["date", "code", w]]
        df = df.pivot(index="date", columns="code", values=w)
        df = df.replace(0, np.nan)
        ress[w] = df
    return ress


def database_save_final_factors(df: pd.DataFrame, name: str, order: int) -> None:
    """ä¿å­˜æœ€ç»ˆå› å­çš„å› å­å€¼

    Parameters
    ----------
    df : pd.DataFrame
        æœ€ç»ˆå› å­å€¼
    name : str
        å› å­çš„åå­—ï¼Œå¦‚â€œé€‚åº¦å†’é™©â€
    order : int
        å› å­çš„åºå·
    """
    homeplace = HomePlace()
    path = homeplace.final_factor_file + name + "_" + "å¤šå› å­" + str(order) + ".feather"
    df.reset_index().to_feather(path)
    final_date = df.index.max()
    final_date = datetime.datetime.strftime(final_date, "%Y%m%d")
    config = pickledb.load(homeplace.update_data_file + "database_config.db", False)
    config.set("data_refresh", "done")
    config.dump()
    logger.success(f"ä»Šæ—¥è®¡ç®—çš„å› å­å€¼ä¿å­˜ï¼Œæœ€æ–°ä¸€å¤©ä¸º{final_date}")
