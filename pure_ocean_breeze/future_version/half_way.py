__updated__ = "2023-02-27 15:22:19"

import numpy as np
import pandas as pd
import time
from sqlalchemy import FLOAT, INT, VARCHAR, BIGINT
import knockknock as kk
import matplotlib.pyplot as plt

plt.style.use(["science", "no-latex", "notebook"])
plt.rcParams["axes.unicode_minus"] = False
import plotly.express as pe
import plotly.io as pio
import tqdm
import os
from loguru import logger
import datetime
from typing import Callable
from functools import reduce,partial
from pure_ocean_breeze.data.database import ClickHouseClient,Questdb
from pure_ocean_breeze.data.tools import drop_duplicates_index
from pure_ocean_breeze.labor.process import pure_moon, decap_industry
from pure_ocean_breeze.data.read_data import read_daily
from pure_ocean_breeze.state.homeplace import HomePlace
from pure_ocean_breeze.data.database import PostgreSQL

try:
    import rqdatac

    rqdatac.init()
except Exception as e:
    print(e)
    desicion = input("ç±³ç­è¿æ¥æš‚æ—¶æœ‰é”™è¯¯ï¼Œæ˜¯å¦ç­‰å¾…å¹¶ç»§ç»­è¿æ¥ï¼Œç­‰å¾…è¯·è¾“å…¥yï¼Œä¸ç­‰å¾…åˆ™è¾“å…¥n")
    if desicion == "y":
        print("è¿æ¥ç±³ç­æš‚æ—¶æœ‰é”™è¯¯ï¼Œå°†ç­‰å¾…30ç§’åé‡è¯•")
        time.sleep(30)
        try:
            import rqdatac

            rqdatac.init()
        except Exception as e:
            print(e)
            print("è¿æ¥ç±³ç­æš‚æ—¶æœ‰é”™è¯¯ï¼Œå°†ç­‰å¾…60ç§’åé‡è¯•")
            time.sleep(60)
            try:
                import rqdatac

                rqdatac.init()
            except Exception as e:
                print(e)
                print("è¿æ¥ç±³ç­æš‚æ—¶æœ‰é”™è¯¯ï¼Œå°†ç­‰å¾…60ç§’åé‡è¯•")
                time.sleep(60)
                try:
                    import rqdatac

                    rqdatac.init()
                except Exception as e:
                    print(e)
                    print("æš‚æ—¶æœªè¿æ¥ç±³ç­")
    else:
        print("æš‚æ—¶æœªè¿æ¥ç±³ç­")


class pure_cloud(object):
    """
    ä¸ºäº†æµ‹è¯•å…¶ä»–ä¸åŒçš„é¢‘ç‡è€Œè®¾è®¡çš„ç±»ï¼Œä»…è€ƒè™‘äº†ä¸Šå¸‚æ»¡60å¤©è¿™ä¸€è¦ç´ 
    è¿™ä¸€å›æµ‹é‡‡å–çš„æ–¹æ¡ˆæ˜¯ï¼Œå¯¹äºå›æµ‹é¢‘ç‡nå¤©ï¼Œå°†åˆå§‹èµ„é‡‘ç­‰åˆ†æˆnç¬”ï¼Œæ¯å¤©ä»¥1/nçš„èµ„é‡‘è°ƒä»“
    æ¯ç¬”èµ„é‡‘ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œæœ€ç»ˆæ±‡èšæˆä¸€ä¸ªæ”¶ç›Šç‡åºåˆ—
    """

    def __init__(
        self,
        fac,
        freq,
        group=10,
        boxcox=1,
        trade_cost=0,
        print_comments=1,
        plt_plot=1,
        plotly_plot=0,
        filename="å‡€å€¼èµ°åŠ¿å›¾",
        comments_writer=None,
        nets_writer=None,
        sheet_name=None,
    ):
        """næ˜¯å›æµ‹çš„é¢‘ç‡ï¼Œç­‰åˆ†æˆnä»½ï¼Œgroupæ˜¯å›æµ‹çš„ç»„æ•°ï¼Œboxcoxæ˜¯æ˜¯å¦åšè¡Œä¸šå¸‚å€¼ä¸­æ€§åŒ–"""
        self.fac = fac
        self.freq = freq
        self.group = group
        self.boxcox = boxcox
        self.trade_cost = trade_cost
        ages = read_daily(age=1)
        sts = read_daily(st=1)
        states = read_daily(state=1)
        opens = read_daily(open=1)
        closes = read_daily(close=1)
        capitals = read_daily(flow_cap=1).resample("M").last()
        moon = pure_moon()
        moon.set_basic_data(
            age=ages,
            st=sts,
            state=states,
            open=opens,
            close=closes,
            capital=capitals,
        )
        moon.prerpare()
        ages = moon.ages.copy()
        ages = (ages >= 60) + 0
        self.ages = ages.replace(0, np.nan)
        self.closes = read_daily(close=1)
        self.rets = (
            (self.closes.shift(-self.freq) / self.closes - 1) * self.ages
        ) / self.freq
        self.run(
            print_comments=print_comments,
            plt_plot=plt_plot,
            plotly_plot=plotly_plot,
            filename=filename,
        )
        if comments_writer:
            if sheet_name:
                self.long_short_comments.to_excel(
                    comments_writer, sheet_name=sheet_name
                )
            else:
                raise AttributeError("å¿…é¡»åˆ¶å®šsheet_nameå‚æ•°ğŸ¤’")
        if nets_writer:
            if sheet_name:
                self.group_nets.to_excel(nets_writer, sheet_name=sheet_name)
            else:
                raise AttributeError("å¿…é¡»åˆ¶å®šsheet_nameå‚æ•°ğŸ¤’")

    def comments(self, series, series1):
        """å¯¹twinsä¸­çš„ç»“æœç»™å‡ºè¯„ä»·
        è¯„ä»·æŒ‡æ ‡åŒ…æ‹¬å¹´åŒ–æ”¶ç›Šç‡ã€æ€»æ”¶ç›Šç‡ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€å¹´åŒ–å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ç‡ã€èƒœç‡"""
        ret = (series.iloc[-1] - series.iloc[0]) / series.iloc[0]
        duration = (series.index[-1] - series.index[0]).days
        year = duration / 365
        ret_yearly = (series.iloc[-1] / series.iloc[0]) ** (1 / year) - 1
        max_draw = -(series / series.expanding(1).max() - 1).min()
        vol = np.std(series1) * (250**0.5)
        sharpe = ret_yearly / vol
        wins = series1[series1 > 0]
        win_rate = len(wins) / len(series1)
        return pd.Series(
            [ret, ret_yearly, vol, sharpe, max_draw, win_rate],
            index=["æ€»æ”¶ç›Šç‡", "å¹´åŒ–æ”¶ç›Šç‡", "å¹´åŒ–æ³¢åŠ¨ç‡", "ä¿¡æ¯æ¯”ç‡", "æœ€å¤§å›æ’¤ç‡", "èƒœç‡"],
        )

    @kk.desktop_sender(title="å˜¿ï¼Œå˜é¢‘å›æµ‹ç»“æŸå•¦ï½ğŸ—“")
    def run(self, print_comments, plt_plot, plotly_plot, filename):
        """å¯¹å› å­å€¼åˆ†ç»„å¹¶åŒ¹é…"""
        if self.boxcox:
            self.fac = decap_industry(self.fac,daily=1)
        self.fac = self.fac.T.apply(
            lambda x: pd.qcut(x, self.group, labels=False, duplicates="drop")
        ).T
        self.fac = self.fac.shift(1)
        self.vs = [
            (((self.fac == i) + 0).replace(0, np.nan) * self.rets).mean(axis=1)
            for i in range(self.group)
        ]
        self.group_rets = pd.DataFrame(
            {f"group{k}": list(v) for k, v in zip(range(1, self.group + 1), self.vs)},
            index=self.vs[0].index,
        )
        self.group_rets = self.group_rets.dropna(how="all")
        self.group_rets = self.group_rets
        self.group_nets = (self.group_rets + 1).cumprod()
        self.group_nets = self.group_nets.apply(lambda x: x / x.iloc[0])
        self.one = self.group_nets["group1"]
        self.end = self.group_nets[f"group{self.group}"]
        if self.one.iloc[-1] > self.end.iloc[-1]:
            self.long_name = "group1"
            self.short_name = f"group{self.group}"
        else:
            self.long_name = f"group{self.group}"
            self.short_name = "group1"
        self.long_short_ret = (
            self.group_rets[self.long_name] - self.group_rets[self.short_name]
        )
        self.long_short_net = (self.long_short_ret + 1).cumprod()
        self.long_short_net = self.long_short_net / self.long_short_net.iloc[0]
        if self.long_short_net.iloc[-1] < 1:
            self.long_short_ret = (
                self.group_rets[self.short_name] - self.group_rets[self.long_name]
            )
            self.long_short_net = (self.long_short_ret + 1).cumprod()
            self.long_short_net = self.long_short_net / self.long_short_net.iloc[0]
            self.long_short_ret = (
                self.group_rets[self.short_name]
                - self.group_rets[self.long_name]
                - 2 * self.trade_cost / self.freq
            )
            self.long_short_net = (self.long_short_ret + 1).cumprod()
            self.long_short_net = self.long_short_net / self.long_short_net.iloc[0]
        else:
            self.long_short_ret = (
                self.group_rets[self.long_name]
                - self.group_rets[self.short_name]
                - 2 * self.trade_cost / self.freq
            )
            self.long_short_net = (self.long_short_ret + 1).cumprod()
            self.long_short_net = self.long_short_net / self.long_short_net.iloc[0]
        self.group_rets = pd.concat(
            [self.group_rets, self.long_short_ret.to_frame("long_short")], axis=1
        )
        self.group_nets = pd.concat(
            [self.group_nets, self.long_short_net.to_frame("long_short")], axis=1
        )
        self.long_short_comments = self.comments(
            self.long_short_net, self.long_short_ret
        )
        if print_comments:
            print(self.long_short_comments)
        if plt_plot:
            self.group_nets.plot(rot=60)
            plt.savefig(filename + ".png")
            plt.show()
        if plotly_plot:
            fig = pe.line(self.group_nets)
            filename_path = filename + ".html"
            pio.write_html(fig, filename_path, auto_open=True)


class pure_moonson(object):
    """è¡Œä¸šè½®åŠ¨å›æµ‹æ¡†æ¶"""

    def __init__(self, fac, group_num=5):
        homeplace = HomePlace()
        pindu = (
            pd.read_parquet(homeplace.daily_data_file + "å„è¡Œä¸šè¡Œæƒ…æ•°æ®.parquet")
            .resample("M")
            .last()
        )
        rindu = pindu / pindu.shift(1) - 1
        self.rindu = rindu
        self.fac = fac
        self.group = self.get_groups(fac, group_num)
        print("æœªå®Œå·¥ï¼Œå¾…å®Œå–„ï¼Œæš‚æ—¶è¯·å‹¿ä½¿ç”¨âš ï¸")

    def get_groups(self, df, groups_num):
        """ä¾æ®å› å­å€¼ï¼Œåˆ¤æ–­æ˜¯åœ¨ç¬¬å‡ ç»„"""
        if "group" in list(df.columns):
            df = df.drop(columns=["group"])
        df = df.sort_values(["fac"], ascending=True)
        each_group = round(df.shape[0] / groups_num)
        l = list(
            map(
                lambda x, y: [x] * y,
                list(range(1, groups_num + 1)),
                [each_group] * groups_num,
            )
        )
        l = reduce(lambda x, y: x + y, l)
        if len(l) < df.shape[0]:
            l = l + [groups_num] * (df.shape[0] - len(l))
        l = l[: df.shape[0]]
        df.insert(0, "group", l)
        return df


class pure_fall_flexible(object):
    def __init__(
        self,
        factor_file: str,
        startdate: int = None,
        enddate: int = None,
        kind: str = "stock",
        clickhouse: bool = 0,
        questdb: bool = 0,
    ) -> None:
        """åŸºäºclickhouseçš„åˆ†é’Ÿæ•°æ®ï¼Œè®¡ç®—å› å­å€¼ï¼Œæ¯å¤©çš„å› å­å€¼ç”¨åˆ°å¤šæ—¥çš„æ•°æ®ï¼Œæˆ–è€…ç”¨åˆ°æˆªé¢çš„æ•°æ®
        å¯¹ä¸€æ®µæ—¶é—´çš„æˆªé¢æ•°æ®è¿›è¡Œæ“ä½œï¼Œåœ¨get_daily_factorsçš„funcå‡½æ•°ä¸­
        è¯·å†™å…¥df=df.groupby([xxx]).apply(fff)ä¹‹ç±»çš„è¯­å¥
        ç„¶åå•ç‹¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œä½œä¸ºè¦applyçš„fffï¼Œå¯ä»¥åœ¨applyä¸ŠåŠ è¿›åº¦æ¡

        Parameters
        ----------
        factor_file : str
            ç”¨äºå­˜å‚¨å› å­çš„æ–‡ä»¶åç§°ï¼Œè¯·ä»¥'.parquet'ç»“å°¾
        startdate : int, optional
            è®¡ç®—å› å­çš„èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20220816, by default None
        enddate : int, optional
            è®¡ç®—å› å­çš„ç»ˆæ­¢æ—¥æœŸï¼Œå½¢å¦‚20220816, by default None
        kind : str, optional
            æŒ‡å®šè®¡ç®—è‚¡ç¥¨è¿˜æ˜¯æŒ‡æ•°ï¼ŒæŒ‡æ•°åˆ™ä¸º'index', by default "stock"
        clickhouse : bool, optional
            ä½¿ç”¨clickhouseä½œä¸ºæ•°æ®æºï¼Œå¦‚æœpostgresqlä¸æœ¬å‚æ•°éƒ½ä¸º0ï¼Œå°†ä¾ç„¶ä»clickhouseä¸­è¯»å–, by default 0
        questdb : bool, optional
            ä½¿ç”¨questdbä½œä¸ºæ•°æ®æº, by default 0
        """
        homeplace = HomePlace()
        self.kind = kind
        if clickhouse == 0 and questdb == 0:
            clickhouse = 1
        self.clickhouse = clickhouse
        self.questdb = questdb
        if clickhouse == 1:
            # è¿æ¥clickhouse
            self.chc = ClickHouseClient("minute_data")
        elif questdb:
            self.chc = Questdb()
        # å®Œæ•´çš„å› å­æ–‡ä»¶è·¯å¾„
        factor_file = homeplace.factor_data_file + factor_file
        self.factor_file = factor_file
        # è¯»å…¥ä¹‹å‰çš„å› å­
        if os.path.exists(factor_file):
            factor_old = drop_duplicates_index(pd.read_parquet(self.factor_file))
            self.factor_old = factor_old
            # å·²ç»ç®—å¥½çš„æ—¥å­
            dates_old = sorted(list(factor_old.index.strftime("%Y%m%d").astype(int)))
            self.dates_old = dates_old
        else:
            self.factor_old = None
            self.dates_old = []
            logger.info("è¿™ä¸ªå› å­ä»¥å‰æ²¡æœ‰ï¼Œæ­£åœ¨é‡æ–°è®¡ç®—")
        # è¯»å–å½“å‰æ‰€æœ‰çš„æ—¥å­
        dates_all = self.chc.show_all_dates(f"minute_data_{kind}")
        if startdate is None:
            ...
        else:
            dates_all = [i for i in dates_all if i >= startdate]
        if enddate is None:
            ...
        else:
            dates_all = [i for i in dates_all if i <= enddate]
        self.dates_all = dates_all
        # éœ€è¦æ–°è¡¥å……çš„æ—¥å­
        self.dates_new = sorted([i for i in dates_all if i not in dates_old])

    def __call__(self) -> pd.DataFrame:
        """ç›´æ¥è¿”å›å› å­å€¼çš„pd.DataFrame

        Returns
        -------
        `pd.DataFrame`
            è®¡ç®—å‡ºçš„å› å­å€¼
        """
        return self.factor.copy()

    @kk.desktop_sender(title="å˜¿ï¼Œåˆ†é’Ÿæ•°æ®å¤„ç†å®Œå•¦ï½ğŸˆ")
    def get_daily_factors(
        self,
        func: Callable,
        fields: str = "*",
        chunksize: int = 250,
        show_time: bool = 0,
        tqdm_inside: bool = 0,
    ) -> None:
        """æ¯æ¬¡æŠ½å–chunksizeå¤©çš„æˆªé¢ä¸Šå…¨éƒ¨è‚¡ç¥¨çš„åˆ†é’Ÿæ•°æ®
        ä¾ç…§å®šä¹‰çš„å‡½æ•°è®¡ç®—å› å­å€¼

        Parameters
        ----------
        func : Callable
            ç”¨äºè®¡ç®—å› å­å€¼çš„å‡½æ•°
        fields : str, optional
            è‚¡ç¥¨æ•°æ®æ¶‰åŠåˆ°å“ªäº›å­—æ®µï¼Œæ’é™¤ä¸å¿…è¦çš„å­—æ®µï¼Œå¯ä»¥èŠ‚çº¦è¯»å–æ•°æ®çš„æ—¶é—´ï¼Œå½¢å¦‚'date,code,num,close,amount,open'
            æå–å‡ºçš„æ•°æ®ï¼Œè‡ªåŠ¨æŒ‰ç…§code,date,numæ’åºï¼Œå› æ­¤code,date,numæ˜¯å¿…ä¸å¯å°‘çš„å­—æ®µ, by default "*"
        chunksize : int, optional
            æ¯æ¬¡è¯»å–çš„æˆªé¢ä¸Šçš„å¤©æ•°, by default 10
        show_time : bool, optional
            å±•ç¤ºæ¯æ¬¡è¯»å–æ•°æ®æ‰€éœ€è¦çš„æ—¶é—´, by default 0
        tqdm_inside : bool, optional
            å°†è¿›åº¦æ¡åŠ åœ¨å†…éƒ¨ï¼Œè€Œéå¤–éƒ¨ï¼Œå»ºè®®ä»…chunksizeè¾ƒå¤§æ—¶ä½¿ç”¨, by default 0
        """
        the_func = partial(func)
        # å°†éœ€è¦æ›´æ–°çš„æ—¥å­åˆ†å—ï¼Œæ¯200å¤©ä¸€ç»„ï¼Œä¸€èµ·è¿ç®—
        dates_new_len = len(self.dates_new)
        if dates_new_len > 0:
            cut_points = list(range(0, dates_new_len, chunksize)) + [dates_new_len - 1]
            if cut_points[-1] == cut_points[-2]:
                cut_points = cut_points[:-1]
            self.cut_points = cut_points
            self.factor_new = []
            # å¼€å§‹è®¡ç®—å› å­å€¼
            if tqdm_inside:
                # å¼€å§‹è®¡ç®—å› å­å€¼
                for date1, date2 in cut_points:
                    if self.clickhouse == 1:
                        sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date>{self.dates_new[date1]*100} and date<={self.dates_new[date2]*100} order by code,date,num"
                    else:
                        sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date>{self.dates_new[date1]} and date<={self.dates_new[date2]}"
                    if show_time:
                        df = self.chc.get_data_show_time(sql_order)
                    else:
                        df = self.chc.get_data(sql_order)
                    if self.clickhouse == 1:
                        df = ((df.set_index("code")) / 100).reset_index()
                    tqdm.auto.tqdm.pandas()
                    df = the_func(df)
                    if isinstance(df, pd.Series):
                        df = df.reset_index()
                    df.columns = ["date", "code", "fac"]
                    df = df.pivot(columns="code", index="date", values="fac")
                    df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
                    self.factor_new.append(df)
            else:
                # å¼€å§‹è®¡ç®—å› å­å€¼
                for date1, date2 in tqdm.auto.tqdm(cut_points, desc="ä¸çŸ¥ä¹˜æœˆå‡ äººå½’ï¼Œè½æœˆæ‘‡æƒ…æ»¡æ±Ÿæ ‘ã€‚"):
                    if self.clickhouse == 1:
                        sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date>{self.dates_new[date1]*100} and date<={self.dates_new[date2]*100} order by code,date,num"
                    else:
                        sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date>{self.dates_new[date1]} and date<={self.dates_new[date2]} order by code,date,num"
                    if show_time:
                        df = self.chc.get_data_show_time(sql_order)
                    else:
                        df = self.chc.get_data(sql_order)
                    if self.clickhouse == 1:
                        df = ((df.set_index("code")) / 100).reset_index()
                    df = the_func(df)
                    if isinstance(df, pd.Series):
                        df = df.reset_index()
                    df.columns = ["date", "code", "fac"]
                    df = df.pivot(columns="code", index="date", values="fac")
                    df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
                    self.factor_new.append(df)
            self.factor_new = pd.concat(self.factor_new)
            # æ‹¼æ¥æ–°çš„å’Œæ—§çš„
            self.factor = pd.concat([self.factor_old, self.factor_new]).sort_index()
            new_end_date = datetime.datetime.strftime(self.factor.index.max(), "%Y%m%d")
            # å­˜å…¥æœ¬åœ°
            self.factor.to_parquet(self.factor_file)
            logger.info(f"æˆªæ­¢åˆ°{new_end_date}çš„å› å­å€¼è®¡ç®—å®Œäº†")
        elif dates_new_len == 1:
            print("å…±1å¤©")
            if tqdm_inside:
                # å¼€å§‹è®¡ç®—å› å­å€¼
                if self.clickhouse == 1:
                    sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date={self.dates_new[0]*100} order by code,date,num"
                else:
                    sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date={self.dates_new[0]} order by code,date,num"
                if show_time:
                    df = self.chc.get_data_show_time(sql_order)
                else:
                    df = self.chc.get_data(sql_order)
                if self.clickhouse == 1:
                    df = ((df.set_index("code")) / 100).reset_index()
                tqdm.auto.tqdm.pandas()
                df = the_func(df)
                if isinstance(df, pd.Series):
                    df = df.reset_index()
                df.columns = ["date", "code", "fac"]
                df = df.pivot(columns="code", index="date", values="fac")
                df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
            else:
                # å¼€å§‹è®¡ç®—å› å­å€¼
                if self.clickhouse == 1:
                    sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date={self.dates_new[0]*100} order by code,date,num"
                else:
                    sql_order = f"select {fields} from minute_data.minute_data_{self.kind} where date={self.dates_new[0]} order by code,date,num"
                if show_time:
                    df = self.chc.get_data_show_time(sql_order)
                else:
                    df = self.chc.get_data(sql_order)
                if self.clickhouse == 1:
                    df = ((df.set_index("code")) / 100).reset_index()
                df = the_func(df)
                if isinstance(df, pd.Series):
                    df = df.reset_index()
                df.columns = ["date", "code", "fac"]
                df = df.pivot(columns="code", index="date", values="fac")
                df.index = pd.to_datetime(df.index.astype(str), format="%Y%m%d")
                self.factor_new.append(df)
            self.factor_new = df
            # æ‹¼æ¥æ–°çš„å’Œæ—§çš„
            self.factor = (
                pd.concat([self.factor_old, self.factor_new])
                .sort_index()
                .drop_duplicates()
            )
            new_end_date = datetime.datetime.strftime(self.factor.index.max(), "%Y%m%d")
            # å­˜å…¥æœ¬åœ°
            self.factor.to_parquet(self.factor_file)
            logger.info(f"è¡¥å……{self.dates_new[0]}æˆªæ­¢åˆ°{new_end_date}çš„å› å­å€¼è®¡ç®—å®Œäº†")
        else:
            self.factor = self.factor_old
            new_end_date = datetime.datetime.strftime(self.factor.index.max(), "%Y%m%d")
            logger.info(f"å½“å‰æˆªæ­¢åˆ°{new_end_date}çš„å› å­å€¼å·²ç»æ˜¯æœ€æ–°çš„äº†")
            
            
def database_update_minute_data_to_postgresql(kind: str) -> None:
    """ä½¿ç”¨ç±³ç­æ›´æ–°åˆ†é’Ÿæ•°æ®è‡³postgresqlä¸­

    Parameters
    ----------
    kind : str
        æ›´æ–°è‚¡ç¥¨åˆ†é’Ÿæ•°æ®æˆ–æŒ‡æ•°åˆ†é’Ÿæ•°æ®ï¼Œè‚¡ç¥¨åˆ™'stock'ï¼ŒæŒ‡æ•°åˆ™'index'

    Raises
    ------
    `IOError`
        å¦‚æœæœªæŒ‡å®šè‚¡ç¥¨è¿˜æ˜¯æŒ‡æ•°ï¼Œå°†æŠ¥é”™
    """
    if kind == "stock":
        code_type = "CS"
    elif kind == "index":
        code_type = "INDX"
    else:
        raise IOError("æ€»å¾—æŒ‡å®šä¸€ç§ç±»å‹å§ï¼Ÿè¯·ä»stockå’Œindexä¸­é€‰ä¸€ä¸ª")
    # è·å–å‰©ä½™ä½¿ç”¨é¢
    user1 = round(rqdatac.user.get_quota()["bytes_used"] / 1024 / 1024, 2)
    logger.info(f"ä»Šæ—¥å·²ä½¿ç”¨rqsdkæµé‡{user1}MB")
    # è·å–å…¨éƒ¨è‚¡ç¥¨/æŒ‡æ•°ä»£ç 
    cs = rqdatac.all_instruments(type=code_type, market="cn", date=None)
    codes = list(cs.order_book_id)
    # è·å–ä¸Šæ¬¡æ›´æ–°æˆªæ­¢æ—¶é—´
    try:
        qdb = Questdb()
        last_date = max(qdb.show_all_dates(f"minute_data_{kind}"))
    except Exception:
        qdb = Questdb(web_port="9000")
        last_date = max(qdb.show_all_dates(f"minute_data_{kind}"))
    # æœ¬æ¬¡æ›´æ–°èµ·å§‹æ—¥æœŸ
    start_date = pd.Timestamp(str(last_date)) + pd.Timedelta(days=1)
    start_date = datetime.datetime.strftime(start_date, "%Y-%m-%d")
    # æœ¬æ¬¡æ›´æ–°ç»ˆæ­¢æ—¥æœŸ
    end_date = datetime.datetime.now()
    if end_date.hour < 17:
        end_date = end_date - pd.Timedelta(days=1)
    end_date = datetime.datetime.strftime(end_date, "%Y-%m-%d")
    logger.info(f"æœ¬æ¬¡å°†ä¸‹è½½ä»{start_date}åˆ°{end_date}çš„æ•°æ®")
    # ä¸‹è½½æ•°æ®
    ts = rqdatac.get_price(
        codes,
        start_date=start_date,
        end_date=end_date,
        frequency="1m",
        fields=["volume", "total_turnover", "high", "low", "close", "open"],
        adjust_type="none",
        skip_suspended=False,
        market="cn",
        expect_df=True,
        time_slice=None,
    )
    # è°ƒæ•´æ•°æ®æ ¼å¼
    ts = ts.reset_index()
    ts = ts.rename(
        columns={
            "order_book_id": "code",
            "datetime": "date",
            "volume": "amount",
            "total_turnover": "money",
        }
    )
    ts = ts.sort_values(["code", "date"])
    ts.date = ts.date.dt.strftime("%Y%m%d").astype(int)
    ts = ts.groupby(["code", "date"]).apply(
        lambda x: x.assign(num=list(range(1, x.shape[0] + 1)))
    )
    ts.code = ts.code.str.replace(".XSHE", ".SZ")
    ts.code = ts.code.str.replace(".XSHG", ".SH")
    # æ•°æ®å†™å…¥æ•°æ®åº“
    pgdb = PostgreSQL("minute_data")
    ts.to_sql(
        f"minute_data_{kind}",
        pgdb.engine,
        if_exists="append",
        index=False,
        dtype={
            "code": VARCHAR(9),
            "date": INT,
            "open": FLOAT,
            "high": FLOAT,
            "low": FLOAT,
            "close": FLOAT,
            "amount": FLOAT,
            "money": FLOAT,
            "num": INT,
        },
    )
    # è·å–å‰©ä½™ä½¿ç”¨é¢
    user2 = round(rqdatac.user.get_quota()["bytes_used"] / 1024 / 1024, 2)
    user12 = round(user2 - user1, 2)
    logger.info(f"ä»Šæ—¥å·²ä½¿ç”¨rqsdkæµé‡{user2}MBï¼Œæœ¬é¡¹æ›´æ–°æ¶ˆè€—æµé‡{user12}MB")
