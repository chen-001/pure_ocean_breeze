__updated__ = "2023-07-26 16:42:17"

import os
import numpy as np
import pandas as pd
import datetime
from typing import Any, Union, Dict, Tuple

from pure_ocean_breeze.jason.state.states import STATES
from pure_ocean_breeze.jason.state.homeplace import HomePlace
from pure_ocean_breeze.jason.state.decorators import *
from cachier import cachier

try:
    homeplace = HomePlace()
except Exception:
    print("æ‚¨æš‚æœªåˆå§‹åŒ–ï¼ŒåŠŸèƒ½å°†å—é™")


@cachier()
def read_daily(
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    vwap: bool = 0,
    tr: bool = 0,
    sharenum: bool = 0,
    total_sharenum: bool = 0,
    amount: bool = 0,
    money: bool = 0,
    flow_cap: bool = 0,
    total_cap: bool = 0,
    adjfactor: bool = 0,
    state: bool = 0,
    state_loose: bool = 0,
    unadjust: bool = 0,
    ret: bool = 0,
    ret_inday: bool = 0,
    ret_night: bool = 0,
    vol: bool = 0,
    vol_inday: bool = 0,
    vol_night: bool = 0,
    swing: bool = 0,
    stop_up: bool = 0,
    stop_down: bool = 0,
    up_down_limit_status:bool=0,
    swindustry_dummy: bool = 0,
    start: Union[int, str] = STATES["START"],
) -> pd.DataFrame:
    """ç›´æŽ¥è¯»å–å¸¸ç”¨çš„é‡ä»·è¯»å–æ—¥é¢‘æ•°æ®ï¼Œé»˜è®¤ä¸ºå¤æƒä»·æ ¼ï¼Œ
    åœ¨ open,close,high,low,tr,sharenum,volume ä¸­é€‰æ‹©ä¸€ä¸ªå‚æ•°æŒ‡å®šä¸º1

    Parameters
    ----------
    open : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å¼€ç›˜ä»·, by default 0
    close : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ”¶ç›˜ä»·, by default 0
    high : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€é«˜ä»·, by default 0
    low : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æœ€ä½Žä»·, by default 0
    vwap : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ—¥å‡æˆäº¤ä»·, by default 0
    tr : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ¢æ‰‹çŽ‡, by default 0
    sharenum : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šè‚¡æ•°, by default 0
    total_sharenum : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ€»è‚¡æ•°, by default 0
    amount : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æˆäº¤é‡, by default 0
    money : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æˆäº¤é¢, by default 0
    flow_cap : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æµé€šå¸‚å€¼, by default 0
    total_cap : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ€»å¸‚å€¼, by default 0
    adjfactor : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å¤æƒå› å­, by default 0
    state : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥äº¤æ˜“çŠ¶æ€æ˜¯å¦æ­£å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸äº¤æ˜“ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    state_loose : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–å½“æ—¥äº¤æ˜“çŠ¶æ€æ˜¯å¦æ­£å¸¸ï¼Œ1è¡¨ç¤ºæ­£å¸¸äº¤æ˜“ï¼Œç©ºå€¼åˆ™ä¸æ˜¯, by default 0
    unadjust : bool, optional
        ä¸º1åˆ™å°†ä¸Šè¿°ä»·æ ¼æ”¹ä¸ºä¸å¤æƒä»·æ ¼, by default 0
    ret : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ—¥é—´æ”¶ç›ŠçŽ‡, by default 0
    ret_inday : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ—¥å†…æ”¶ç›ŠçŽ‡, by default 0
    ret_night : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–éš”å¤œæ³¢åŠ¨çŽ‡, by default 0
    vol : bool, optional
        ä¸º1åˆ™é€‰æ‹©è¯»å–æ»šåŠ¨20æ—¥æ—¥é—´æ³¢åŠ¨çŽ‡, by default 0
    vol_inday : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ»šåŠ¨20æ—¥æ—¥å†…æ”¶ç›ŠçŽ‡æ³¢åŠ¨çŽ‡, by default 0
    vol_night : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ»šåŠ¨20æ—¥éš”å¤œæ”¶ç›ŠçŽ‡æ³¢åŠ¨çŽ‡, by default 0
    swing : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æŒ¯å¹…, by default 0
    stop_up : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ¯åªè‚¡ç¥¨æ¶¨åœä»·, by default 0
    stop_down : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–æ¯åªè‚¡ç¥¨è·Œåœä»·, by default 0
    swindustry_dummy : bool, optional
        ä¸º1åˆ™è¡¨ç¤ºè¯»å–ç”³ä¸‡ä¸€çº§è¡Œä¸šå“‘å˜é‡, by default 0
    start : Union[int,str], optional
        èµ·å§‹æ—¥æœŸï¼Œå½¢å¦‚20130101, by default STATES["START"]

    Returns
    -------
    `pd.DataFrame`
        ä¸€ä¸ªcolumnsä¸ºè‚¡ç¥¨ä»£ç ï¼Œindexä¸ºæ—¶é—´ï¼Œvaluesä¸ºç›®æ ‡æ•°æ®çš„pd.DataFrame

    Raises
    ------
    `IOError`
        open,close,high,low,tr,sharenum,volume éƒ½ä¸º0æ—¶ï¼Œå°†æŠ¥é”™
    """

    if not unadjust:
        if open:
            df = pd.read_parquet(
                homeplace.daily_data_file + "opens.parquet"
            ) * read_daily(state=1, start=start)
        elif close:
            df = pd.read_parquet(
                homeplace.daily_data_file + "closes.parquet"
            ) * read_daily(state=1, start=start)
        elif high:
            df = pd.read_parquet(
                homeplace.daily_data_file + "highs.parquet"
            ) * read_daily(state=1, start=start)
        elif low:
            df = pd.read_parquet(
                homeplace.daily_data_file + "lows.parquet"
            ) * read_daily(state=1, start=start)
        elif vwap:
            df = (
                pd.read_parquet(homeplace.daily_data_file + "vwaps.parquet")
                * read_daily(adjfactor=1, start=start)
                *read_daily(state=1, start=start)
            )
        elif tr:
            df = pd.read_parquet(homeplace.daily_data_file + "trs.parquet").replace(
                0, np.nan
            ) *read_daily(state=1, start=start)
        elif sharenum:
            df = pd.read_parquet(homeplace.daily_data_file + "sharenums.parquet")
        elif total_sharenum:
            df = pd.read_parquet(homeplace.daily_data_file + "total_sharenums.parquet")
        elif amount:
            df = pd.read_parquet(
                homeplace.daily_data_file + "amounts.parquet"
            ) * read_daily(state=1, start=start)
        elif money:
            df = pd.read_parquet(
                homeplace.daily_data_file + "moneys.parquet"
            )*read_daily(state=1, start=start)
        elif flow_cap:
            df = pd.read_parquet(homeplace.daily_data_file + "flow_caps.parquet")
        elif total_cap:
            df = pd.read_parquet(homeplace.daily_data_file + "total_caps.parquet")
        elif adjfactor:
            df=pd.read_parquet(homeplace.daily_data_file+'adjfactors.parquet')
        elif state:
            df = pd.read_parquet(homeplace.daily_data_file + "states.parquet")
        elif state_loose:
            df = pd.read_parquet(homeplace.daily_data_file + "states_loose.parquet")
        elif ret:
            df = read_daily(close=1, start=start)
            df = df / df.shift(1) - 1
        elif ret_inday:
            df = read_daily(close=1, start=start) / read_daily(open=1, start=start) - 1
        elif ret_night:
            df = (
                read_daily(open=1, start=start)
                / read_daily(close=1, start=start).shift(1)
                - 1
            )
        elif vol:
            df = read_daily(ret=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif vol_inday:
            df = read_daily(ret_inday=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif vol_night:
            df = read_daily(ret_night=1, start=start)
            df = df.rolling(20, min_periods=10).std()
        elif swing:
            df = (
                read_daily(high=1, start=start) - read_daily(low=1, start=start)
            ) / read_daily(close=1, start=start).shift(1)
        elif stop_up:
            df = (
                pd.read_parquet(homeplace.daily_data_file + "stop_ups.parquet")
                * read_daily(adjfactor=1, start=start)
                * read_daily(state=1, start=start)
            )
        elif stop_down:
            df = (
                pd.read_parquet(homeplace.daily_data_file + "stop_downs.parquet")
                * read_daily(adjfactor=1, start=start)
                * read_daily(state=1, start=start)
            )
        elif up_down_limit_status:
            df=pd.read_parquet(homeplace.daily_data_file+'up_down_limit_status.parquet')
        elif swindustry_dummy:
            df=pd.read_parquet(homeplace.daily_data_file+'sw_industry_level1_dummies.parquet')
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸðŸ¤’")
    else:
        if open:
            df = pd.read_parquet(
                homeplace.daily_data_file + "opens_unadj.parquet"
            ) * read_daily(state=1, start=start)
        elif close:
            df = pd.read_parquet(
                homeplace.daily_data_file + "closes_unadj.parquet"
            ) * read_daily(state=1, start=start)
        elif high:
            df = pd.read_parquet(
                homeplace.daily_data_file + "highs_unadj.parquet"
            ) * read_daily(state=1, start=start)
        elif low:
            df = pd.read_parquet(
                homeplace.daily_data_file + "lows_unadj.parquet"
            ) * read_daily(state=1, start=start)
        elif vwap:
            df = pd.read_parquet(
                homeplace.daily_data_file + "vwaps.parquet"
            ) * read_daily(state=1, start=start)
        elif stop_up:
            df = pd.read_parquet(
                homeplace.daily_data_file + "stop_ups.parquet"
            ) * read_daily(state=1, start=start)
        elif stop_down:
            df = pd.read_parquet(
                homeplace.daily_data_file + "stop_downs.parquet"
            ) * read_daily(state=1, start=start)
        else:
            raise IOError("é˜ä¸‹æ€»å¾—è¯»ç‚¹ä»€ä¹ˆå§ï¼ŸðŸ¤’")
    if "date" not in df.columns:
        df = df[df.index >= pd.Timestamp(str(start))]
    return df.dropna(how="all")


def get_industry_dummies(
    daily: bool = 0,
    weekly: bool = 0,
    start: int = STATES["START"],
) -> Dict:
    """ç”Ÿæˆ30/31ä¸ªè¡Œä¸šçš„å“‘å˜é‡çŸ©é˜µï¼Œè¿”å›žä¸€ä¸ªå­—å…¸

    Parameters
    ----------
    daily : bool, optional
        è¿”å›žæ—¥é¢‘çš„å“‘å˜é‡, by default 0
    weekly : bool, optional
        è¿”å›žweeké¢‘çš„å“‘å˜é‡, by default 0
    start : int, optional
        èµ·å§‹æ—¥æœŸ, by default STATES["START"]

    Returns
    -------
    `Dict`
        å„ä¸ªè¡Œä¸šåŠå…¶å“‘å˜é‡æž„æˆçš„å­—å…¸

    Raises
    ------
    `ValueError`
        å¦‚æžœæœªæŒ‡å®šé¢‘çŽ‡ï¼Œå°†æŠ¥é”™
    """
    homeplace = HomePlace()
    name='sw_industry_level1_dummies.parquet'
    if weekly:
        industry_dummy = pd.read_parquet(homeplace.daily_data_file + name)
        industry_dummy = (
            industry_dummy.set_index("date")
            .groupby("code")
            .resample("W")
            .last()
            .fillna(0)
            .drop(columns=["code"])
            .reset_index()
        )
    elif daily:
        industry_dummy = pd.read_parquet(homeplace.daily_data_file + name).fillna(0)
    else:
        raise ValueError("æ‚¨æ€»å¾—æŒ‡å®šä¸€ä¸ªé¢‘çŽ‡å§ï¼ŸðŸ¤’")
    industry_dummy = industry_dummy[industry_dummy.date >= pd.Timestamp(str(start))]
    ws = list(industry_dummy.columns)[2:]
    ress = {}
    for w in ws:
        df = industry_dummy[["date", "code", w]]
        df = df.pivot(index="date", columns="code", values=w)
        df = df.replace(0, np.nan)
        ress[w] = df
    return ress


def database_read_final_factors(name: str = None) -> pd.DataFrame:
    """æ ¹æ®å› å­åå­—ï¼Œæˆ–å› å­åºå·ï¼Œè¯»å–æœ€ç»ˆå› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None

    Returns
    -------
    `pd.DataFrame`
        æœ€ç»ˆå› å­å€¼å’Œæ–‡ä»¶è·¯å¾„
    """
    homeplace = HomePlace()
    df=pd.read_parquet(homeplace.final_factor_file+name+'.parquet')
    return df


def database_read_primary_factors(name: str) -> pd.DataFrame:
    """æ ¹æ®å› å­åå­—ï¼Œè¯»å–åˆçº§å› å­çš„å› å­å€¼

    Parameters
    ----------
    name : str, optional
        å› å­çš„åå­—, by default None

    Returns
    -------
    `pd.DataFrame`
        åˆçº§å› å­çš„å› å­å€¼
    """
    homeplace = HomePlace()
    df = pd.read_parquet(homeplace.factor_data_file + name+'.parquet')
    return df

@cachier()
def read_market(
    open: bool = 0,
    close: bool = 0,
    high: bool = 0,
    low: bool = 0,
    start: int = STATES["START"],
    every_stock: bool = 1,
    sh50: bool = 0,
    hs300: bool = 0,
    zz500: bool = 0,
    zz1000: bool = 0,
) -> Union[pd.DataFrame, pd.Series]:
    """è¯»å–ä¸­è¯å…¨æŒ‡æ—¥è¡Œæƒ…æ•°æ®

    Parameters
    ----------
    open : bool, optional
        è¯»å–å¼€ç›˜ç‚¹æ•°, by default 0
    close : bool, optional
        è¯»å–æ”¶ç›˜ç‚¹æ•°, by default 0
    high : bool, optional
        è¯»å–æœ€é«˜ç‚¹æ•°, by default 0
    low : bool, optional
        è¯»å–æœ€ä½Žç‚¹æ•°, by default 0
    start : int, optional
        è¯»å–çš„èµ·å§‹æ—¥æœŸ, by default STATES["START"]
    every_stock : bool, optional
        æ˜¯å¦ä¿®æ”¹ä¸ºindexæ˜¯æ—¶é—´ï¼Œcolumnsæ˜¯æ¯åªè‚¡ç¥¨ä»£ç ï¼Œæ¯ä¸€åˆ—å€¼éƒ½ç›¸åŒçš„å½¢å¼, by default 1
    sh50 : bool, optional
        æ˜¯å¦è¯»å–ä¸Šè¯50, by default 0
    hs300 : bool, optional
        æ˜¯å¦è¯»å–æ²ªæ·±300, by default 0
    zz500 : bool, optional
        æ˜¯å¦è¯»å–ä¸­è¯500, by default 0
    zz1000 : bool, optional
        æ˜¯å¦è¯»å–ä¸­è¯1000, by default 0

    Returns
    -------
    Union[pd.DataFrame,pd.Series]
        è¯»å–market_indexçš„è¡Œæƒ…æ•°æ®        

    Raises
    ------
    IOError
        å¦‚æžœæ²¡æœ‰æŒ‡å®šä»»ä½•æŒ‡æ•°ï¼Œå°†æŠ¥é”™
    """
    homeplace=HomePlace()
    if open:
        # ç±³ç­çš„ç¬¬ä¸€åˆ†é’Ÿæ˜¯é›†åˆç«žä»·ï¼Œç¬¬ä¸€åˆ†é’Ÿçš„æ”¶ç›˜ä»·å³ä¸ºå½“å¤©å¼€ç›˜ä»·
        df = pd.read_parquet(homeplace.daily_data_file + "index_opens.parquet")
    elif close:
        df = pd.read_parquet(homeplace.daily_data_file + "index_closes.parquet")
    elif high:
        df = pd.read_parquet(homeplace.daily_data_file + "index_highs.parquet")
    elif low:
        df = pd.read_parquet(homeplace.daily_data_file + "index_lows.parquet")
    else:
        raise IOError("æ€»å¾—æŒ‡å®šä¸€ä¸ªæŒ‡æ ‡å§ï¼ŸðŸ¤’")
    if sh50:
        df = df["000016.SH"]
    elif hs300:
        df = df["000300.SH"]
    elif zz500:
        df = df["000905.SH"]
    elif zz1000:
        df = df["000852.SH"]
    else:
        raise IOError("æ€»å¾—æŒ‡å®šä¸€ä¸ªæŒ‡æ•°å§ï¼ŸðŸ¤’")
    if every_stock:
        tr = read_daily(tr=1, start=start)
        df = pd.DataFrame({k: list(df) for k in list(tr.columns)}, index=df.index)
    return df


@cachier()
def moon_read_dummy(freq):
    def deal_dummy(industry_dummy):
            industry_dummy = industry_dummy.drop(columns=["code"]).reset_index()
            industry_ws = [f"w{i}" for i in range(1, industry_dummy.shape[1] - 1)]
            col = ["code", "date"] + industry_ws
            industry_dummy.columns = col
            industry_dummy = industry_dummy[
                industry_dummy.date >= pd.Timestamp(str(STATES["START"]))
            ]
            return industry_dummy

            # week_here
    swindustry_dummy = (
        pd.read_parquet(
            homeplace.daily_data_file + "sw_industry_level1_dummies.parquet"
        )
        .fillna(0)
        .set_index("date")
        .groupby("code")
        .resample(freq)
        .last()
        )
    return deal_dummy(swindustry_dummy)

@cachier()
def moon_read_barra():
    styles = os.listdir(homeplace.barra_data_file)
    styles = [i for i in styles if (i.endswith(".parquet")) and (i[0] != ".")]
    barras = {}
    for s in styles:
        k = s.split(".")[0]
        v = pd.read_parquet(homeplace.barra_data_file + s).resample("W").last()
        barras[k] = v
    return barras